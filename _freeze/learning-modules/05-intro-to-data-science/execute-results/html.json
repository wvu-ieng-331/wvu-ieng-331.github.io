{
  "hash": "ee227d1564f32a00b5dc22f7117b56c8",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"05 | Introduction to Data Science\"\nsubtitle: \"Python data workflows with Polars and Plotly\"\nformat:\n  html:\n    fig-height: 2\n    other-links:\n      - text: \"Python Polars the Definitive Guide (Early Release)\"\n        href: resources/Python_Polars_the_Definitive_Guide_-_Early_Release_6.pdf\n        icon: filetype-pdf\n      - text: billboard.csv\n        href: data/billboard.csv\n        icon: filetype-csv\n      - text: cms_patient_experience.csv\n        href: data/cms_patient_experience.csv\n        icon: filetype-csv\n      - text: penguins.csv\n        href: data/penguins.csv\n        icon: filetype-csv\n      - text: students.csv\n        href: data/students.csv\n        icon: filetype-csv\n      - text: who2.csv\n        href: data/who2.csv\n        icon: filetype-csv\norder: 5\n---\n\n\n## Overview\n\nIn this beginning chapter, we will cover the fundamentals of data analysis in the form of **importing**, **tidying**, **transforming**, and **visualizing data**, as shown below:\n\n![In this learning module, you’ll learn how to import, tidy, transform, and visualize data.](images/whole-game.png)\n\nBy the end of this module, you will be able to:\n\n- Import data from various file formats into Python using Polars\n- Clean and reshape datasets to facilitate analysis\n- Transform data through filtering, sorting, and creating new variables\n- Group and aggregate data to identify patterns and trends\n- Visualize distributions and relationships using Plotly Express\n- Apply tidy data principles to structure datasets effectively\n\n### Initialization\n\nAt this point, you will need to install a few more Python packages:\n\n```{.bash filename=\"terminal\"}\nuv add polars[all] plotly[express] statsmodels palmerpenguins nycflights13 billboard\n```\n\nOnce installed, import the following:\n\n::: {#import-modules .cell execution_count=2}\n``` {.python .cell-code}\nimport plotly.express as px\nimport polars as pl\nimport palmerpenguins\n```\n:::\n\n\n## Data visualization\n\nPython has several systems for making graphs, but we will be focusing on [Plotly](https://plotly.com/python/), specifically [Plotly Express](https://plotly.com/python/plotly-express/). Plotly Express contains functions that can create entire plots at once, and makes it easy to create most common figures.\n\nThis section will teach you how to visualize your data using **Plotly Express**, walking through visualizing distributions of single variables, as well as relationships between two or more variables.\n\n### The `penguins` data frame\n\nThe dataset we will be working with is a commonly used one, affectionately referred to as the Palmer Penguins, which includes body measurements for penguins on three islands in the Palmer Archipelago. A **data frame** is a rectangular collection of variables (in the columns) and observations (in the rows). `penguins` contains 344 observations collected and made available by Dr. Kristen Gorman and the Palmer Station, Antarctica.\n\nLet's define some term:\n\n- A **variable** is a quantity, quality, or property that you can measure.\n- A **value** is the state of a variable when you measure it. The value of a variable may change from measurement to measurement.\n- An **observation** is a set of measurements made under similar conditions (you usually make all of the measurements in an observation at the same time and on the same object). An observation will contain several values, each associated with a different variable. We'll sometimes refer to an observation as a data point.\n- **Tabular data** is a set of values, each associated with a variable and an observation. Tabular data is *tidy* if each value is placed in its own \"cell\", each variable in its own column, and each observation in its own row.\n\nIn this context, a variable refers to an attribute of all the penguins, and an observation refers to all the attributes of a single penguin.\n\nWe will use `palmerpenguins` package to get the `penguins` data, and convert it to a `polars` data frame:\n\n::: {#57cf82e6 .cell execution_count=3}\n``` {.python .cell-code}\npenguins = pl.from_pandas(palmerpenguins.load_penguins())\n```\n:::\n\n\nThe reason we convert to a Polars data frame is because we want to use the tools and methods that come with Polars:\n\n::: {#191a111d .cell execution_count=4}\n``` {.python .cell-code}\ntype(penguins)\n```\n\n::: {.cell-output .cell-output-display execution_count=4}\n```\npolars.dataframe.frame.DataFrame\n```\n:::\n:::\n\n\nDepending on what tool/IDE you're using Python with, just having the variable name (`penguins`) as the last line will print a formatted view of the data. If not, you can also use `print()` to use Polars' native formatting:\n\n::: {#e02f0b34 .cell execution_count=5}\n``` {.python .cell-code}\npenguins\n```\n\n::: {.cell-output .cell-output-display execution_count=5}\n```{=html}\n<div><style>\n.dataframe > thead > tr,\n.dataframe > tbody > tr {\n  text-align: right;\n  white-space: pre-wrap;\n}\n</style>\n<small>shape: (344, 8)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>species</th><th>island</th><th>bill_length_mm</th><th>bill_depth_mm</th><th>flipper_length_mm</th><th>body_mass_g</th><th>sex</th><th>year</th></tr><tr><td>str</td><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>str</td><td>i64</td></tr></thead><tbody><tr><td>&quot;Adelie&quot;</td><td>&quot;Torgersen&quot;</td><td>39.1</td><td>18.7</td><td>181.0</td><td>3750.0</td><td>&quot;male&quot;</td><td>2007</td></tr><tr><td>&quot;Adelie&quot;</td><td>&quot;Torgersen&quot;</td><td>39.5</td><td>17.4</td><td>186.0</td><td>3800.0</td><td>&quot;female&quot;</td><td>2007</td></tr><tr><td>&quot;Adelie&quot;</td><td>&quot;Torgersen&quot;</td><td>40.3</td><td>18.0</td><td>195.0</td><td>3250.0</td><td>&quot;female&quot;</td><td>2007</td></tr><tr><td>&quot;Adelie&quot;</td><td>&quot;Torgersen&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>2007</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;Chinstrap&quot;</td><td>&quot;Dream&quot;</td><td>43.5</td><td>18.1</td><td>202.0</td><td>3400.0</td><td>&quot;female&quot;</td><td>2009</td></tr><tr><td>&quot;Chinstrap&quot;</td><td>&quot;Dream&quot;</td><td>49.6</td><td>18.2</td><td>193.0</td><td>3775.0</td><td>&quot;male&quot;</td><td>2009</td></tr><tr><td>&quot;Chinstrap&quot;</td><td>&quot;Dream&quot;</td><td>50.8</td><td>19.0</td><td>210.0</td><td>4100.0</td><td>&quot;male&quot;</td><td>2009</td></tr><tr><td>&quot;Chinstrap&quot;</td><td>&quot;Dream&quot;</td><td>50.2</td><td>18.7</td><td>198.0</td><td>3775.0</td><td>&quot;female&quot;</td><td>2009</td></tr></tbody></table></div>\n```\n:::\n:::\n\n\n::: {#08138c8f .cell execution_count=6}\n``` {.python .cell-code}\nprint(penguins)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nshape: (344, 8)\n┌───────────┬───────────┬──────────────┬──────────────┬──────────────┬─────────────┬────────┬──────┐\n│ species   ┆ island    ┆ bill_length_ ┆ bill_depth_m ┆ flipper_leng ┆ body_mass_g ┆ sex    ┆ year │\n│ ---       ┆ ---       ┆ mm           ┆ m            ┆ th_mm        ┆ ---         ┆ ---    ┆ ---  │\n│ str       ┆ str       ┆ ---          ┆ ---          ┆ ---          ┆ f64         ┆ str    ┆ i64  │\n│           ┆           ┆ f64          ┆ f64          ┆ f64          ┆             ┆        ┆      │\n╞═══════════╪═══════════╪══════════════╪══════════════╪══════════════╪═════════════╪════════╪══════╡\n│ Adelie    ┆ Torgersen ┆ 39.1         ┆ 18.7         ┆ 181.0        ┆ 3750.0      ┆ male   ┆ 2007 │\n│ Adelie    ┆ Torgersen ┆ 39.5         ┆ 17.4         ┆ 186.0        ┆ 3800.0      ┆ female ┆ 2007 │\n│ Adelie    ┆ Torgersen ┆ 40.3         ┆ 18.0         ┆ 195.0        ┆ 3250.0      ┆ female ┆ 2007 │\n│ Adelie    ┆ Torgersen ┆ null         ┆ null         ┆ null         ┆ null        ┆ null   ┆ 2007 │\n│ …         ┆ …         ┆ …            ┆ …            ┆ …            ┆ …           ┆ …      ┆ …    │\n│ Chinstrap ┆ Dream     ┆ 43.5         ┆ 18.1         ┆ 202.0        ┆ 3400.0      ┆ female ┆ 2009 │\n│ Chinstrap ┆ Dream     ┆ 49.6         ┆ 18.2         ┆ 193.0        ┆ 3775.0      ┆ male   ┆ 2009 │\n│ Chinstrap ┆ Dream     ┆ 50.8         ┆ 19.0         ┆ 210.0        ┆ 4100.0      ┆ male   ┆ 2009 │\n│ Chinstrap ┆ Dream     ┆ 50.2         ┆ 18.7         ┆ 198.0        ┆ 3775.0      ┆ female ┆ 2009 │\n└───────────┴───────────┴──────────────┴──────────────┴──────────────┴─────────────┴────────┴──────┘\n```\n:::\n:::\n\n\nThis data frame contains 8 columns. For an alternative view, use `DataFrame.glimpse()`, which is helpful for wide tables that have many columns:\n\n::: {#5875c016 .cell execution_count=7}\n``` {.python .cell-code}\npenguins.glimpse()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRows: 344\nColumns: 8\n$ species           <str> 'Adelie', 'Adelie', 'Adelie', 'Adelie', 'Adelie', 'Adelie', 'Adelie', 'Adelie', 'Adelie', 'Adelie'\n$ island            <str> 'Torgersen', 'Torgersen', 'Torgersen', 'Torgersen', 'Torgersen', 'Torgersen', 'Torgersen', 'Torgersen', 'Torgersen', 'Torgersen'\n$ bill_length_mm    <f64> 39.1, 39.5, 40.3, None, 36.7, 39.3, 38.9, 39.2, 34.1, 42.0\n$ bill_depth_mm     <f64> 18.7, 17.4, 18.0, None, 19.3, 20.6, 17.8, 19.6, 18.1, 20.2\n$ flipper_length_mm <f64> 181.0, 186.0, 195.0, None, 193.0, 190.0, 181.0, 195.0, 193.0, 190.0\n$ body_mass_g       <f64> 3750.0, 3800.0, 3250.0, None, 3450.0, 3650.0, 3625.0, 4675.0, 3475.0, 4250.0\n$ sex               <str> 'male', 'female', 'female', None, 'female', 'male', 'female', 'male', None, None\n$ year              <i64> 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007\n\n```\n:::\n:::\n\n\nAmong these variables are:\n\n1. `species`: a penguin's species (Adelie, Chinstrap, or Gentoo).\n2. `flipper_length_mm`: length of a penguin's flipper, in millimeters.\n3. `body_mass_g`: body mass of a penguin, in grams.\n\n### First visualization\n\nOur goal is to recreate the following visual that displays the relationship between flipper lengths and body masses of these penguins, taking into consideration the species of the penguin.\n\n::: {#final-goal-plot .cell execution_count=8}\n\n::: {#final-goal-plot-1 .cell-output .cell-output-display}\n```{=html}\n        <script type=\"text/javascript\">\n        window.PlotlyConfig = {MathJaxConfig: 'local'};\n        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n        </script>\n        <script type=\"module\">import \"https://cdn.plot.ly/plotly-3.0.0.min\"</script>\n        \n```\n:::\n\n::: {#final-goal-plot-2 .cell-output .cell-output-display}\n```{=html}\n<iframe\n    scrolling=\"no\"\n    width=\"100%\"\n    height=\"545px\"\n    src=\"iframe_figures/figure_8.html\"\n    frameborder=\"0\"\n    allowfullscreen\n></iframe>\n```\n:::\n:::\n\n\n### Using Plotly Express\n\nWith Plotly Express, you begin a plot by calling a plotting function from the module, commonly referred to as `px`. You can then add arguments to your plot function for more customization.\n\nAt it's most basic form, the plotting function creates a *blank canvas* with a grid since we've given it no data.\n\n::: {#514571a9 .cell execution_count=9}\n``` {.python .cell-code}\npx.scatter()\n```\n\n::: {.cell-output .cell-output-display}\n```{=html}\n<iframe\n    scrolling=\"no\"\n    width=\"100%\"\n    height=\"545px\"\n    src=\"iframe_figures/figure_9.html\"\n    frameborder=\"0\"\n    allowfullscreen\n></iframe>\n```\n:::\n:::\n\n\nNext, we need to actually provide data, along with the appropriate number of variables depending on the type of plot we are trying to create.\n\n::: {#167eb3da .cell execution_count=10}\n``` {.python .cell-code}\npx.scatter(data_frame=penguins, x=\"flipper_length_mm\", y=\"body_mass_g\")\n```\n\n::: {.cell-output .cell-output-display}\n```{=html}\n<iframe\n    scrolling=\"no\"\n    width=\"100%\"\n    height=\"545px\"\n    src=\"iframe_figures/figure_10.html\"\n    frameborder=\"0\"\n    allowfullscreen\n></iframe>\n```\n:::\n:::\n\n\n`px.scatter()` creates a [scatter plot](https://plotly.com/python/line-and-scatter/), and we will learn many more plot types through out the course. You can learn more about the different plots Plotly Express offers at their [gallery](https://plotly.com/python/plotly-express/#gallery).\n\nThis doesn't match our \"final goal\" *yet*, but using this plot we can start answering the question that motivated our exploration: \"What does the relationship between flipper length and body mass look like?\" The relationship appears to be positive (as flipper length increases, so does body mass), fairly linear (the points are clustered around a line instead of a curve), and moderately strong (there isn’t too much scatter around such a line). Penguins with longer flippers are generally larger in terms of their body mass.\n\nBefore we go further, I want to point out that this dataset has some missing values for `flipper_length_mm` and `body_mass_g`, but Plotly does not warn you about this when creating the plot. If one and/or other variable is missing data, we cannot plot that.\n\n### Adding aesthetics and layers\n\nScatter plots are useful for displaying the relationship between two numerical variables, but it’s always a good idea to be skeptical of any apparent relationship between two variables and ask if there may be other variables that explain or change the nature of this apparent relationship. For example, does the relationship between flipper length and body mass differ by species? Let’s incorporate species into our plot and see if this reveals any additional insights into the apparent relationship between these variables. We will do this by representing species with different colored points.\n\nTo achieve this, we will use some of the other arguments that `px.scatter()` provides for us, like `color`:\n\n::: {#1ff9a7a7 .cell execution_count=11}\n``` {.python .cell-code}\npx.scatter(\n    data_frame=penguins, \n    x=\"flipper_length_mm\", \n    y=\"body_mass_g\", \n    color=\"species\"\n)\n```\n\n::: {.cell-output .cell-output-display}\n```{=html}\n<iframe\n    scrolling=\"no\"\n    width=\"100%\"\n    height=\"545px\"\n    src=\"iframe_figures/figure_11.html\"\n    frameborder=\"0\"\n    allowfullscreen\n></iframe>\n```\n:::\n:::\n\n\nWhen a categorical variable is mapped to an aesthetic, Plotly will automatically assign a unique value of the aesthetic (here, a unique color) to each unique level of the variable (each of the three species), a process known as **scaling**. Plotly will also add a legend that explains which value correspond to which levels.\n\nNow let's add another layer, a trendline displaying the relationship between body mass and flipper length. `px.scatter()` has an argument for this, `trendline`, and a couple other arguments that modify its behavior. Specifically, we want to draw a line of best fit using Ordinary Least Squares (ols). You can see the other options, and more info about this plotting function with `?px.scatter()` or in the online documentation.\n\n::: {#403e4a4b .cell execution_count=12}\n``` {.python .cell-code}\npx.scatter(\n    data_frame=penguins, \n    x=\"flipper_length_mm\", \n    y=\"body_mass_g\", \n    color=\"species\",\n    trendline=\"ols\"\n)\n```\n\n::: {.cell-output .cell-output-display}\n```{=html}\n<iframe\n    scrolling=\"no\"\n    width=\"100%\"\n    height=\"545px\"\n    src=\"iframe_figures/figure_12.html\"\n    frameborder=\"0\"\n    allowfullscreen\n></iframe>\n```\n:::\n:::\n\n\nWe've added lines, but this plot doesn't look like our final goal, which only has one line for the entire dataset, opposed to separate lines for each of the penguin species. `px.scatter()` has an argument, `trendline_scope`, which controls how the trendline is drawn when there are groups, in this case created when we used `color=\"species\"`. The default for `trendline_scope` is `\"trace\"`, which draws a line per color, symbol, facet, etc., and `\"overall\"`, which computes one trendline for the entire dataset,a nd replicates across all facets.\n\n::: {#3e6a7962 .cell execution_count=13}\n``` {.python .cell-code}\npx.scatter(\n    data_frame=penguins, \n    x=\"flipper_length_mm\", \n    y=\"body_mass_g\", \n    color=\"species\",\n    trendline=\"ols\",\n    trendline_scope=\"overall\"\n)\n```\n\n::: {.cell-output .cell-output-display}\n```{=html}\n<iframe\n    scrolling=\"no\"\n    width=\"100%\"\n    height=\"545px\"\n    src=\"iframe_figures/figure_13.html\"\n    frameborder=\"0\"\n    allowfullscreen\n></iframe>\n```\n:::\n:::\n\n\nNow we have something that is very close to our final plot, thought it's not there yet. We still need to use different shapes for each species and improve the labels.\n\nIt's generally not a good idea to represent information only using colors on a plot as people perceive colors differently do to color blindness or other color vision difference. `px.scatter()` allows us to control the shapes of the dots using the `symbol` argument.\n\n::: {#d642b170 .cell execution_count=14}\n``` {.python .cell-code}\npx.scatter(\n    penguins,\n    x=\"flipper_length_mm\",\n    y=\"body_mass_g\",\n    color=\"species\",\n    symbol=\"species\",\n    trendline=\"ols\",\n    trendline_scope=\"overall\",\n)\n```\n\n::: {.cell-output .cell-output-display}\n```{=html}\n<iframe\n    scrolling=\"no\"\n    width=\"100%\"\n    height=\"545px\"\n    src=\"iframe_figures/figure_14.html\"\n    frameborder=\"0\"\n    allowfullscreen\n></iframe>\n```\n:::\n:::\n\n\nNote that the legend is automatically updated to reflect the different shapes of the points as well.\n\nFinally, we can use `title`, `subtitle`, and `labels` arguments to update our labels. `title` and `subtitle` just take a string, adding labels are bit more advanced. `labels` takes a dictionary with key:value combos for each of the labels on the plot that you would like to change. In our plot, we want to update the labels for the x-axis, y-axis, and the legend, but we refer to them by their current label, not their position:\n\n::: {#5b2799dc .cell execution_count=15}\n``` {.python .cell-code}\npx.scatter(\n    penguins,\n    x=\"flipper_length_mm\",\n    y=\"body_mass_g\",\n    color=\"species\",\n    symbol=\"species\",\n    trendline=\"ols\",\n    trendline_scope=\"overall\",\n    title=\"Body mass and flipper length\",\n    subtitle=\"Dimensions for Adelie, Chinstrap, and Gentoo Penguins\",\n    labels={\n        \"species\":\"Species\",\n        \"body_mass_g\":\"Body mass (g)\",\n        \"flipper_length_mm\":\"Flipper length (mm)\"\n    }\n)\n```\n\n::: {.cell-output .cell-output-display}\n```{=html}\n<iframe\n    scrolling=\"no\"\n    width=\"100%\"\n    height=\"545px\"\n    src=\"iframe_figures/figure_15.html\"\n    frameborder=\"0\"\n    allowfullscreen\n></iframe>\n```\n:::\n:::\n\n\nNow we have our final plot. If you haven't noticed already, Plotly creates *interactive* plots, you can hover over certain data points to see their values, use the legend as a filter, and so on. In the top right of every plot, you will see a menu with some options.\n\n### Visualizing distributions\n\nHow you visualize the distribution of a variable depends on the type of the variable: categorical or numerical.\n\n#### A categorical variable\n\nA value is **categorical** if it can only take one of a small set of values. To examine the distribution of a categorical variable, you can use a [bar chart](https://plotly.com/python/bar-charts/). The height of the bars displays how many observations occurred with each `x` value.\n\n::: {#ed698f57 .cell execution_count=16}\n``` {.python .cell-code}\npx.bar(penguins, x=\"species\")\n```\n\n::: {.cell-output .cell-output-display}\n```{=html}\n<iframe\n    scrolling=\"no\"\n    width=\"100%\"\n    height=\"545px\"\n    src=\"iframe_figures/figure_16.html\"\n    frameborder=\"0\"\n    allowfullscreen\n></iframe>\n```\n:::\n:::\n\n\n`px.bar()` will result in **one rectangle drawn per row of input**, which can result in the striped look above. To combine these rectangles into on color per position, we can pre-calculate the **count** as and use it as the **y** value:\n\n::: {#a974c0bc .cell execution_count=17}\n``` {.python .cell-code}\n# we'll learn more about this Polars code later\npenguins_count = penguins.group_by(\"species\").len(\"count\")\nprint(penguins_count)\n\npx.bar(penguins_count, x=\"species\", y=\"count\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nshape: (3, 2)\n┌───────────┬───────┐\n│ species   ┆ count │\n│ ---       ┆ ---   │\n│ str       ┆ u32   │\n╞═══════════╪═══════╡\n│ Adelie    ┆ 152   │\n│ Gentoo    ┆ 124   │\n│ Chinstrap ┆ 68    │\n└───────────┴───────┘\n```\n:::\n\n::: {.cell-output .cell-output-display}\n```{=html}\n<iframe\n    scrolling=\"no\"\n    width=\"100%\"\n    height=\"545px\"\n    src=\"iframe_figures/figure_17.html\"\n    frameborder=\"0\"\n    allowfullscreen\n></iframe>\n```\n:::\n:::\n\n\nThe order of categorical values in axes, legends, and facets depends on the order in which these values are first encountered in `data_frame`. It's often preferable to re-order the bars based on their frequency, which we can do with the `category_orders` argument. `category_orders` takes a dictionary where the keys correspond to column names, and the values should be lists of strings corresponding to the specific display order desired\n\n::: {#ac5ffa34 .cell execution_count=18}\n``` {.python .cell-code}\npx.bar(\n    penguins_count,\n    x=\"species\", \n    y=\"count\",\n    category_orders={\"species\": [\"Adelie\", \"Gentoo\", \"Chinstrap\"]}\n)\n```\n\n::: {.cell-output .cell-output-display}\n```{=html}\n<iframe\n    scrolling=\"no\"\n    width=\"100%\"\n    height=\"545px\"\n    src=\"iframe_figures/figure_18.html\"\n    frameborder=\"0\"\n    allowfullscreen\n></iframe>\n```\n:::\n:::\n\n\nWhile it's easy enough to manually sort three columns, this could become very tedious for more columns. Here is one programmatic way you could sort the columns:\n\n::: {#02eca153 .cell execution_count=19}\n``` {.python .cell-code}\npenguins_sorted = (\n    penguins_count\n    .sort(by=\"count\", descending=True)\n    .get_column(\"species\")\n)\n\nprint(penguins_sorted)\n\npx.bar(\n    penguins_count,\n    x=\"species\", \n    y=\"count\",\n    category_orders={\"species\": penguins_sorted}\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nshape: (3,)\nSeries: 'species' [str]\n[\n\t\"Adelie\"\n\t\"Gentoo\"\n\t\"Chinstrap\"\n]\n```\n:::\n\n::: {.cell-output .cell-output-display}\n```{=html}\n<iframe\n    scrolling=\"no\"\n    width=\"100%\"\n    height=\"545px\"\n    src=\"iframe_figures/figure_19.html\"\n    frameborder=\"0\"\n    allowfullscreen\n></iframe>\n```\n:::\n:::\n\n\nWe will dive into the data manipulation code later, this is just to show what's possible.\n\n#### A numerical variable\n\nA variable is **numerical** (or quantitative) if it can take on a wide range of numerical values, and it is sensible to add, subtract, or take averages with those values. Numerical variables can be continuous or discrete.\n\nOne common visualization for distributions of continuous variables is a [histogram](https://plotly.com/python/histograms/).\n\n::: {#c75b873f .cell execution_count=20}\n``` {.python .cell-code}\npx.histogram(penguins, x=\"body_mass_g\")\n```\n\n::: {.cell-output .cell-output-display}\n```{=html}\n<iframe\n    scrolling=\"no\"\n    width=\"100%\"\n    height=\"545px\"\n    src=\"iframe_figures/figure_20.html\"\n    frameborder=\"0\"\n    allowfullscreen\n></iframe>\n```\n:::\n:::\n\n\nA histogram divides the x-axis into equally spaced bins and then uses the heigh of the bar to display the number observations that fall in each bin. In the graph above, the tallest bar shows that 39 observations have a `body_mass_g` value between 3,500 and 3,700 grams, which are the left and right edges of the bar.\n\nWhen working with histograms, it's a good idea to use different number of bins to reveal different patterns in the data. In the plots below, X bars is too many, resulting in narrow bars. Similarly, 3 bins is too few, resulting in all the data being binned into huge categories that make it difficult to determine the shape of the distribution. A bin number of 20 provides a sensible balance.\n\n::: {layout=\"[[1,1], [1]]\"}\n\n::: {#1f020cb8 .cell execution_count=21}\n``` {.python .cell-code}\npx.histogram(penguins, x=\"body_mass_g\", nbins=200)\n```\n\n::: {.cell-output .cell-output-display}\n```{=html}\n<iframe\n    scrolling=\"no\"\n    width=\"100%\"\n    height=\"545px\"\n    src=\"iframe_figures/figure_21.html\"\n    frameborder=\"0\"\n    allowfullscreen\n></iframe>\n```\n:::\n:::\n\n\n::: {#64e3398c .cell execution_count=22}\n``` {.python .cell-code}\npx.histogram(penguins, x=\"body_mass_g\", nbins=3)\n```\n\n::: {.cell-output .cell-output-display}\n```{=html}\n<iframe\n    scrolling=\"no\"\n    width=\"100%\"\n    height=\"545px\"\n    src=\"iframe_figures/figure_22.html\"\n    frameborder=\"0\"\n    allowfullscreen\n></iframe>\n```\n:::\n:::\n\n\n::: {#27ccf90d .cell execution_count=23}\n``` {.python .cell-code}\npx.histogram(penguins, x=\"body_mass_g\", nbins=20)\n```\n\n::: {.cell-output .cell-output-display}\n```{=html}\n<iframe\n    scrolling=\"no\"\n    width=\"100%\"\n    height=\"545px\"\n    src=\"iframe_figures/figure_23.html\"\n    frameborder=\"0\"\n    allowfullscreen\n></iframe>\n```\n:::\n:::\n\n\n:::\n\nAn alternative visualization for distributions of numerical variables is a [density plot](https://www.data-to-viz.com/graph/density.html). A density plot is a smoothed-out version of a histogram and a practical alternative, particularly for continuous data that comes from an underlying smooth distribution. At the time of writing, Plotly Express doesn't have a quick way to create a density plot, but it does offer very customizable [violin plots](https://plotly.com/python/violin/), which we can make to look like a density plot if we would like.\n\n::: {#517b9ae7 .cell execution_count=24}\n``` {.python .cell-code}\npx.violin(penguins, x=\"body_mass_g\")\n```\n\n::: {.cell-output .cell-output-display}\n```{=html}\n<iframe\n    scrolling=\"no\"\n    width=\"100%\"\n    height=\"545px\"\n    src=\"iframe_figures/figure_24.html\"\n    frameborder=\"0\"\n    allowfullscreen\n></iframe>\n```\n:::\n:::\n\n\nThe density plot is similar to the violin plot, with only one side, and the peaks are more exaggerated:\n\n::: {#3cec6a34 .cell execution_count=25}\n``` {.python .cell-code}\npx.violin(\n    penguins, \n    x=\"body_mass_g\", # plots the variable across the x-axis\n    range_y=[\n        0,   # limits the bottom of y-axis, removing reflection\n        0.25 # limits the top of y-axis, stretching the peaks\n    ]\n)\n```\n\n::: {.cell-output .cell-output-display}\n```{=html}\n<iframe\n    scrolling=\"no\"\n    width=\"100%\"\n    height=\"545px\"\n    src=\"iframe_figures/figure_25.html\"\n    frameborder=\"0\"\n    allowfullscreen\n></iframe>\n```\n:::\n:::\n\n\nWhile this workaround works, sticking to the original violin plot I think looks better, and we can add some extra arguments to see more details:\n\n::: {#848578eb .cell execution_count=26}\n``` {.python .cell-code}\npx.violin(penguins, x=\"body_mass_g\", points=\"all\")\n```\n\n::: {.cell-output .cell-output-display}\n```{=html}\n<iframe\n    scrolling=\"no\"\n    width=\"100%\"\n    height=\"545px\"\n    src=\"iframe_figures/figure_26.html\"\n    frameborder=\"0\"\n    allowfullscreen\n></iframe>\n```\n:::\n:::\n\n\nPlay around with different arguments and see what you like best!\n\nAs an analogy to understand these plots vs a histogram, imagine a histogram made out of wooden blocks. Then, imagine that you drop a cooked spaghetti string over it. The shape the spaghetti will take draped over blocks can be thought of as the shape of the density curve. It shows fewer details than a histogram but can make it easier to quickly glean the shape of the distribution, particularly with respect to modes and skewness.\n\n### Visualizing relationships\n\nTo visualize a relationship we need to have at least two variables mapped to aesthetics of a plot. In the following sections you will learn about commonly used plots for visualizing relationships between two or more variables and the plots used for creating them.\n\n#### A numerical and a categorical variable\n\nTo visualize the relationship between a numerical and a categorical variable we can use side-by-side box plots. A [boxplot](https://plotly.com/python/box-plots/) is a type of visual shorthand for measures of position (percentiles) that describe a distribution. It is also useful for identifying potential outliers. Each boxplot consists of:\n\n- A box that indicates the range of the middle half of the data, a distance known as the inter-quartile range (IQR), stretching from the 25th percentile of the distribution to the 75th percentile. In the middle of the box is a line that displays the median, i.e. 50th percentile, of the distribution. These three lines give you a sense of the spread of the distribution and whether or not the distribution is symmetric about the median or skewed to one side.\n\n- Visual points that display observations that fall more than 1.5 times the IQR from either edge of the box. These outlying points are unusual so are plotted individually.\n\n- A line (or whisker) that extends from each end of the box and goes to the farthest non-outlier point in the distribution.\n\n![\"Diagram depicting how a boxplot is created.\"](images/EDA-boxplot.png)\n\nLet’s take a look at the distribution of body mass by species using `px.box()`\n\n::: {#3ac70c3b .cell execution_count=27}\n``` {.python .cell-code}\npx.box(penguins, x=\"species\", y=\"body_mass_g\")\n```\n\n::: {.cell-output .cell-output-display}\n```{=html}\n<iframe\n    scrolling=\"no\"\n    width=\"100%\"\n    height=\"545px\"\n    src=\"iframe_figures/figure_27.html\"\n    frameborder=\"0\"\n    allowfullscreen\n></iframe>\n```\n:::\n:::\n\n\nAlternatively, we can make violin plots with multiple groups:\n\n::: {#f3fa44c0 .cell execution_count=28}\n``` {.python .cell-code}\npx.violin(penguins, x=\"body_mass_g\", color=\"species\", box=True)\n```\n\n::: {.cell-output .cell-output-display}\n```{=html}\n<iframe\n    scrolling=\"no\"\n    width=\"100%\"\n    height=\"545px\"\n    src=\"iframe_figures/figure_28.html\"\n    frameborder=\"0\"\n    allowfullscreen\n></iframe>\n```\n:::\n:::\n\n\nAs we've seen before, there are many ways to see and code what we are looking for.\n\n#### Two categorical variables\n\nWe can use stacked bar plots to visualize the relationship between two categorical variables. For example, the following two stacked bar plots both display the relationship between `island` and `species`, or specifically, visualizing the distribution of `species` within each island.\n\nThe first plot shows the frequencies of each species of penguins on each island. The plot of frequencies shows that there are equal numbers of Adelies on each island. But we don’t have a good sense of the percentage balance within each island.\n\n::: {#2f2f1cc1 .cell execution_count=29}\n``` {.python .cell-code}\npx.bar(penguins, x=\"island\", color=\"species\")\n```\n\n::: {.cell-output .cell-output-display}\n```{=html}\n<iframe\n    scrolling=\"no\"\n    width=\"100%\"\n    height=\"545px\"\n    src=\"iframe_figures/figure_29.html\"\n    frameborder=\"0\"\n    allowfullscreen\n></iframe>\n```\n:::\n:::\n\n\nor\n\n::: {#53addb58 .cell execution_count=30}\n``` {.python .cell-code}\ndata = penguins.group_by([\"island\", \"species\"]).len(\"count\")\ndata_order = data.group_by(\"island\").agg(pl.col(\"count\").sum()).sort(by=\"count\", descending=True).get_column(\"island\")\n\n\npx.bar(\n    data, x=\"island\", y=\"count\", color=\"species\",\n    category_orders = {\"island\": data_order, \"species\": data_order}\n)\n```\n\n::: {.cell-output .cell-output-display}\n```{=html}\n<iframe\n    scrolling=\"no\"\n    width=\"100%\"\n    height=\"545px\"\n    src=\"iframe_figures/figure_30.html\"\n    frameborder=\"0\"\n    allowfullscreen\n></iframe>\n```\n:::\n:::\n\n\n#### Two numerical variables\n\nSo far we've seen scatter plots for visualizing the relationship between two numerical variables. A scatter plot is probably the most commonly used plot for visualizing the relationship between to numerical variables.\n\n::: {#e28b25b7 .cell execution_count=31}\n``` {.python .cell-code}\npx.scatter(penguins, x=\"flipper_length_mm\", y=\"body_mass_g\")\n```\n\n::: {.cell-output .cell-output-display}\n```{=html}\n<iframe\n    scrolling=\"no\"\n    width=\"100%\"\n    height=\"545px\"\n    src=\"iframe_figures/figure_31.html\"\n    frameborder=\"0\"\n    allowfullscreen\n></iframe>\n```\n:::\n:::\n\n\n#### Three or more variables\n\nAs we saw before, we can incorporate more variables into a plot by mapping them to additional aesthetics. For example, in the following plot, the colors of points represent species and the shapes represent islands.\n\n::: {#b1a6d8ff .cell execution_count=32}\n``` {.python .cell-code}\npx.scatter(\n    penguins, \n    x=\"flipper_length_mm\", y=\"body_mass_g\",\n    color=\"species\", symbol=\"island\"\n)\n```\n\n::: {.cell-output .cell-output-display}\n```{=html}\n<iframe\n    scrolling=\"no\"\n    width=\"100%\"\n    height=\"545px\"\n    src=\"iframe_figures/figure_32.html\"\n    frameborder=\"0\"\n    allowfullscreen\n></iframe>\n```\n:::\n:::\n\n\nHowever adding too many aesthetic mappings to a plot makes it cluttered and difficult to make sense of. Another way, which is particularly useful for categorical variables, is to split your plot into **facets**, subplots that each display one subset of the data.\n\nMost Plotly Express functions provide arguments to facet, just make sure to check the documentation.\n\n::: {#3499d3e3 .cell execution_count=33}\n``` {.python .cell-code}\npx.scatter(\n    penguins, \n    x=\"flipper_length_mm\", y=\"body_mass_g\",\n    color=\"species\", symbol=\"island\",\n    facet_col=\"island\"\n)\n```\n\n::: {.cell-output .cell-output-display}\n```{=html}\n<iframe\n    scrolling=\"no\"\n    width=\"100%\"\n    height=\"545px\"\n    src=\"iframe_figures/figure_33.html\"\n    frameborder=\"0\"\n    allowfullscreen\n></iframe>\n```\n:::\n:::\n\n\n### Summary\n\nIn this section, you’ve learned the basics of data visualization with Plotly Express. We started with the basic idea that underpins Plotly Express: a visualization is a mapping from variables in your data to aesthetic properties like position, color, size and shape. You then learned about increasing the complexity with more arguments in the Plotly functions. You also learned about commonly used plots for visualizing the distribution of a single variable as well as for visualizing relationships between two or more variables, by leveraging additional aesthetic mappings and/or splitting your plot into small multiples using faceting.\n\n## Data transformation\n\nVisualization is an important tool for generating insight, but it’s rare that you get the data in exactly the right form you need to make the graph you want. Often you’ll need to create some new variables or summaries to answer your questions with your data, or maybe you just want to rename the variables or reorder the observations to make the data a little easier to work with. We've already seen examples of this above when creating the bar charts. In this section, we'll see how to do that with the [Polars](https://docs.pola.rs/) package.\n\nThe goal of this section is to give you an overview of all the key tools for transforming a data frame. We’ll start with functions that operate on rows and then columns of a data frame, then circle back to talk more about method chaining, an important tool that you use to combine functions. We will then introduce the ability to work with groups. We will end the section with a case study that showcases these functions in action.\n\n### The `flights` data frame\n\nTo explore basic Polars methods and expressions, we will use the `flights` data frame from the `nycflights13` package. This dataset contains all 336,776 flights that departed from New York City in 2013.\n\n::: {#6d9c1dba .cell execution_count=34}\n``` {.python .cell-code}\nimport nycflights13\nimport polars as pl\n\nflights = (\n    pl\n    .from_pandas(nycflights13.flights)\n    .with_columns(pl.col(\"time_hour\").str.to_datetime(\"%FT%TZ\"))\n) # We will learn what's going on here in later this section\n\nflights\n```\n\n::: {.cell-output .cell-output-display execution_count=34}\n```{=html}\n<div><style>\n.dataframe > thead > tr,\n.dataframe > tbody > tr {\n  text-align: right;\n  white-space: pre-wrap;\n}\n</style>\n<small>shape: (336_776, 19)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>year</th><th>month</th><th>day</th><th>dep_time</th><th>sched_dep_time</th><th>dep_delay</th><th>arr_time</th><th>sched_arr_time</th><th>arr_delay</th><th>carrier</th><th>flight</th><th>tailnum</th><th>origin</th><th>dest</th><th>air_time</th><th>distance</th><th>hour</th><th>minute</th><th>time_hour</th></tr><tr><td>i64</td><td>i64</td><td>i64</td><td>f64</td><td>i64</td><td>f64</td><td>f64</td><td>i64</td><td>f64</td><td>str</td><td>i64</td><td>str</td><td>str</td><td>str</td><td>f64</td><td>i64</td><td>i64</td><td>i64</td><td>datetime[μs]</td></tr></thead><tbody><tr><td>2013</td><td>1</td><td>1</td><td>517.0</td><td>515</td><td>2.0</td><td>830.0</td><td>819</td><td>11.0</td><td>&quot;UA&quot;</td><td>1545</td><td>&quot;N14228&quot;</td><td>&quot;EWR&quot;</td><td>&quot;IAH&quot;</td><td>227.0</td><td>1400</td><td>5</td><td>15</td><td>2013-01-01 10:00:00</td></tr><tr><td>2013</td><td>1</td><td>1</td><td>533.0</td><td>529</td><td>4.0</td><td>850.0</td><td>830</td><td>20.0</td><td>&quot;UA&quot;</td><td>1714</td><td>&quot;N24211&quot;</td><td>&quot;LGA&quot;</td><td>&quot;IAH&quot;</td><td>227.0</td><td>1416</td><td>5</td><td>29</td><td>2013-01-01 10:00:00</td></tr><tr><td>2013</td><td>1</td><td>1</td><td>542.0</td><td>540</td><td>2.0</td><td>923.0</td><td>850</td><td>33.0</td><td>&quot;AA&quot;</td><td>1141</td><td>&quot;N619AA&quot;</td><td>&quot;JFK&quot;</td><td>&quot;MIA&quot;</td><td>160.0</td><td>1089</td><td>5</td><td>40</td><td>2013-01-01 10:00:00</td></tr><tr><td>2013</td><td>1</td><td>1</td><td>544.0</td><td>545</td><td>-1.0</td><td>1004.0</td><td>1022</td><td>-18.0</td><td>&quot;B6&quot;</td><td>725</td><td>&quot;N804JB&quot;</td><td>&quot;JFK&quot;</td><td>&quot;BQN&quot;</td><td>183.0</td><td>1576</td><td>5</td><td>45</td><td>2013-01-01 10:00:00</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>2013</td><td>9</td><td>30</td><td>null</td><td>2200</td><td>null</td><td>null</td><td>2312</td><td>null</td><td>&quot;9E&quot;</td><td>3525</td><td>null</td><td>&quot;LGA&quot;</td><td>&quot;SYR&quot;</td><td>null</td><td>198</td><td>22</td><td>0</td><td>2013-10-01 02:00:00</td></tr><tr><td>2013</td><td>9</td><td>30</td><td>null</td><td>1210</td><td>null</td><td>null</td><td>1330</td><td>null</td><td>&quot;MQ&quot;</td><td>3461</td><td>&quot;N535MQ&quot;</td><td>&quot;LGA&quot;</td><td>&quot;BNA&quot;</td><td>null</td><td>764</td><td>12</td><td>10</td><td>2013-09-30 16:00:00</td></tr><tr><td>2013</td><td>9</td><td>30</td><td>null</td><td>1159</td><td>null</td><td>null</td><td>1344</td><td>null</td><td>&quot;MQ&quot;</td><td>3572</td><td>&quot;N511MQ&quot;</td><td>&quot;LGA&quot;</td><td>&quot;CLE&quot;</td><td>null</td><td>419</td><td>11</td><td>59</td><td>2013-09-30 15:00:00</td></tr><tr><td>2013</td><td>9</td><td>30</td><td>null</td><td>840</td><td>null</td><td>null</td><td>1020</td><td>null</td><td>&quot;MQ&quot;</td><td>3531</td><td>&quot;N839MQ&quot;</td><td>&quot;LGA&quot;</td><td>&quot;RDU&quot;</td><td>null</td><td>431</td><td>8</td><td>40</td><td>2013-09-30 12:00:00</td></tr></tbody></table></div>\n```\n:::\n:::\n\n\n`flights` is a Polars [`DataFrame`](https://docs.pola.rs/api/python/stable/reference/dataframe/index.html). Different packages have their own version of a data frame with their own methods, functions, etc., but in this course, we will be using Polars. Polars provides its own way of working with data frames, as well as importing, exporting, printing, and much more, including the previously shown `DataFrame.glimpse()` method:\n\n::: {#1832f7d3 .cell execution_count=35}\n``` {.python .cell-code}\nflights.glimpse()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRows: 336776\nColumns: 19\n$ year                    <i64> 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013\n$ month                   <i64> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1\n$ day                     <i64> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1\n$ dep_time                <f64> 517.0, 533.0, 542.0, 544.0, 554.0, 554.0, 555.0, 557.0, 557.0, 558.0\n$ sched_dep_time          <i64> 515, 529, 540, 545, 600, 558, 600, 600, 600, 600\n$ dep_delay               <f64> 2.0, 4.0, 2.0, -1.0, -6.0, -4.0, -5.0, -3.0, -3.0, -2.0\n$ arr_time                <f64> 830.0, 850.0, 923.0, 1004.0, 812.0, 740.0, 913.0, 709.0, 838.0, 753.0\n$ sched_arr_time          <i64> 819, 830, 850, 1022, 837, 728, 854, 723, 846, 745\n$ arr_delay               <f64> 11.0, 20.0, 33.0, -18.0, -25.0, 12.0, 19.0, -14.0, -8.0, 8.0\n$ carrier                 <str> 'UA', 'UA', 'AA', 'B6', 'DL', 'UA', 'B6', 'EV', 'B6', 'AA'\n$ flight                  <i64> 1545, 1714, 1141, 725, 461, 1696, 507, 5708, 79, 301\n$ tailnum                 <str> 'N14228', 'N24211', 'N619AA', 'N804JB', 'N668DN', 'N39463', 'N516JB', 'N829AS', 'N593JB', 'N3ALAA'\n$ origin                  <str> 'EWR', 'LGA', 'JFK', 'JFK', 'LGA', 'EWR', 'EWR', 'LGA', 'JFK', 'LGA'\n$ dest                    <str> 'IAH', 'IAH', 'MIA', 'BQN', 'ATL', 'ORD', 'FLL', 'IAD', 'MCO', 'ORD'\n$ air_time                <f64> 227.0, 227.0, 160.0, 183.0, 116.0, 150.0, 158.0, 53.0, 140.0, 138.0\n$ distance                <i64> 1400, 1416, 1089, 1576, 762, 719, 1065, 229, 944, 733\n$ hour                    <i64> 5, 5, 5, 5, 6, 5, 6, 6, 6, 6\n$ minute                  <i64> 15, 29, 40, 45, 0, 58, 0, 0, 0, 0\n$ time_hour      <datetime[μs]> 2013-01-01 10:00:00, 2013-01-01 10:00:00, 2013-01-01 10:00:00, 2013-01-01 10:00:00, 2013-01-01 11:00:00, 2013-01-01 10:00:00, 2013-01-01 11:00:00, 2013-01-01 11:00:00, 2013-01-01 11:00:00, 2013-01-01 11:00:00\n\n```\n:::\n:::\n\n\nIn both views, the variable names are followed by abbreviations that tell you the type of each variable: `i64` is short for integer, `f64` is short for float, `str` is short for string, and `datetime[μs]` for date-time (in this case, down to the micro-seconds).\n\nWe're going to learn the primary methods (or contexts as Polars calls them) which will allow yo uto solve the vast majority of your data manipulation challenges. Before we discuss their individual differences, it's worth stating what they have in common:\n\n1. The methods are always attached (or chained) to a data frame.\n2. The arguments typically describe which columns to operate on.\n3. The output is a new data frame (for the most part, ex: `group_by`).\n\nBecause each method does one thing well, solving complex problems will usually require combining multiple methods, and we will do so with something called \"method chaining\". You've already seen this before, this is when we attach multiple methods together without creating a placeholder variable between steps. You can think of each `.` operator of saying \"then\". This should help you get a sense of the following code without understanding the details:\n\n::: {#a4aceb22 .cell execution_count=36}\n``` {.python .cell-code}\nflights.filter(\n    pl.col(\"dest\") == \"IAH\"\n).group_by(\n    [\"year\", \"month\", \"day\"]\n).agg( # \"aggregate\", or summarize\n    arr_delay=pl.col(\"arr_delay\").mean()\n)\n```\n\n::: {.cell-output .cell-output-display execution_count=36}\n```{=html}\n<div><style>\n.dataframe > thead > tr,\n.dataframe > tbody > tr {\n  text-align: right;\n  white-space: pre-wrap;\n}\n</style>\n<small>shape: (365, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>year</th><th>month</th><th>day</th><th>arr_delay</th></tr><tr><td>i64</td><td>i64</td><td>i64</td><td>f64</td></tr></thead><tbody><tr><td>2013</td><td>11</td><td>27</td><td>-0.73913</td></tr><tr><td>2013</td><td>12</td><td>16</td><td>-8.181818</td></tr><tr><td>2013</td><td>9</td><td>11</td><td>-20.55</td></tr><tr><td>2013</td><td>8</td><td>3</td><td>-3.944444</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>2013</td><td>2</td><td>22</td><td>7.35</td></tr><tr><td>2013</td><td>10</td><td>5</td><td>-12.466667</td></tr><tr><td>2013</td><td>10</td><td>29</td><td>1.0</td></tr><tr><td>2013</td><td>10</td><td>30</td><td>9.571429</td></tr></tbody></table></div>\n```\n:::\n:::\n\n\nWe can also write the previous code in a cleaner format. When surrounded by parenthesis, the `.` operator does not have to \"touch\" the closing method before it:\n\n```{.python}\n(\n    flights\n    .filter(pl.col(\"dest\") == \"IAH\")\n    .group_by([\"year\", \"month\", \"day\"])\n    .agg(arr_delay=pl.col(\"arr_delay\").mean())\n)\n```\n\nIf we didn't use method chaining, we would have to create a bunch of intermediate objects:\n\n::: {#48f9278e .cell execution_count=37}\n``` {.python .cell-code}\nflights1 = flights.filter(pl.col(\"dest\") == \"IAH\")\nflights2 = flights1.group_by([\"year\", \"month\", \"day\"])\nflights3 = flights2.agg(arr_delay=pl.col(\"arr_delay\").mean())\n```\n:::\n\n\nWhile all of these have their time and place, method chaining generally produces data analysis code that is easier to write and read.\n\nWe can organize these contexts (methods) based on what they operate on: **rows**, **columns**, **groups**, or **tables**.\n\n### Rows\n\nThe most important contexts that operate on rows of a dataset are `DataFrame.filter()`, which changes which rows are present without changing their order, and `DataFrame.sort()`, which changes the order of the rows without changing which are present. Both methods only affect the rows, and the columns are left unchanged. We'll also see `DataFrame.unique()` which returns rows with unique values. Unlike `DataFrame.sort()` and `DataFrame.filter()`, it can also optionally modify the columns.\n\n#### `DataFrame.filter()`\n\n[`DataFrame.filter()`](https://docs.pola.rs/api/python/stable/reference/dataframe/api/polars.DataFrame.filter.html) allows you to keep rows based on the values of the columns. The arguments (also known as predicates) are the conditions that must be true to keep the row. For example, we could find all flights that departed more than 120 minutes late:\n\n::: {#72cdc5e1 .cell execution_count=38}\n``` {.python .cell-code}\nflights.filter(pl.col(\"dep_delay\") > 120)\n```\n\n::: {.cell-output .cell-output-display execution_count=38}\n```{=html}\n<div><style>\n.dataframe > thead > tr,\n.dataframe > tbody > tr {\n  text-align: right;\n  white-space: pre-wrap;\n}\n</style>\n<small>shape: (9_723, 19)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>year</th><th>month</th><th>day</th><th>dep_time</th><th>sched_dep_time</th><th>dep_delay</th><th>arr_time</th><th>sched_arr_time</th><th>arr_delay</th><th>carrier</th><th>flight</th><th>tailnum</th><th>origin</th><th>dest</th><th>air_time</th><th>distance</th><th>hour</th><th>minute</th><th>time_hour</th></tr><tr><td>i64</td><td>i64</td><td>i64</td><td>f64</td><td>i64</td><td>f64</td><td>f64</td><td>i64</td><td>f64</td><td>str</td><td>i64</td><td>str</td><td>str</td><td>str</td><td>f64</td><td>i64</td><td>i64</td><td>i64</td><td>datetime[μs]</td></tr></thead><tbody><tr><td>2013</td><td>1</td><td>1</td><td>848.0</td><td>1835</td><td>853.0</td><td>1001.0</td><td>1950</td><td>851.0</td><td>&quot;MQ&quot;</td><td>3944</td><td>&quot;N942MQ&quot;</td><td>&quot;JFK&quot;</td><td>&quot;BWI&quot;</td><td>41.0</td><td>184</td><td>18</td><td>35</td><td>2013-01-01 23:00:00</td></tr><tr><td>2013</td><td>1</td><td>1</td><td>957.0</td><td>733</td><td>144.0</td><td>1056.0</td><td>853</td><td>123.0</td><td>&quot;UA&quot;</td><td>856</td><td>&quot;N534UA&quot;</td><td>&quot;EWR&quot;</td><td>&quot;BOS&quot;</td><td>37.0</td><td>200</td><td>7</td><td>33</td><td>2013-01-01 12:00:00</td></tr><tr><td>2013</td><td>1</td><td>1</td><td>1114.0</td><td>900</td><td>134.0</td><td>1447.0</td><td>1222</td><td>145.0</td><td>&quot;UA&quot;</td><td>1086</td><td>&quot;N76502&quot;</td><td>&quot;LGA&quot;</td><td>&quot;IAH&quot;</td><td>248.0</td><td>1416</td><td>9</td><td>0</td><td>2013-01-01 14:00:00</td></tr><tr><td>2013</td><td>1</td><td>1</td><td>1540.0</td><td>1338</td><td>122.0</td><td>2020.0</td><td>1825</td><td>115.0</td><td>&quot;B6&quot;</td><td>705</td><td>&quot;N570JB&quot;</td><td>&quot;JFK&quot;</td><td>&quot;SJU&quot;</td><td>193.0</td><td>1598</td><td>13</td><td>38</td><td>2013-01-01 18:00:00</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>2013</td><td>9</td><td>30</td><td>1951.0</td><td>1649</td><td>182.0</td><td>2157.0</td><td>1903</td><td>174.0</td><td>&quot;EV&quot;</td><td>4294</td><td>&quot;N13988&quot;</td><td>&quot;EWR&quot;</td><td>&quot;SAV&quot;</td><td>95.0</td><td>708</td><td>16</td><td>49</td><td>2013-09-30 20:00:00</td></tr><tr><td>2013</td><td>9</td><td>30</td><td>2053.0</td><td>1815</td><td>158.0</td><td>2310.0</td><td>2054</td><td>136.0</td><td>&quot;EV&quot;</td><td>5292</td><td>&quot;N600QX&quot;</td><td>&quot;EWR&quot;</td><td>&quot;ATL&quot;</td><td>91.0</td><td>746</td><td>18</td><td>15</td><td>2013-09-30 22:00:00</td></tr><tr><td>2013</td><td>9</td><td>30</td><td>2159.0</td><td>1845</td><td>194.0</td><td>2344.0</td><td>2030</td><td>194.0</td><td>&quot;9E&quot;</td><td>3320</td><td>&quot;N906XJ&quot;</td><td>&quot;JFK&quot;</td><td>&quot;BUF&quot;</td><td>50.0</td><td>301</td><td>18</td><td>45</td><td>2013-09-30 22:00:00</td></tr><tr><td>2013</td><td>9</td><td>30</td><td>2235.0</td><td>2001</td><td>154.0</td><td>59.0</td><td>2249</td><td>130.0</td><td>&quot;B6&quot;</td><td>1083</td><td>&quot;N804JB&quot;</td><td>&quot;JFK&quot;</td><td>&quot;MCO&quot;</td><td>123.0</td><td>944</td><td>20</td><td>1</td><td>2013-10-01 00:00:00</td></tr></tbody></table></div>\n```\n:::\n:::\n\n\nWe can use all of the same boolean expressions we've learned previous, as well as chain them with `&` (instead of `and`), `|` (instead of `or`), and `~` (instead of `not`). Note that Polars is picky about ambiguity, so each condition we check for also has it's own parenthesis, similar to what we might use in a calculator to make sure the order of operations is being followed exactly as we want:\n\n::: {#2ad7f0f4 .cell execution_count=39}\n``` {.python .cell-code}\n# Flights that departed on January 1\nflights.filter(\n    (pl.col(\"month\") == 1) & (pl.col(\"day\") == 1)\n)\n```\n\n::: {.cell-output .cell-output-display execution_count=39}\n```{=html}\n<div><style>\n.dataframe > thead > tr,\n.dataframe > tbody > tr {\n  text-align: right;\n  white-space: pre-wrap;\n}\n</style>\n<small>shape: (842, 19)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>year</th><th>month</th><th>day</th><th>dep_time</th><th>sched_dep_time</th><th>dep_delay</th><th>arr_time</th><th>sched_arr_time</th><th>arr_delay</th><th>carrier</th><th>flight</th><th>tailnum</th><th>origin</th><th>dest</th><th>air_time</th><th>distance</th><th>hour</th><th>minute</th><th>time_hour</th></tr><tr><td>i64</td><td>i64</td><td>i64</td><td>f64</td><td>i64</td><td>f64</td><td>f64</td><td>i64</td><td>f64</td><td>str</td><td>i64</td><td>str</td><td>str</td><td>str</td><td>f64</td><td>i64</td><td>i64</td><td>i64</td><td>datetime[μs]</td></tr></thead><tbody><tr><td>2013</td><td>1</td><td>1</td><td>517.0</td><td>515</td><td>2.0</td><td>830.0</td><td>819</td><td>11.0</td><td>&quot;UA&quot;</td><td>1545</td><td>&quot;N14228&quot;</td><td>&quot;EWR&quot;</td><td>&quot;IAH&quot;</td><td>227.0</td><td>1400</td><td>5</td><td>15</td><td>2013-01-01 10:00:00</td></tr><tr><td>2013</td><td>1</td><td>1</td><td>533.0</td><td>529</td><td>4.0</td><td>850.0</td><td>830</td><td>20.0</td><td>&quot;UA&quot;</td><td>1714</td><td>&quot;N24211&quot;</td><td>&quot;LGA&quot;</td><td>&quot;IAH&quot;</td><td>227.0</td><td>1416</td><td>5</td><td>29</td><td>2013-01-01 10:00:00</td></tr><tr><td>2013</td><td>1</td><td>1</td><td>542.0</td><td>540</td><td>2.0</td><td>923.0</td><td>850</td><td>33.0</td><td>&quot;AA&quot;</td><td>1141</td><td>&quot;N619AA&quot;</td><td>&quot;JFK&quot;</td><td>&quot;MIA&quot;</td><td>160.0</td><td>1089</td><td>5</td><td>40</td><td>2013-01-01 10:00:00</td></tr><tr><td>2013</td><td>1</td><td>1</td><td>544.0</td><td>545</td><td>-1.0</td><td>1004.0</td><td>1022</td><td>-18.0</td><td>&quot;B6&quot;</td><td>725</td><td>&quot;N804JB&quot;</td><td>&quot;JFK&quot;</td><td>&quot;BQN&quot;</td><td>183.0</td><td>1576</td><td>5</td><td>45</td><td>2013-01-01 10:00:00</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>2013</td><td>1</td><td>1</td><td>null</td><td>1630</td><td>null</td><td>null</td><td>1815</td><td>null</td><td>&quot;EV&quot;</td><td>4308</td><td>&quot;N18120&quot;</td><td>&quot;EWR&quot;</td><td>&quot;RDU&quot;</td><td>null</td><td>416</td><td>16</td><td>30</td><td>2013-01-01 21:00:00</td></tr><tr><td>2013</td><td>1</td><td>1</td><td>null</td><td>1935</td><td>null</td><td>null</td><td>2240</td><td>null</td><td>&quot;AA&quot;</td><td>791</td><td>&quot;N3EHAA&quot;</td><td>&quot;LGA&quot;</td><td>&quot;DFW&quot;</td><td>null</td><td>1389</td><td>19</td><td>35</td><td>2013-01-02 00:00:00</td></tr><tr><td>2013</td><td>1</td><td>1</td><td>null</td><td>1500</td><td>null</td><td>null</td><td>1825</td><td>null</td><td>&quot;AA&quot;</td><td>1925</td><td>&quot;N3EVAA&quot;</td><td>&quot;LGA&quot;</td><td>&quot;MIA&quot;</td><td>null</td><td>1096</td><td>15</td><td>0</td><td>2013-01-01 20:00:00</td></tr><tr><td>2013</td><td>1</td><td>1</td><td>null</td><td>600</td><td>null</td><td>null</td><td>901</td><td>null</td><td>&quot;B6&quot;</td><td>125</td><td>&quot;N618JB&quot;</td><td>&quot;JFK&quot;</td><td>&quot;FLL&quot;</td><td>null</td><td>1069</td><td>6</td><td>0</td><td>2013-01-01 11:00:00</td></tr></tbody></table></div>\n```\n:::\n:::\n\n\n::: {#11ae13ff .cell execution_count=40}\n``` {.python .cell-code}\n# Flights that departed in January or February\nflights.filter(\n    (pl.col(\"month\") == 1) | (pl.col(\"month\") == 2)\n)\n```\n\n::: {.cell-output .cell-output-display execution_count=40}\n```{=html}\n<div><style>\n.dataframe > thead > tr,\n.dataframe > tbody > tr {\n  text-align: right;\n  white-space: pre-wrap;\n}\n</style>\n<small>shape: (51_955, 19)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>year</th><th>month</th><th>day</th><th>dep_time</th><th>sched_dep_time</th><th>dep_delay</th><th>arr_time</th><th>sched_arr_time</th><th>arr_delay</th><th>carrier</th><th>flight</th><th>tailnum</th><th>origin</th><th>dest</th><th>air_time</th><th>distance</th><th>hour</th><th>minute</th><th>time_hour</th></tr><tr><td>i64</td><td>i64</td><td>i64</td><td>f64</td><td>i64</td><td>f64</td><td>f64</td><td>i64</td><td>f64</td><td>str</td><td>i64</td><td>str</td><td>str</td><td>str</td><td>f64</td><td>i64</td><td>i64</td><td>i64</td><td>datetime[μs]</td></tr></thead><tbody><tr><td>2013</td><td>1</td><td>1</td><td>517.0</td><td>515</td><td>2.0</td><td>830.0</td><td>819</td><td>11.0</td><td>&quot;UA&quot;</td><td>1545</td><td>&quot;N14228&quot;</td><td>&quot;EWR&quot;</td><td>&quot;IAH&quot;</td><td>227.0</td><td>1400</td><td>5</td><td>15</td><td>2013-01-01 10:00:00</td></tr><tr><td>2013</td><td>1</td><td>1</td><td>533.0</td><td>529</td><td>4.0</td><td>850.0</td><td>830</td><td>20.0</td><td>&quot;UA&quot;</td><td>1714</td><td>&quot;N24211&quot;</td><td>&quot;LGA&quot;</td><td>&quot;IAH&quot;</td><td>227.0</td><td>1416</td><td>5</td><td>29</td><td>2013-01-01 10:00:00</td></tr><tr><td>2013</td><td>1</td><td>1</td><td>542.0</td><td>540</td><td>2.0</td><td>923.0</td><td>850</td><td>33.0</td><td>&quot;AA&quot;</td><td>1141</td><td>&quot;N619AA&quot;</td><td>&quot;JFK&quot;</td><td>&quot;MIA&quot;</td><td>160.0</td><td>1089</td><td>5</td><td>40</td><td>2013-01-01 10:00:00</td></tr><tr><td>2013</td><td>1</td><td>1</td><td>544.0</td><td>545</td><td>-1.0</td><td>1004.0</td><td>1022</td><td>-18.0</td><td>&quot;B6&quot;</td><td>725</td><td>&quot;N804JB&quot;</td><td>&quot;JFK&quot;</td><td>&quot;BQN&quot;</td><td>183.0</td><td>1576</td><td>5</td><td>45</td><td>2013-01-01 10:00:00</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>2013</td><td>2</td><td>28</td><td>null</td><td>905</td><td>null</td><td>null</td><td>1115</td><td>null</td><td>&quot;MQ&quot;</td><td>4478</td><td>&quot;N722MQ&quot;</td><td>&quot;LGA&quot;</td><td>&quot;DTW&quot;</td><td>null</td><td>502</td><td>9</td><td>5</td><td>2013-02-28 14:00:00</td></tr><tr><td>2013</td><td>2</td><td>28</td><td>null</td><td>1115</td><td>null</td><td>null</td><td>1310</td><td>null</td><td>&quot;MQ&quot;</td><td>4485</td><td>&quot;N725MQ&quot;</td><td>&quot;LGA&quot;</td><td>&quot;CMH&quot;</td><td>null</td><td>479</td><td>11</td><td>15</td><td>2013-02-28 16:00:00</td></tr><tr><td>2013</td><td>2</td><td>28</td><td>null</td><td>830</td><td>null</td><td>null</td><td>1205</td><td>null</td><td>&quot;UA&quot;</td><td>1480</td><td>null</td><td>&quot;EWR&quot;</td><td>&quot;SFO&quot;</td><td>null</td><td>2565</td><td>8</td><td>30</td><td>2013-02-28 13:00:00</td></tr><tr><td>2013</td><td>2</td><td>28</td><td>null</td><td>840</td><td>null</td><td>null</td><td>1147</td><td>null</td><td>&quot;UA&quot;</td><td>443</td><td>null</td><td>&quot;JFK&quot;</td><td>&quot;LAX&quot;</td><td>null</td><td>2475</td><td>8</td><td>40</td><td>2013-02-28 13:00:00</td></tr></tbody></table></div>\n```\n:::\n:::\n\n\nThere's a useful shortcut when you're combining `|` and `==`: `Expr.is_in()`. It keeps rows where the variable equals one of the values on the right:\n\n::: {#5e8d2395 .cell execution_count=41}\n``` {.python .cell-code}\n# A shorter way to select flights that departed in January or February\nflights.filter(\n    pl.col(\"month\").is_in([1, 2])\n)\n```\n\n::: {.cell-output .cell-output-display execution_count=41}\n```{=html}\n<div><style>\n.dataframe > thead > tr,\n.dataframe > tbody > tr {\n  text-align: right;\n  white-space: pre-wrap;\n}\n</style>\n<small>shape: (51_955, 19)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>year</th><th>month</th><th>day</th><th>dep_time</th><th>sched_dep_time</th><th>dep_delay</th><th>arr_time</th><th>sched_arr_time</th><th>arr_delay</th><th>carrier</th><th>flight</th><th>tailnum</th><th>origin</th><th>dest</th><th>air_time</th><th>distance</th><th>hour</th><th>minute</th><th>time_hour</th></tr><tr><td>i64</td><td>i64</td><td>i64</td><td>f64</td><td>i64</td><td>f64</td><td>f64</td><td>i64</td><td>f64</td><td>str</td><td>i64</td><td>str</td><td>str</td><td>str</td><td>f64</td><td>i64</td><td>i64</td><td>i64</td><td>datetime[μs]</td></tr></thead><tbody><tr><td>2013</td><td>1</td><td>1</td><td>517.0</td><td>515</td><td>2.0</td><td>830.0</td><td>819</td><td>11.0</td><td>&quot;UA&quot;</td><td>1545</td><td>&quot;N14228&quot;</td><td>&quot;EWR&quot;</td><td>&quot;IAH&quot;</td><td>227.0</td><td>1400</td><td>5</td><td>15</td><td>2013-01-01 10:00:00</td></tr><tr><td>2013</td><td>1</td><td>1</td><td>533.0</td><td>529</td><td>4.0</td><td>850.0</td><td>830</td><td>20.0</td><td>&quot;UA&quot;</td><td>1714</td><td>&quot;N24211&quot;</td><td>&quot;LGA&quot;</td><td>&quot;IAH&quot;</td><td>227.0</td><td>1416</td><td>5</td><td>29</td><td>2013-01-01 10:00:00</td></tr><tr><td>2013</td><td>1</td><td>1</td><td>542.0</td><td>540</td><td>2.0</td><td>923.0</td><td>850</td><td>33.0</td><td>&quot;AA&quot;</td><td>1141</td><td>&quot;N619AA&quot;</td><td>&quot;JFK&quot;</td><td>&quot;MIA&quot;</td><td>160.0</td><td>1089</td><td>5</td><td>40</td><td>2013-01-01 10:00:00</td></tr><tr><td>2013</td><td>1</td><td>1</td><td>544.0</td><td>545</td><td>-1.0</td><td>1004.0</td><td>1022</td><td>-18.0</td><td>&quot;B6&quot;</td><td>725</td><td>&quot;N804JB&quot;</td><td>&quot;JFK&quot;</td><td>&quot;BQN&quot;</td><td>183.0</td><td>1576</td><td>5</td><td>45</td><td>2013-01-01 10:00:00</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>2013</td><td>2</td><td>28</td><td>null</td><td>905</td><td>null</td><td>null</td><td>1115</td><td>null</td><td>&quot;MQ&quot;</td><td>4478</td><td>&quot;N722MQ&quot;</td><td>&quot;LGA&quot;</td><td>&quot;DTW&quot;</td><td>null</td><td>502</td><td>9</td><td>5</td><td>2013-02-28 14:00:00</td></tr><tr><td>2013</td><td>2</td><td>28</td><td>null</td><td>1115</td><td>null</td><td>null</td><td>1310</td><td>null</td><td>&quot;MQ&quot;</td><td>4485</td><td>&quot;N725MQ&quot;</td><td>&quot;LGA&quot;</td><td>&quot;CMH&quot;</td><td>null</td><td>479</td><td>11</td><td>15</td><td>2013-02-28 16:00:00</td></tr><tr><td>2013</td><td>2</td><td>28</td><td>null</td><td>830</td><td>null</td><td>null</td><td>1205</td><td>null</td><td>&quot;UA&quot;</td><td>1480</td><td>null</td><td>&quot;EWR&quot;</td><td>&quot;SFO&quot;</td><td>null</td><td>2565</td><td>8</td><td>30</td><td>2013-02-28 13:00:00</td></tr><tr><td>2013</td><td>2</td><td>28</td><td>null</td><td>840</td><td>null</td><td>null</td><td>1147</td><td>null</td><td>&quot;UA&quot;</td><td>443</td><td>null</td><td>&quot;JFK&quot;</td><td>&quot;LAX&quot;</td><td>null</td><td>2475</td><td>8</td><td>40</td><td>2013-02-28 13:00:00</td></tr></tbody></table></div>\n```\n:::\n:::\n\n\nWhen you run `DataFrame.filter()`, Polars executes the filtering operation, creating a new DataFrame, and then prints it. It doesn't modify the existing `flights` dataset because Polars never modifies the input (unless when explicitly chosen). To save the result, you need to use the assignment operator, `=`:\n\n::: {#990100f0 .cell execution_count=42}\n``` {.python .cell-code}\njan1 = flights.filter((pl.col(\"month\") == 1) & (pl.col(\"day\") == 1))\njan1\n```\n\n::: {.cell-output .cell-output-display execution_count=42}\n```{=html}\n<div><style>\n.dataframe > thead > tr,\n.dataframe > tbody > tr {\n  text-align: right;\n  white-space: pre-wrap;\n}\n</style>\n<small>shape: (842, 19)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>year</th><th>month</th><th>day</th><th>dep_time</th><th>sched_dep_time</th><th>dep_delay</th><th>arr_time</th><th>sched_arr_time</th><th>arr_delay</th><th>carrier</th><th>flight</th><th>tailnum</th><th>origin</th><th>dest</th><th>air_time</th><th>distance</th><th>hour</th><th>minute</th><th>time_hour</th></tr><tr><td>i64</td><td>i64</td><td>i64</td><td>f64</td><td>i64</td><td>f64</td><td>f64</td><td>i64</td><td>f64</td><td>str</td><td>i64</td><td>str</td><td>str</td><td>str</td><td>f64</td><td>i64</td><td>i64</td><td>i64</td><td>datetime[μs]</td></tr></thead><tbody><tr><td>2013</td><td>1</td><td>1</td><td>517.0</td><td>515</td><td>2.0</td><td>830.0</td><td>819</td><td>11.0</td><td>&quot;UA&quot;</td><td>1545</td><td>&quot;N14228&quot;</td><td>&quot;EWR&quot;</td><td>&quot;IAH&quot;</td><td>227.0</td><td>1400</td><td>5</td><td>15</td><td>2013-01-01 10:00:00</td></tr><tr><td>2013</td><td>1</td><td>1</td><td>533.0</td><td>529</td><td>4.0</td><td>850.0</td><td>830</td><td>20.0</td><td>&quot;UA&quot;</td><td>1714</td><td>&quot;N24211&quot;</td><td>&quot;LGA&quot;</td><td>&quot;IAH&quot;</td><td>227.0</td><td>1416</td><td>5</td><td>29</td><td>2013-01-01 10:00:00</td></tr><tr><td>2013</td><td>1</td><td>1</td><td>542.0</td><td>540</td><td>2.0</td><td>923.0</td><td>850</td><td>33.0</td><td>&quot;AA&quot;</td><td>1141</td><td>&quot;N619AA&quot;</td><td>&quot;JFK&quot;</td><td>&quot;MIA&quot;</td><td>160.0</td><td>1089</td><td>5</td><td>40</td><td>2013-01-01 10:00:00</td></tr><tr><td>2013</td><td>1</td><td>1</td><td>544.0</td><td>545</td><td>-1.0</td><td>1004.0</td><td>1022</td><td>-18.0</td><td>&quot;B6&quot;</td><td>725</td><td>&quot;N804JB&quot;</td><td>&quot;JFK&quot;</td><td>&quot;BQN&quot;</td><td>183.0</td><td>1576</td><td>5</td><td>45</td><td>2013-01-01 10:00:00</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>2013</td><td>1</td><td>1</td><td>null</td><td>1630</td><td>null</td><td>null</td><td>1815</td><td>null</td><td>&quot;EV&quot;</td><td>4308</td><td>&quot;N18120&quot;</td><td>&quot;EWR&quot;</td><td>&quot;RDU&quot;</td><td>null</td><td>416</td><td>16</td><td>30</td><td>2013-01-01 21:00:00</td></tr><tr><td>2013</td><td>1</td><td>1</td><td>null</td><td>1935</td><td>null</td><td>null</td><td>2240</td><td>null</td><td>&quot;AA&quot;</td><td>791</td><td>&quot;N3EHAA&quot;</td><td>&quot;LGA&quot;</td><td>&quot;DFW&quot;</td><td>null</td><td>1389</td><td>19</td><td>35</td><td>2013-01-02 00:00:00</td></tr><tr><td>2013</td><td>1</td><td>1</td><td>null</td><td>1500</td><td>null</td><td>null</td><td>1825</td><td>null</td><td>&quot;AA&quot;</td><td>1925</td><td>&quot;N3EVAA&quot;</td><td>&quot;LGA&quot;</td><td>&quot;MIA&quot;</td><td>null</td><td>1096</td><td>15</td><td>0</td><td>2013-01-01 20:00:00</td></tr><tr><td>2013</td><td>1</td><td>1</td><td>null</td><td>600</td><td>null</td><td>null</td><td>901</td><td>null</td><td>&quot;B6&quot;</td><td>125</td><td>&quot;N618JB&quot;</td><td>&quot;JFK&quot;</td><td>&quot;FLL&quot;</td><td>null</td><td>1069</td><td>6</td><td>0</td><td>2013-01-01 11:00:00</td></tr></tbody></table></div>\n```\n:::\n:::\n\n\n#### `DataFrame.sort()`\n\n[`DataFrame.sort()`](https://docs.pola.rs/api/python/stable/reference/dataframe/api/polars.DataFrame.sort.html) changes the order of the rows based on the value of the columns. It takes a data frame and a set of column names (or more complicated expressions) to order by. If you provide more than one column name, each additional column will be used to break ties in the values of the preceding columns. For example, the following code sorts by the departure time, which is spread over four columns. We get the earliest years first, then within a year, the earliest months, etc.\n\n::: {#f1725506 .cell execution_count=43}\n``` {.python .cell-code}\nflights.sort(by=[\"year\", \"month\", \"day\", \"dep_time\"])\n```\n\n::: {.cell-output .cell-output-display execution_count=43}\n```{=html}\n<div><style>\n.dataframe > thead > tr,\n.dataframe > tbody > tr {\n  text-align: right;\n  white-space: pre-wrap;\n}\n</style>\n<small>shape: (336_776, 19)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>year</th><th>month</th><th>day</th><th>dep_time</th><th>sched_dep_time</th><th>dep_delay</th><th>arr_time</th><th>sched_arr_time</th><th>arr_delay</th><th>carrier</th><th>flight</th><th>tailnum</th><th>origin</th><th>dest</th><th>air_time</th><th>distance</th><th>hour</th><th>minute</th><th>time_hour</th></tr><tr><td>i64</td><td>i64</td><td>i64</td><td>f64</td><td>i64</td><td>f64</td><td>f64</td><td>i64</td><td>f64</td><td>str</td><td>i64</td><td>str</td><td>str</td><td>str</td><td>f64</td><td>i64</td><td>i64</td><td>i64</td><td>datetime[μs]</td></tr></thead><tbody><tr><td>2013</td><td>1</td><td>1</td><td>null</td><td>1935</td><td>null</td><td>null</td><td>2240</td><td>null</td><td>&quot;AA&quot;</td><td>791</td><td>&quot;N3EHAA&quot;</td><td>&quot;LGA&quot;</td><td>&quot;DFW&quot;</td><td>null</td><td>1389</td><td>19</td><td>35</td><td>2013-01-02 00:00:00</td></tr><tr><td>2013</td><td>1</td><td>1</td><td>null</td><td>1500</td><td>null</td><td>null</td><td>1825</td><td>null</td><td>&quot;AA&quot;</td><td>1925</td><td>&quot;N3EVAA&quot;</td><td>&quot;LGA&quot;</td><td>&quot;MIA&quot;</td><td>null</td><td>1096</td><td>15</td><td>0</td><td>2013-01-01 20:00:00</td></tr><tr><td>2013</td><td>1</td><td>1</td><td>null</td><td>1630</td><td>null</td><td>null</td><td>1815</td><td>null</td><td>&quot;EV&quot;</td><td>4308</td><td>&quot;N18120&quot;</td><td>&quot;EWR&quot;</td><td>&quot;RDU&quot;</td><td>null</td><td>416</td><td>16</td><td>30</td><td>2013-01-01 21:00:00</td></tr><tr><td>2013</td><td>1</td><td>1</td><td>null</td><td>600</td><td>null</td><td>null</td><td>901</td><td>null</td><td>&quot;B6&quot;</td><td>125</td><td>&quot;N618JB&quot;</td><td>&quot;JFK&quot;</td><td>&quot;FLL&quot;</td><td>null</td><td>1069</td><td>6</td><td>0</td><td>2013-01-01 11:00:00</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>2013</td><td>12</td><td>31</td><td>2328.0</td><td>2330</td><td>-2.0</td><td>412.0</td><td>409</td><td>3.0</td><td>&quot;B6&quot;</td><td>1389</td><td>&quot;N651JB&quot;</td><td>&quot;EWR&quot;</td><td>&quot;SJU&quot;</td><td>198.0</td><td>1608</td><td>23</td><td>30</td><td>2014-01-01 04:00:00</td></tr><tr><td>2013</td><td>12</td><td>31</td><td>2332.0</td><td>2245</td><td>47.0</td><td>58.0</td><td>3</td><td>55.0</td><td>&quot;B6&quot;</td><td>486</td><td>&quot;N334JB&quot;</td><td>&quot;JFK&quot;</td><td>&quot;ROC&quot;</td><td>60.0</td><td>264</td><td>22</td><td>45</td><td>2014-01-01 03:00:00</td></tr><tr><td>2013</td><td>12</td><td>31</td><td>2355.0</td><td>2359</td><td>-4.0</td><td>430.0</td><td>440</td><td>-10.0</td><td>&quot;B6&quot;</td><td>1503</td><td>&quot;N509JB&quot;</td><td>&quot;JFK&quot;</td><td>&quot;SJU&quot;</td><td>195.0</td><td>1598</td><td>23</td><td>59</td><td>2014-01-01 04:00:00</td></tr><tr><td>2013</td><td>12</td><td>31</td><td>2356.0</td><td>2359</td><td>-3.0</td><td>436.0</td><td>445</td><td>-9.0</td><td>&quot;B6&quot;</td><td>745</td><td>&quot;N665JB&quot;</td><td>&quot;JFK&quot;</td><td>&quot;PSE&quot;</td><td>200.0</td><td>1617</td><td>23</td><td>59</td><td>2014-01-01 04:00:00</td></tr></tbody></table></div>\n```\n:::\n:::\n\n\nYou can use positional arguments to sort by multiple columns in the same way:\n\n::: {#fdb169d6 .cell execution_count=44}\n``` {.python .cell-code}\nflights.sort(\n    by=[\"year\", \"month\", \"day\", \"dep_time\"],\n    descending=[False, False, False, True]\n)\n```\n\n::: {.cell-output .cell-output-display execution_count=44}\n```{=html}\n<div><style>\n.dataframe > thead > tr,\n.dataframe > tbody > tr {\n  text-align: right;\n  white-space: pre-wrap;\n}\n</style>\n<small>shape: (336_776, 19)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>year</th><th>month</th><th>day</th><th>dep_time</th><th>sched_dep_time</th><th>dep_delay</th><th>arr_time</th><th>sched_arr_time</th><th>arr_delay</th><th>carrier</th><th>flight</th><th>tailnum</th><th>origin</th><th>dest</th><th>air_time</th><th>distance</th><th>hour</th><th>minute</th><th>time_hour</th></tr><tr><td>i64</td><td>i64</td><td>i64</td><td>f64</td><td>i64</td><td>f64</td><td>f64</td><td>i64</td><td>f64</td><td>str</td><td>i64</td><td>str</td><td>str</td><td>str</td><td>f64</td><td>i64</td><td>i64</td><td>i64</td><td>datetime[μs]</td></tr></thead><tbody><tr><td>2013</td><td>1</td><td>1</td><td>null</td><td>600</td><td>null</td><td>null</td><td>901</td><td>null</td><td>&quot;B6&quot;</td><td>125</td><td>&quot;N618JB&quot;</td><td>&quot;JFK&quot;</td><td>&quot;FLL&quot;</td><td>null</td><td>1069</td><td>6</td><td>0</td><td>2013-01-01 11:00:00</td></tr><tr><td>2013</td><td>1</td><td>1</td><td>null</td><td>1500</td><td>null</td><td>null</td><td>1825</td><td>null</td><td>&quot;AA&quot;</td><td>1925</td><td>&quot;N3EVAA&quot;</td><td>&quot;LGA&quot;</td><td>&quot;MIA&quot;</td><td>null</td><td>1096</td><td>15</td><td>0</td><td>2013-01-01 20:00:00</td></tr><tr><td>2013</td><td>1</td><td>1</td><td>null</td><td>1935</td><td>null</td><td>null</td><td>2240</td><td>null</td><td>&quot;AA&quot;</td><td>791</td><td>&quot;N3EHAA&quot;</td><td>&quot;LGA&quot;</td><td>&quot;DFW&quot;</td><td>null</td><td>1389</td><td>19</td><td>35</td><td>2013-01-02 00:00:00</td></tr><tr><td>2013</td><td>1</td><td>1</td><td>null</td><td>1630</td><td>null</td><td>null</td><td>1815</td><td>null</td><td>&quot;EV&quot;</td><td>4308</td><td>&quot;N18120&quot;</td><td>&quot;EWR&quot;</td><td>&quot;RDU&quot;</td><td>null</td><td>416</td><td>16</td><td>30</td><td>2013-01-01 21:00:00</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>2013</td><td>12</td><td>31</td><td>459.0</td><td>500</td><td>-1.0</td><td>655.0</td><td>651</td><td>4.0</td><td>&quot;US&quot;</td><td>1895</td><td>&quot;N557UW&quot;</td><td>&quot;EWR&quot;</td><td>&quot;CLT&quot;</td><td>95.0</td><td>529</td><td>5</td><td>0</td><td>2013-12-31 10:00:00</td></tr><tr><td>2013</td><td>12</td><td>31</td><td>26.0</td><td>2245</td><td>101.0</td><td>129.0</td><td>2353</td><td>96.0</td><td>&quot;B6&quot;</td><td>108</td><td>&quot;N374JB&quot;</td><td>&quot;JFK&quot;</td><td>&quot;PWM&quot;</td><td>50.0</td><td>273</td><td>22</td><td>45</td><td>2014-01-01 03:00:00</td></tr><tr><td>2013</td><td>12</td><td>31</td><td>18.0</td><td>2359</td><td>19.0</td><td>449.0</td><td>444</td><td>5.0</td><td>&quot;DL&quot;</td><td>412</td><td>&quot;N713TW&quot;</td><td>&quot;JFK&quot;</td><td>&quot;SJU&quot;</td><td>192.0</td><td>1598</td><td>23</td><td>59</td><td>2014-01-01 04:00:00</td></tr><tr><td>2013</td><td>12</td><td>31</td><td>13.0</td><td>2359</td><td>14.0</td><td>439.0</td><td>437</td><td>2.0</td><td>&quot;B6&quot;</td><td>839</td><td>&quot;N566JB&quot;</td><td>&quot;JFK&quot;</td><td>&quot;BQN&quot;</td><td>189.0</td><td>1576</td><td>23</td><td>59</td><td>2014-01-01 04:00:00</td></tr></tbody></table></div>\n```\n:::\n:::\n\n\nNote that the number of rows has not changed, we’re only arranging the data, we’re not filtering it.\n\n#### `DataFrame.unique()`\n\n[`DataFrame.unique()`](https://docs.pola.rs/api/python/stable/reference/dataframe/api/polars.DataFrame.unique.html) finds all the unique rows in a dataset, so technically, it primarily operates on the rows. Most of the time, however, you’ll want the distinct combination of some variables, so you can also optionally supply column names:\n\n::: {#04156ec9 .cell execution_count=45}\n``` {.python .cell-code}\n# Remove duplicate rows, if any\nflights.unique()\n```\n\n::: {.cell-output .cell-output-display execution_count=45}\n```{=html}\n<div><style>\n.dataframe > thead > tr,\n.dataframe > tbody > tr {\n  text-align: right;\n  white-space: pre-wrap;\n}\n</style>\n<small>shape: (336_776, 19)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>year</th><th>month</th><th>day</th><th>dep_time</th><th>sched_dep_time</th><th>dep_delay</th><th>arr_time</th><th>sched_arr_time</th><th>arr_delay</th><th>carrier</th><th>flight</th><th>tailnum</th><th>origin</th><th>dest</th><th>air_time</th><th>distance</th><th>hour</th><th>minute</th><th>time_hour</th></tr><tr><td>i64</td><td>i64</td><td>i64</td><td>f64</td><td>i64</td><td>f64</td><td>f64</td><td>i64</td><td>f64</td><td>str</td><td>i64</td><td>str</td><td>str</td><td>str</td><td>f64</td><td>i64</td><td>i64</td><td>i64</td><td>datetime[μs]</td></tr></thead><tbody><tr><td>2013</td><td>6</td><td>29</td><td>2003.0</td><td>1958</td><td>5.0</td><td>2205.0</td><td>2245</td><td>-40.0</td><td>&quot;UA&quot;</td><td>1555</td><td>&quot;N36207&quot;</td><td>&quot;EWR&quot;</td><td>&quot;SAN&quot;</td><td>289.0</td><td>2425</td><td>19</td><td>58</td><td>2013-06-29 23:00:00</td></tr><tr><td>2013</td><td>8</td><td>30</td><td>539.0</td><td>545</td><td>-6.0</td><td>932.0</td><td>921</td><td>11.0</td><td>&quot;B6&quot;</td><td>939</td><td>&quot;N524JB&quot;</td><td>&quot;JFK&quot;</td><td>&quot;BQN&quot;</td><td>192.0</td><td>1576</td><td>5</td><td>45</td><td>2013-08-30 09:00:00</td></tr><tr><td>2013</td><td>10</td><td>7</td><td>556.0</td><td>600</td><td>-4.0</td><td>702.0</td><td>659</td><td>3.0</td><td>&quot;US&quot;</td><td>2167</td><td>&quot;N766US&quot;</td><td>&quot;LGA&quot;</td><td>&quot;DCA&quot;</td><td>46.0</td><td>214</td><td>6</td><td>0</td><td>2013-10-07 10:00:00</td></tr><tr><td>2013</td><td>2</td><td>13</td><td>1352.0</td><td>1400</td><td>-8.0</td><td>1447.0</td><td>1503</td><td>-16.0</td><td>&quot;US&quot;</td><td>2130</td><td>&quot;N945UW&quot;</td><td>&quot;LGA&quot;</td><td>&quot;BOS&quot;</td><td>38.0</td><td>184</td><td>14</td><td>0</td><td>2013-02-13 19:00:00</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>2013</td><td>5</td><td>8</td><td>1556.0</td><td>1355</td><td>121.0</td><td>1806.0</td><td>1604</td><td>122.0</td><td>&quot;EV&quot;</td><td>4115</td><td>&quot;N14916&quot;</td><td>&quot;EWR&quot;</td><td>&quot;SAV&quot;</td><td>104.0</td><td>708</td><td>13</td><td>55</td><td>2013-05-08 17:00:00</td></tr><tr><td>2013</td><td>9</td><td>24</td><td>1349.0</td><td>1359</td><td>-10.0</td><td>1452.0</td><td>1511</td><td>-19.0</td><td>&quot;B6&quot;</td><td>118</td><td>&quot;N281JB&quot;</td><td>&quot;JFK&quot;</td><td>&quot;BOS&quot;</td><td>40.0</td><td>187</td><td>13</td><td>59</td><td>2013-09-24 17:00:00</td></tr><tr><td>2013</td><td>8</td><td>3</td><td>2151.0</td><td>2150</td><td>1.0</td><td>38.0</td><td>45</td><td>-7.0</td><td>&quot;B6&quot;</td><td>1201</td><td>&quot;N729JB&quot;</td><td>&quot;JFK&quot;</td><td>&quot;FLL&quot;</td><td>137.0</td><td>1069</td><td>21</td><td>50</td><td>2013-08-04 01:00:00</td></tr><tr><td>2013</td><td>3</td><td>19</td><td>1600.0</td><td>1600</td><td>0.0</td><td>1841.0</td><td>1838</td><td>3.0</td><td>&quot;DL&quot;</td><td>847</td><td>&quot;N648DL&quot;</td><td>&quot;LGA&quot;</td><td>&quot;ATL&quot;</td><td>116.0</td><td>762</td><td>16</td><td>0</td><td>2013-03-19 20:00:00</td></tr></tbody></table></div>\n```\n:::\n:::\n\n\n::: {#48021528 .cell execution_count=46}\n``` {.python .cell-code}\n# Find all unique origin and destination pairs\nflights.unique(subset=[\"origin\", \"dest\"])\n```\n\n::: {.cell-output .cell-output-display execution_count=46}\n```{=html}\n<div><style>\n.dataframe > thead > tr,\n.dataframe > tbody > tr {\n  text-align: right;\n  white-space: pre-wrap;\n}\n</style>\n<small>shape: (224, 19)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>year</th><th>month</th><th>day</th><th>dep_time</th><th>sched_dep_time</th><th>dep_delay</th><th>arr_time</th><th>sched_arr_time</th><th>arr_delay</th><th>carrier</th><th>flight</th><th>tailnum</th><th>origin</th><th>dest</th><th>air_time</th><th>distance</th><th>hour</th><th>minute</th><th>time_hour</th></tr><tr><td>i64</td><td>i64</td><td>i64</td><td>f64</td><td>i64</td><td>f64</td><td>f64</td><td>i64</td><td>f64</td><td>str</td><td>i64</td><td>str</td><td>str</td><td>str</td><td>f64</td><td>i64</td><td>i64</td><td>i64</td><td>datetime[μs]</td></tr></thead><tbody><tr><td>2013</td><td>1</td><td>1</td><td>1353.0</td><td>1357</td><td>-4.0</td><td>1549.0</td><td>1525</td><td>24.0</td><td>&quot;EV&quot;</td><td>4171</td><td>&quot;N14105&quot;</td><td>&quot;EWR&quot;</td><td>&quot;MSN&quot;</td><td>152.0</td><td>799</td><td>13</td><td>57</td><td>2013-01-01 18:00:00</td></tr><tr><td>2013</td><td>1</td><td>1</td><td>1522.0</td><td>1530</td><td>-8.0</td><td>1731.0</td><td>1725</td><td>6.0</td><td>&quot;MQ&quot;</td><td>4146</td><td>&quot;N902MQ&quot;</td><td>&quot;JFK&quot;</td><td>&quot;CMH&quot;</td><td>98.0</td><td>483</td><td>15</td><td>30</td><td>2013-01-01 20:00:00</td></tr><tr><td>2013</td><td>1</td><td>2</td><td>2044.0</td><td>2005</td><td>39.0</td><td>2229.0</td><td>2158</td><td>31.0</td><td>&quot;EV&quot;</td><td>5114</td><td>&quot;N371CA&quot;</td><td>&quot;LGA&quot;</td><td>&quot;BHM&quot;</td><td>143.0</td><td>866</td><td>20</td><td>5</td><td>2013-01-03 01:00:00</td></tr><tr><td>2013</td><td>1</td><td>1</td><td>914.0</td><td>900</td><td>14.0</td><td>1058.0</td><td>1043</td><td>15.0</td><td>&quot;UA&quot;</td><td>783</td><td>&quot;N810UA&quot;</td><td>&quot;EWR&quot;</td><td>&quot;CLE&quot;</td><td>85.0</td><td>404</td><td>9</td><td>0</td><td>2013-01-01 14:00:00</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>2013</td><td>1</td><td>1</td><td>615.0</td><td>615</td><td>0.0</td><td>833.0</td><td>842</td><td>-9.0</td><td>&quot;DL&quot;</td><td>575</td><td>&quot;N326NB&quot;</td><td>&quot;EWR&quot;</td><td>&quot;ATL&quot;</td><td>120.0</td><td>746</td><td>6</td><td>15</td><td>2013-01-01 11:00:00</td></tr><tr><td>2013</td><td>11</td><td>2</td><td>1519.0</td><td>1459</td><td>20.0</td><td>1654.0</td><td>1702</td><td>-8.0</td><td>&quot;DL&quot;</td><td>567</td><td>&quot;N329NB&quot;</td><td>&quot;JFK&quot;</td><td>&quot;STL&quot;</td><td>129.0</td><td>892</td><td>14</td><td>59</td><td>2013-11-02 18:00:00</td></tr><tr><td>2013</td><td>10</td><td>1</td><td>955.0</td><td>1000</td><td>-5.0</td><td>1156.0</td><td>1234</td><td>-38.0</td><td>&quot;9E&quot;</td><td>3574</td><td>&quot;N913XJ&quot;</td><td>&quot;LGA&quot;</td><td>&quot;IND&quot;</td><td>93.0</td><td>660</td><td>10</td><td>0</td><td>2013-10-01 14:00:00</td></tr><tr><td>2013</td><td>1</td><td>1</td><td>2016.0</td><td>1930</td><td>46.0</td><td>null</td><td>2220</td><td>null</td><td>&quot;EV&quot;</td><td>4204</td><td>&quot;N14168&quot;</td><td>&quot;EWR&quot;</td><td>&quot;OKC&quot;</td><td>null</td><td>1325</td><td>19</td><td>30</td><td>2013-01-02 00:00:00</td></tr></tbody></table></div>\n```\n:::\n:::\n\n\nIt should be noted that the default argument for `keep` is `any`, which **does not give any guarantee of which unique rows are kept**. If you dataset is ordered, you might want to use one of the other options for `keep`.\n\nIf you want the number of occurrences instead, you'll need to use a combination of `DataFrame.group_by` along with a `GroupBy.agg()`.\n\n### Columns\n\nThere are two important contexts that affect the columns without changing the rows: `DataFrame.with_columns()`, which creates new columns that are derived from the existing columns, & `select()`, which changes which columns are present.\n\n#### `DataFrame.with_columns()`\n\nThe job of [`DataFrame.with_columns()`](https://docs.pola.rs/api/python/stable/reference/dataframe/api/polars.DataFrame.with_columns.html) is to add new columns. In the Data Wrangling module, you will learn a large set of functions that you can use to manipulate different types of variables. For new, we'll stick with basic algebra, which allows us to compute the `gain`, how much time a delayed flight made up in the air, and the `speed` in miles per hour:\n\n::: {#e1e934ce .cell execution_count=47}\n``` {.python .cell-code}\nflights.with_columns(\n    gain = pl.col(\"dep_delay\") - pl.col(\"arr_delay\"),\n    speed = pl.col(\"distance\") / pl.col(\"air_time\") * 60\n)\n```\n\n::: {.cell-output .cell-output-display execution_count=47}\n```{=html}\n<div><style>\n.dataframe > thead > tr,\n.dataframe > tbody > tr {\n  text-align: right;\n  white-space: pre-wrap;\n}\n</style>\n<small>shape: (336_776, 21)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>year</th><th>month</th><th>day</th><th>dep_time</th><th>sched_dep_time</th><th>dep_delay</th><th>arr_time</th><th>sched_arr_time</th><th>arr_delay</th><th>carrier</th><th>flight</th><th>tailnum</th><th>origin</th><th>dest</th><th>air_time</th><th>distance</th><th>hour</th><th>minute</th><th>time_hour</th><th>gain</th><th>speed</th></tr><tr><td>i64</td><td>i64</td><td>i64</td><td>f64</td><td>i64</td><td>f64</td><td>f64</td><td>i64</td><td>f64</td><td>str</td><td>i64</td><td>str</td><td>str</td><td>str</td><td>f64</td><td>i64</td><td>i64</td><td>i64</td><td>datetime[μs]</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>2013</td><td>1</td><td>1</td><td>517.0</td><td>515</td><td>2.0</td><td>830.0</td><td>819</td><td>11.0</td><td>&quot;UA&quot;</td><td>1545</td><td>&quot;N14228&quot;</td><td>&quot;EWR&quot;</td><td>&quot;IAH&quot;</td><td>227.0</td><td>1400</td><td>5</td><td>15</td><td>2013-01-01 10:00:00</td><td>-9.0</td><td>370.044053</td></tr><tr><td>2013</td><td>1</td><td>1</td><td>533.0</td><td>529</td><td>4.0</td><td>850.0</td><td>830</td><td>20.0</td><td>&quot;UA&quot;</td><td>1714</td><td>&quot;N24211&quot;</td><td>&quot;LGA&quot;</td><td>&quot;IAH&quot;</td><td>227.0</td><td>1416</td><td>5</td><td>29</td><td>2013-01-01 10:00:00</td><td>-16.0</td><td>374.273128</td></tr><tr><td>2013</td><td>1</td><td>1</td><td>542.0</td><td>540</td><td>2.0</td><td>923.0</td><td>850</td><td>33.0</td><td>&quot;AA&quot;</td><td>1141</td><td>&quot;N619AA&quot;</td><td>&quot;JFK&quot;</td><td>&quot;MIA&quot;</td><td>160.0</td><td>1089</td><td>5</td><td>40</td><td>2013-01-01 10:00:00</td><td>-31.0</td><td>408.375</td></tr><tr><td>2013</td><td>1</td><td>1</td><td>544.0</td><td>545</td><td>-1.0</td><td>1004.0</td><td>1022</td><td>-18.0</td><td>&quot;B6&quot;</td><td>725</td><td>&quot;N804JB&quot;</td><td>&quot;JFK&quot;</td><td>&quot;BQN&quot;</td><td>183.0</td><td>1576</td><td>5</td><td>45</td><td>2013-01-01 10:00:00</td><td>17.0</td><td>516.721311</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>2013</td><td>9</td><td>30</td><td>null</td><td>2200</td><td>null</td><td>null</td><td>2312</td><td>null</td><td>&quot;9E&quot;</td><td>3525</td><td>null</td><td>&quot;LGA&quot;</td><td>&quot;SYR&quot;</td><td>null</td><td>198</td><td>22</td><td>0</td><td>2013-10-01 02:00:00</td><td>null</td><td>null</td></tr><tr><td>2013</td><td>9</td><td>30</td><td>null</td><td>1210</td><td>null</td><td>null</td><td>1330</td><td>null</td><td>&quot;MQ&quot;</td><td>3461</td><td>&quot;N535MQ&quot;</td><td>&quot;LGA&quot;</td><td>&quot;BNA&quot;</td><td>null</td><td>764</td><td>12</td><td>10</td><td>2013-09-30 16:00:00</td><td>null</td><td>null</td></tr><tr><td>2013</td><td>9</td><td>30</td><td>null</td><td>1159</td><td>null</td><td>null</td><td>1344</td><td>null</td><td>&quot;MQ&quot;</td><td>3572</td><td>&quot;N511MQ&quot;</td><td>&quot;LGA&quot;</td><td>&quot;CLE&quot;</td><td>null</td><td>419</td><td>11</td><td>59</td><td>2013-09-30 15:00:00</td><td>null</td><td>null</td></tr><tr><td>2013</td><td>9</td><td>30</td><td>null</td><td>840</td><td>null</td><td>null</td><td>1020</td><td>null</td><td>&quot;MQ&quot;</td><td>3531</td><td>&quot;N839MQ&quot;</td><td>&quot;LGA&quot;</td><td>&quot;RDU&quot;</td><td>null</td><td>431</td><td>8</td><td>40</td><td>2013-09-30 12:00:00</td><td>null</td><td>null</td></tr></tbody></table></div>\n```\n:::\n:::\n\n\nNote that since we haven't assigned the result of the above computation back to `flights`, the new variables `gain` and `speed` will only be printed but will not be stored in a data frame. And if we want them to be available in a data frame for future use, we should think carefully about whether we want the result to be assigned back to `flights`, overwriting the original data frame with many more variables, or to a new object. Often, the right answer is a new object that is named informatively to indicate its contents, e.g., `delay_gain`, but you might also have good reasons for overwriting `flights`.\n\n#### `DataFrame.select()`\n\nIt’s not uncommon to get datasets with hundreds or even thousands of variables. In this situation, the first challenge is often just focusing on the variables you’re interested in. [`DataFrame.select()`](https://docs.pola.rs/api/python/stable/reference/dataframe/api/polars.DataFrame.select.html) allows you to rapidly zoom in on a useful subset using operations based on the names of the variables:\n\n- Select columns by name:\n\n::: {#f11eb25b .cell execution_count=48}\n``` {.python .cell-code}\nflights.select(\"year\")\n```\n\n::: {.cell-output .cell-output-display execution_count=48}\n```{=html}\n<div><style>\n.dataframe > thead > tr,\n.dataframe > tbody > tr {\n  text-align: right;\n  white-space: pre-wrap;\n}\n</style>\n<small>shape: (336_776, 1)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>year</th></tr><tr><td>i64</td></tr></thead><tbody><tr><td>2013</td></tr><tr><td>2013</td></tr><tr><td>2013</td></tr><tr><td>2013</td></tr><tr><td>&hellip;</td></tr><tr><td>2013</td></tr><tr><td>2013</td></tr><tr><td>2013</td></tr><tr><td>2013</td></tr></tbody></table></div>\n```\n:::\n:::\n\n\n- Select multiple columns by passing a list of column names:\n\n::: {#00b712ff .cell execution_count=49}\n``` {.python .cell-code}\nflights.select([\"year\", \"month\", \"day\"])\n```\n\n::: {.cell-output .cell-output-display execution_count=49}\n```{=html}\n<div><style>\n.dataframe > thead > tr,\n.dataframe > tbody > tr {\n  text-align: right;\n  white-space: pre-wrap;\n}\n</style>\n<small>shape: (336_776, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>year</th><th>month</th><th>day</th></tr><tr><td>i64</td><td>i64</td><td>i64</td></tr></thead><tbody><tr><td>2013</td><td>1</td><td>1</td></tr><tr><td>2013</td><td>1</td><td>1</td></tr><tr><td>2013</td><td>1</td><td>1</td></tr><tr><td>2013</td><td>1</td><td>1</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>2013</td><td>9</td><td>30</td></tr><tr><td>2013</td><td>9</td><td>30</td></tr><tr><td>2013</td><td>9</td><td>30</td></tr><tr><td>2013</td><td>9</td><td>30</td></tr></tbody></table></div>\n```\n:::\n:::\n\n\n- Multiple columns can also be selected using positional arguments instead of a list. Expressions are also accepted:\n\n::: {#b350b6c6 .cell execution_count=50}\n``` {.python .cell-code}\nflights.select(\n    pl.col(\"year\"),\n    pl.col(\"month\"),\n    month_add_one = pl.col(\"month\") + 1 # Adds 1 to the values of \"month\"\n)\n```\n\n::: {.cell-output .cell-output-display execution_count=50}\n```{=html}\n<div><style>\n.dataframe > thead > tr,\n.dataframe > tbody > tr {\n  text-align: right;\n  white-space: pre-wrap;\n}\n</style>\n<small>shape: (336_776, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>year</th><th>month</th><th>month_add_one</th></tr><tr><td>i64</td><td>i64</td><td>i64</td></tr></thead><tbody><tr><td>2013</td><td>1</td><td>2</td></tr><tr><td>2013</td><td>1</td><td>2</td></tr><tr><td>2013</td><td>1</td><td>2</td></tr><tr><td>2013</td><td>1</td><td>2</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>2013</td><td>9</td><td>10</td></tr><tr><td>2013</td><td>9</td><td>10</td></tr><tr><td>2013</td><td>9</td><td>10</td></tr><tr><td>2013</td><td>9</td><td>10</td></tr></tbody></table></div>\n```\n:::\n:::\n\n\nPolars also provides more advanced way to select columns using its [Selectors](https://docs.pola.rs/api/python/stable/reference/selectors.html). Selectors allow for more intuitive selection of columns from DataFrame objects based on their name, type, or other properties. They unify and build on the related functionality that is available through the `pl.col()` expression and can also broadcast expressions over the selected columns.\n\nSelectors are available as functions imported from `polars.selectors`. Typical/recommended usage is to import the module as `cs` and employ selectors from there.\n\n::: {#e9b50238 .cell execution_count=51}\n``` {.python .cell-code}\nimport polars.selectors as cs\nimport polars as pl\n```\n:::\n\n\nThere are a number of selectors you can use within select:\n\n- `cs.starts_with(\"abc\")`: matches column names that begin with \"abc\".\n- `cs.ends_with(\"xyz\")`: matches column names that end with \"xyz\".\n- `cs.contains(\"ijk\")`: matches column names that contain \"ijk\".\n- `cs.matches(r\"\\d{3}\")`: matches column names using regex, columns with three digits repeating in the name in this case.\n- `cs.temporal()`: matches columns with temporal (time) data types.\n- `cs.string()`: matches columns with string data types.\n\nThese are just a few, you can see all the selectors with examples in the documentation, or by looking at the options after typing `cs.` in your editor.\n\nYou can combine selectors with the following `set` operations:\n\n| Operation            | Expression |\n|----------------------|------------|\n| UNION                | A \\| B     |\n| INTERSECTION         | A & B      |\n| DIFFERENCE           | A - B      |\n| SYMMETRIC DIFFERENCE | A ^ B      |\n| COMPLEMENT           | ~A         |\n\n::: {#65668abf .cell execution_count=52}\n``` {.python .cell-code}\nflights.select(cs.temporal() | cs.string())\n```\n\n::: {.cell-output .cell-output-display execution_count=52}\n```{=html}\n<div><style>\n.dataframe > thead > tr,\n.dataframe > tbody > tr {\n  text-align: right;\n  white-space: pre-wrap;\n}\n</style>\n<small>shape: (336_776, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>carrier</th><th>tailnum</th><th>origin</th><th>dest</th><th>time_hour</th></tr><tr><td>str</td><td>str</td><td>str</td><td>str</td><td>datetime[μs]</td></tr></thead><tbody><tr><td>&quot;UA&quot;</td><td>&quot;N14228&quot;</td><td>&quot;EWR&quot;</td><td>&quot;IAH&quot;</td><td>2013-01-01 10:00:00</td></tr><tr><td>&quot;UA&quot;</td><td>&quot;N24211&quot;</td><td>&quot;LGA&quot;</td><td>&quot;IAH&quot;</td><td>2013-01-01 10:00:00</td></tr><tr><td>&quot;AA&quot;</td><td>&quot;N619AA&quot;</td><td>&quot;JFK&quot;</td><td>&quot;MIA&quot;</td><td>2013-01-01 10:00:00</td></tr><tr><td>&quot;B6&quot;</td><td>&quot;N804JB&quot;</td><td>&quot;JFK&quot;</td><td>&quot;BQN&quot;</td><td>2013-01-01 10:00:00</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;9E&quot;</td><td>null</td><td>&quot;LGA&quot;</td><td>&quot;SYR&quot;</td><td>2013-10-01 02:00:00</td></tr><tr><td>&quot;MQ&quot;</td><td>&quot;N535MQ&quot;</td><td>&quot;LGA&quot;</td><td>&quot;BNA&quot;</td><td>2013-09-30 16:00:00</td></tr><tr><td>&quot;MQ&quot;</td><td>&quot;N511MQ&quot;</td><td>&quot;LGA&quot;</td><td>&quot;CLE&quot;</td><td>2013-09-30 15:00:00</td></tr><tr><td>&quot;MQ&quot;</td><td>&quot;N839MQ&quot;</td><td>&quot;LGA&quot;</td><td>&quot;RDU&quot;</td><td>2013-09-30 12:00:00</td></tr></tbody></table></div>\n```\n:::\n:::\n\n\nNote that both individual selector results and selector set operations will always return matching columns in the same order as the underlying DataFrame schema.\n\n### Groups\n\nSo far, we've learned about contexts (DataFrame methods) that work with rows and columns. `Polars` gets even more powerful when you add in the ability to work with groups. In this section, we'll focus on the most important contexts: `DataFrame.group_by()`, `DataFrame.agg()`, and the various *slice*-ing contexts.\n\n#### `DataFrame.group_by()`\n\nUse [`DataFrame.group_by()`](https://docs.pola.rs/api/python/stable/reference/dataframe/api/polars.DataFrame.group_by.html) to divide your dataset into groups meaningful for your analysis:\n\n::: {#d50fac1a .cell execution_count=53}\n``` {.python .cell-code}\nflights.group_by(\"month\")\n```\n\n::: {.cell-output .cell-output-display execution_count=53}\n```\n<polars.dataframe.group_by.GroupBy at 0x29dc0cc6ff0>\n```\n:::\n:::\n\n\nAs you can see, `DataFrame.group_by()` doesn't change the data, but returns a [`GroupBy`](https://docs.pola.rs/api/python/stable/reference/dataframe/group_by.html) object. This acts like a `DataFrame`, but subsequent operations will now work \"by month\", and comes with some extra methods.\n\n#### `GroupBy.agg()`\n\nThe most important grouped operation is an aggregation, which, if being used to calculate a single summary statistic, reduces the data frame to have a single row for each group. In Polars, this operation is performed by [`GroupBy.agg()`](https://docs.pola.rs/api/python/stable/reference/dataframe/api/polars.dataframe.group_by.GroupBy.agg.html), as shown by the following example, which computes the average departure delay by month:\n\n::: {#38b3a152 .cell execution_count=54}\n``` {.python .cell-code}\n(\n    flights\n    .group_by(\"month\")\n    .agg(avg_delay = pl.col(\"dep_delay\").mean())\n)\n```\n\n::: {.cell-output .cell-output-display execution_count=54}\n```{=html}\n<div><style>\n.dataframe > thead > tr,\n.dataframe > tbody > tr {\n  text-align: right;\n  white-space: pre-wrap;\n}\n</style>\n<small>shape: (12, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>month</th><th>avg_delay</th></tr><tr><td>i64</td><td>f64</td></tr></thead><tbody><tr><td>1</td><td>10.036665</td></tr><tr><td>10</td><td>6.243988</td></tr><tr><td>12</td><td>16.576688</td></tr><tr><td>6</td><td>20.846332</td></tr><tr><td>&hellip;</td><td>&hellip;</td></tr><tr><td>3</td><td>13.227076</td></tr><tr><td>11</td><td>5.435362</td></tr><tr><td>5</td><td>12.986859</td></tr><tr><td>9</td><td>6.722476</td></tr></tbody></table></div>\n```\n:::\n:::\n\n\nThere are two things to note:\n\n1. Polars automatically drops the missing values in `dep_delay` when calculating the mean.\n2. Polars has a few different methods called `mean()`, but they do different things depending on root object (`DataFrame`, `GroupBy`, `Expr`, etc.)\n\nYou can create any number of aggregations in a single call to `GroupBy.agg()`. You'll learn various useful summaries in later modules, but one very useful summary is `pl.len()`, which returns the number of rows in each group:\n\n::: {#18fcc1fe .cell execution_count=55}\n``` {.python .cell-code}\n(\n    flights\n    .group_by(\"month\")\n    .agg(\n        avg_delay = pl.col(\"dep_delay\").mean(),\n        n = pl.len()\n    )\n    .sort(\"month\")\n)\n```\n\n::: {.cell-output .cell-output-display execution_count=55}\n```{=html}\n<div><style>\n.dataframe > thead > tr,\n.dataframe > tbody > tr {\n  text-align: right;\n  white-space: pre-wrap;\n}\n</style>\n<small>shape: (12, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>month</th><th>avg_delay</th><th>n</th></tr><tr><td>i64</td><td>f64</td><td>u32</td></tr></thead><tbody><tr><td>1</td><td>10.036665</td><td>27004</td></tr><tr><td>2</td><td>10.816843</td><td>24951</td></tr><tr><td>3</td><td>13.227076</td><td>28834</td></tr><tr><td>4</td><td>13.938038</td><td>28330</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>9</td><td>6.722476</td><td>27574</td></tr><tr><td>10</td><td>6.243988</td><td>28889</td></tr><tr><td>11</td><td>5.435362</td><td>27268</td></tr><tr><td>12</td><td>16.576688</td><td>28135</td></tr></tbody></table></div>\n```\n:::\n:::\n\n\nMeans and counts can get you a surprisingly long way in data science!\n\n#### Slicing functions\n\nThere are a few ways Polars provides for you to extract specific rows within each group:\n\n- `GroupBy.head(n = 1)` takes the first row from each group. (Also works with `DataFrame`)\n- `GroupBy.tail(n = 1)` takes the last row from each group. (Also works with `DataFrame`)\n\n`GroupBy` also provides some powerful aggregations for whole groups, like:\n\n::: {#4b9976ba .cell execution_count=56}\n``` {.python .cell-code}\nflights.group_by(\"dest\").max() # shows max value for each group and column\nflights.group_by(\"dest\").min() # shows min value for each group and column\n```\n\n::: {.cell-output .cell-output-display execution_count=56}\n```{=html}\n<div><style>\n.dataframe > thead > tr,\n.dataframe > tbody > tr {\n  text-align: right;\n  white-space: pre-wrap;\n}\n</style>\n<small>shape: (105, 19)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>dest</th><th>year</th><th>month</th><th>day</th><th>dep_time</th><th>sched_dep_time</th><th>dep_delay</th><th>arr_time</th><th>sched_arr_time</th><th>arr_delay</th><th>carrier</th><th>flight</th><th>tailnum</th><th>origin</th><th>air_time</th><th>distance</th><th>hour</th><th>minute</th><th>time_hour</th></tr><tr><td>str</td><td>i64</td><td>i64</td><td>i64</td><td>f64</td><td>i64</td><td>f64</td><td>f64</td><td>i64</td><td>f64</td><td>str</td><td>i64</td><td>str</td><td>str</td><td>f64</td><td>i64</td><td>i64</td><td>i64</td><td>datetime[μs]</td></tr></thead><tbody><tr><td>&quot;MVY&quot;</td><td>2013</td><td>5</td><td>1</td><td>817.0</td><td>829</td><td>-18.0</td><td>914.0</td><td>946</td><td>-33.0</td><td>&quot;9E&quot;</td><td>1338</td><td>&quot;N178JB&quot;</td><td>&quot;JFK&quot;</td><td>30.0</td><td>173</td><td>8</td><td>10</td><td>2013-05-16 17:00:00</td></tr><tr><td>&quot;JAC&quot;</td><td>2013</td><td>1</td><td>1</td><td>802.0</td><td>800</td><td>-13.0</td><td>1111.0</td><td>1102</td><td>-17.0</td><td>&quot;DL&quot;</td><td>1162</td><td>&quot;N13716&quot;</td><td>&quot;EWR&quot;</td><td>248.0</td><td>1874</td><td>8</td><td>0</td><td>2013-01-01 13:00:00</td></tr><tr><td>&quot;MCO&quot;</td><td>2013</td><td>1</td><td>1</td><td>2.0</td><td>550</td><td>-21.0</td><td>1.0</td><td>3</td><td>-63.0</td><td>&quot;AA&quot;</td><td>4</td><td>&quot;D942DN&quot;</td><td>&quot;EWR&quot;</td><td>107.0</td><td>937</td><td>5</td><td>0</td><td>2013-01-01 11:00:00</td></tr><tr><td>&quot;MHT&quot;</td><td>2013</td><td>1</td><td>1</td><td>6.0</td><td>647</td><td>-17.0</td><td>1.0</td><td>800</td><td>-37.0</td><td>&quot;9E&quot;</td><td>3255</td><td>&quot;N10156&quot;</td><td>&quot;EWR&quot;</td><td>31.0</td><td>195</td><td>6</td><td>0</td><td>2013-01-01 18:00:00</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;BWI&quot;</td><td>2013</td><td>1</td><td>1</td><td>8.0</td><td>600</td><td>-18.0</td><td>5.0</td><td>30</td><td>-53.0</td><td>&quot;9E&quot;</td><td>63</td><td>&quot;N10156&quot;</td><td>&quot;EWR&quot;</td><td>31.0</td><td>169</td><td>6</td><td>0</td><td>2013-01-01 11:00:00</td></tr><tr><td>&quot;BDL&quot;</td><td>2013</td><td>1</td><td>1</td><td>15.0</td><td>527</td><td>-15.0</td><td>3.0</td><td>628</td><td>-43.0</td><td>&quot;EV&quot;</td><td>471</td><td>&quot;N10156&quot;</td><td>&quot;EWR&quot;</td><td>20.0</td><td>116</td><td>5</td><td>0</td><td>2013-01-01 18:00:00</td></tr><tr><td>&quot;MDW&quot;</td><td>2013</td><td>1</td><td>1</td><td>1.0</td><td>600</td><td>-13.0</td><td>1.0</td><td>715</td><td>-49.0</td><td>&quot;WN&quot;</td><td>1</td><td>&quot;N200WN&quot;</td><td>&quot;EWR&quot;</td><td>92.0</td><td>711</td><td>6</td><td>0</td><td>2013-01-01 13:00:00</td></tr><tr><td>&quot;ANC&quot;</td><td>2013</td><td>7</td><td>3</td><td>1613.0</td><td>1615</td><td>-2.0</td><td>1906.0</td><td>1953</td><td>-47.0</td><td>&quot;UA&quot;</td><td>887</td><td>&quot;N528UA&quot;</td><td>&quot;EWR&quot;</td><td>388.0</td><td>3370</td><td>16</td><td>15</td><td>2013-07-06 20:00:00</td></tr></tbody></table></div>\n```\n:::\n:::\n\n\nIf you want the top/bottom `k` number of rows (optionally by group), use the `DataFrame.top_k` or `DataFrame.bottom_k` contexts:\n\n::: {#fe3bcf79 .cell execution_count=57}\n``` {.python .cell-code}\nflights.top_k(k = 4, by = \"arr_delay\")\nflights.bottom_k(k = 4, by = \"arr_delay\")\n```\n\n::: {.cell-output .cell-output-display execution_count=57}\n```{=html}\n<div><style>\n.dataframe > thead > tr,\n.dataframe > tbody > tr {\n  text-align: right;\n  white-space: pre-wrap;\n}\n</style>\n<small>shape: (4, 19)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>year</th><th>month</th><th>day</th><th>dep_time</th><th>sched_dep_time</th><th>dep_delay</th><th>arr_time</th><th>sched_arr_time</th><th>arr_delay</th><th>carrier</th><th>flight</th><th>tailnum</th><th>origin</th><th>dest</th><th>air_time</th><th>distance</th><th>hour</th><th>minute</th><th>time_hour</th></tr><tr><td>i64</td><td>i64</td><td>i64</td><td>f64</td><td>i64</td><td>f64</td><td>f64</td><td>i64</td><td>f64</td><td>str</td><td>i64</td><td>str</td><td>str</td><td>str</td><td>f64</td><td>i64</td><td>i64</td><td>i64</td><td>datetime[μs]</td></tr></thead><tbody><tr><td>2013</td><td>5</td><td>7</td><td>1715.0</td><td>1729</td><td>-14.0</td><td>1944.0</td><td>2110</td><td>-86.0</td><td>&quot;VX&quot;</td><td>193</td><td>&quot;N843VA&quot;</td><td>&quot;EWR&quot;</td><td>&quot;SFO&quot;</td><td>315.0</td><td>2565</td><td>17</td><td>29</td><td>2013-05-07 21:00:00</td></tr><tr><td>2013</td><td>5</td><td>20</td><td>719.0</td><td>735</td><td>-16.0</td><td>951.0</td><td>1110</td><td>-79.0</td><td>&quot;VX&quot;</td><td>11</td><td>&quot;N840VA&quot;</td><td>&quot;JFK&quot;</td><td>&quot;SFO&quot;</td><td>316.0</td><td>2586</td><td>7</td><td>35</td><td>2013-05-20 11:00:00</td></tr><tr><td>2013</td><td>5</td><td>2</td><td>1947.0</td><td>1949</td><td>-2.0</td><td>2209.0</td><td>2324</td><td>-75.0</td><td>&quot;UA&quot;</td><td>612</td><td>&quot;N851UA&quot;</td><td>&quot;EWR&quot;</td><td>&quot;LAX&quot;</td><td>300.0</td><td>2454</td><td>19</td><td>49</td><td>2013-05-02 23:00:00</td></tr><tr><td>2013</td><td>5</td><td>6</td><td>1826.0</td><td>1830</td><td>-4.0</td><td>2045.0</td><td>2200</td><td>-75.0</td><td>&quot;AA&quot;</td><td>269</td><td>&quot;N3KCAA&quot;</td><td>&quot;JFK&quot;</td><td>&quot;SEA&quot;</td><td>289.0</td><td>2422</td><td>18</td><td>30</td><td>2013-05-06 22:00:00</td></tr></tbody></table></div>\n```\n:::\n:::\n\n\n#### Grouping by multiple variables\n\nYou can create groups using more than one variable. For example, we could make a group for each date:\n\n::: {#759cfd6e .cell execution_count=58}\n``` {.python .cell-code}\ndaily = (\n    flights\n    .group_by([\"year\", \"month\", \"day\"])\n)\n\ndaily.max()\n```\n\n::: {.cell-output .cell-output-display execution_count=58}\n```{=html}\n<div><style>\n.dataframe > thead > tr,\n.dataframe > tbody > tr {\n  text-align: right;\n  white-space: pre-wrap;\n}\n</style>\n<small>shape: (365, 19)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>year</th><th>month</th><th>day</th><th>dep_time</th><th>sched_dep_time</th><th>dep_delay</th><th>arr_time</th><th>sched_arr_time</th><th>arr_delay</th><th>carrier</th><th>flight</th><th>tailnum</th><th>origin</th><th>dest</th><th>air_time</th><th>distance</th><th>hour</th><th>minute</th><th>time_hour</th></tr><tr><td>i64</td><td>i64</td><td>i64</td><td>f64</td><td>i64</td><td>f64</td><td>f64</td><td>i64</td><td>f64</td><td>str</td><td>i64</td><td>str</td><td>str</td><td>str</td><td>f64</td><td>i64</td><td>i64</td><td>i64</td><td>datetime[μs]</td></tr></thead><tbody><tr><td>2013</td><td>4</td><td>26</td><td>2358.0</td><td>2359</td><td>275.0</td><td>2358.0</td><td>2359</td><td>252.0</td><td>&quot;YV&quot;</td><td>5793</td><td>&quot;N993DL&quot;</td><td>&quot;LGA&quot;</td><td>&quot;XNA&quot;</td><td>614.0</td><td>4983</td><td>23</td><td>59</td><td>2013-04-27 03:00:00</td></tr><tr><td>2013</td><td>5</td><td>18</td><td>2356.0</td><td>2359</td><td>369.0</td><td>2359.0</td><td>2358</td><td>362.0</td><td>&quot;WN&quot;</td><td>5769</td><td>&quot;N9EAMQ&quot;</td><td>&quot;LGA&quot;</td><td>&quot;TPA&quot;</td><td>618.0</td><td>4983</td><td>23</td><td>59</td><td>2013-05-19 03:00:00</td></tr><tr><td>2013</td><td>6</td><td>30</td><td>2359.0</td><td>2359</td><td>437.0</td><td>2400.0</td><td>2359</td><td>469.0</td><td>&quot;YV&quot;</td><td>6177</td><td>&quot;N998AT&quot;</td><td>&quot;LGA&quot;</td><td>&quot;XNA&quot;</td><td>601.0</td><td>4983</td><td>23</td><td>59</td><td>2013-07-01 03:00:00</td></tr><tr><td>2013</td><td>9</td><td>13</td><td>2352.0</td><td>2359</td><td>245.0</td><td>2359.0</td><td>2359</td><td>236.0</td><td>&quot;YV&quot;</td><td>6177</td><td>&quot;N9EAMQ&quot;</td><td>&quot;LGA&quot;</td><td>&quot;XNA&quot;</td><td>605.0</td><td>4983</td><td>23</td><td>59</td><td>2013-09-14 03:00:00</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>2013</td><td>6</td><td>9</td><td>2356.0</td><td>2359</td><td>246.0</td><td>2359.0</td><td>2359</td><td>239.0</td><td>&quot;YV&quot;</td><td>6177</td><td>&quot;N9EAMQ&quot;</td><td>&quot;LGA&quot;</td><td>&quot;XNA&quot;</td><td>617.0</td><td>4983</td><td>23</td><td>59</td><td>2013-06-10 03:00:00</td></tr><tr><td>2013</td><td>10</td><td>14</td><td>2347.0</td><td>2359</td><td>702.0</td><td>2356.0</td><td>2359</td><td>688.0</td><td>&quot;YV&quot;</td><td>6181</td><td>&quot;N994DL&quot;</td><td>&quot;LGA&quot;</td><td>&quot;XNA&quot;</td><td>631.0</td><td>4983</td><td>23</td><td>59</td><td>2013-10-15 03:00:00</td></tr><tr><td>2013</td><td>10</td><td>2</td><td>2341.0</td><td>2359</td><td>306.0</td><td>2400.0</td><td>2359</td><td>272.0</td><td>&quot;YV&quot;</td><td>6181</td><td>&quot;N9EAMQ&quot;</td><td>&quot;LGA&quot;</td><td>&quot;XNA&quot;</td><td>623.0</td><td>4983</td><td>23</td><td>59</td><td>2013-10-03 03:00:00</td></tr><tr><td>2013</td><td>1</td><td>23</td><td>2358.0</td><td>2359</td><td>478.0</td><td>2359.0</td><td>2359</td><td>486.0</td><td>&quot;YV&quot;</td><td>6055</td><td>&quot;N989DL&quot;</td><td>&quot;LGA&quot;</td><td>&quot;XNA&quot;</td><td>653.0</td><td>4983</td><td>23</td><td>59</td><td>2013-01-24 04:00:00</td></tr></tbody></table></div>\n```\n:::\n:::\n\n\n`GroupBy` methods return a `DataFrame`, so there is no need to explicitly \"un-group\" your dataset.\n\n### Summary\n\nIn this chapter, you’ve learned the tools that Polars provides for working with data frames. The tools are roughly grouped into three categories: those that manipulate the rows (like `DataFrame.filter()` and `DataFrame.sort()`) those that manipulate the columns (like `DataFrame.select()` and `DataFrame.with_columns()`) and those that manipulate groups (like `DataFrame.group_by()` and `GroupBy.agg()`). In this chapter, we’ve focused on these “whole data frame” tools, but you haven’t yet learned much about what you can do with the individual variable. We’ll return to that in a later module in the course, where each section provides tools for a specific type of variable.\n\n## Data tidying\n\nIn this section, you will learn a consistent way to organize your data in Python using a system called **tidy data**. Getting your data into this format requires some work up front, but that work pays off in the long term. Once you have tidy data, you will spend much less time munging data from one representation to another, allowing you to spend more time on the data questions you care about.\n\nYou'll first learn the definition of tidy data and see it applied to a simple toy dataset. Then we’ll dive into the primary tool you’ll use for tidying data: pivoting. Pivoting allows you to change the form of your data without changing any of the values.\n\n::: {#8cde5fd2 .cell execution_count=59}\n``` {.python .cell-code}\nimport polars as pl\nimport polars.selectors as cs\nimport plotly.express as px\n```\n:::\n\n\n### Tidy data\n\nYou can represent the same underlying data in multiple ways. The example below shows the same data organized in three different ways. Each dataset shows the same values of four variables: `country`, `year`, `population`, and number of documented `cases` of TB (tuberculosis), but each dataset organizes the values in a different way.\n\n\n\n::: {#3641e0b2 .cell execution_count=61}\n``` {.python .cell-code}\ntable1\n```\n\n::: {.cell-output .cell-output-display execution_count=61}\n```{=html}\n<div><style>\n.dataframe > thead > tr,\n.dataframe > tbody > tr {\n  text-align: right;\n  white-space: pre-wrap;\n}\n</style>\n<small>shape: (6, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>country</th><th>year</th><th>cases</th><th>population</th></tr><tr><td>str</td><td>i64</td><td>i64</td><td>i64</td></tr></thead><tbody><tr><td>&quot;Afghanistan&quot;</td><td>1999</td><td>745</td><td>19987071</td></tr><tr><td>&quot;Afghanistan&quot;</td><td>2000</td><td>2666</td><td>20595360</td></tr><tr><td>&quot;Brazil&quot;</td><td>1999</td><td>37737</td><td>172006362</td></tr><tr><td>&quot;Brazil&quot;</td><td>2000</td><td>80488</td><td>174504898</td></tr><tr><td>&quot;China&quot;</td><td>1999</td><td>212258</td><td>1272915272</td></tr><tr><td>&quot;China&quot;</td><td>2000</td><td>213766</td><td>1280428583</td></tr></tbody></table></div>\n```\n:::\n:::\n\n\n::: {#257aa993 .cell execution_count=62}\n``` {.python .cell-code}\ntable2\n```\n\n::: {.cell-output .cell-output-display execution_count=62}\n```{=html}\n<div><style>\n.dataframe > thead > tr,\n.dataframe > tbody > tr {\n  text-align: right;\n  white-space: pre-wrap;\n}\n</style>\n<small>shape: (12, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>country</th><th>year</th><th>type</th><th>count</th></tr><tr><td>str</td><td>i64</td><td>str</td><td>i64</td></tr></thead><tbody><tr><td>&quot;Afghanistan&quot;</td><td>1999</td><td>&quot;cases&quot;</td><td>745</td></tr><tr><td>&quot;Afghanistan&quot;</td><td>1999</td><td>&quot;population&quot;</td><td>19987071</td></tr><tr><td>&quot;Afghanistan&quot;</td><td>2000</td><td>&quot;cases&quot;</td><td>2666</td></tr><tr><td>&quot;Afghanistan&quot;</td><td>2000</td><td>&quot;population&quot;</td><td>20595360</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;China&quot;</td><td>1999</td><td>&quot;cases&quot;</td><td>212258</td></tr><tr><td>&quot;China&quot;</td><td>1999</td><td>&quot;population&quot;</td><td>1272915272</td></tr><tr><td>&quot;China&quot;</td><td>2000</td><td>&quot;cases&quot;</td><td>213766</td></tr><tr><td>&quot;China&quot;</td><td>2000</td><td>&quot;population&quot;</td><td>1280428583</td></tr></tbody></table></div>\n```\n:::\n:::\n\n\n::: {#3c6ee864 .cell execution_count=63}\n``` {.python .cell-code}\ntable3\n```\n\n::: {.cell-output .cell-output-display execution_count=63}\n```{=html}\n<div><style>\n.dataframe > thead > tr,\n.dataframe > tbody > tr {\n  text-align: right;\n  white-space: pre-wrap;\n}\n</style>\n<small>shape: (6, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>country</th><th>year</th><th>rate</th></tr><tr><td>str</td><td>i64</td><td>str</td></tr></thead><tbody><tr><td>&quot;Afghanistan&quot;</td><td>1999</td><td>&quot;745/19987071&quot;</td></tr><tr><td>&quot;Afghanistan&quot;</td><td>2000</td><td>&quot;2666/20595360&quot;</td></tr><tr><td>&quot;Brazil&quot;</td><td>1999</td><td>&quot;37737/172006362&quot;</td></tr><tr><td>&quot;Brazil&quot;</td><td>2000</td><td>&quot;80488/174504898&quot;</td></tr><tr><td>&quot;China&quot;</td><td>1999</td><td>&quot;212258/1272915272&quot;</td></tr><tr><td>&quot;China&quot;</td><td>2000</td><td>&quot;213766/1280428583&quot;</td></tr></tbody></table></div>\n```\n:::\n:::\n\n\nThese are all representations of the same underlying data, but they are not equally easy to use. One of them, `table1`, will be much easier to work with Polars & Plotly because it’s **tidy**.\n\nThere are three interrelated rules that make a dataset tidy:\n\n1. Each variable is a column; each column is a variable.\n2. Each observation is a row; each row is an observation.\n3. Each value is a cell; each cell is a single value.\n\n![The following three rules make a dataset tidy: variables are columns, observations are rows, and values are cells.](images/tidy-1.png)\n\nWhy ensure that your data is tidy? There are two main advantages:\n\n1. There’s a general advantage to picking one consistent way of storing data. If you have a consistent data structure, it’s easier to learn the tools that work with it because they have an underlying uniformity.\n\n2. There’s a specific advantage to placing variables in columns because it allows Polar's vectorized nature to shine. Plotly also works by default with tidy data formats, and requires (a little) workaround for wide formats.\n\nHere are some examples of how Polars & Plotly work with tidy data:\n\n::: {#b2ff967b .cell execution_count=64}\n``` {.python .cell-code}\n# Compute rate per 10,000\ntable1.with_columns(\n    rate = pl.col(\"cases\") / pl.col(\"population\") * 1000\n)\n```\n\n::: {.cell-output .cell-output-display execution_count=64}\n```{=html}\n<div><style>\n.dataframe > thead > tr,\n.dataframe > tbody > tr {\n  text-align: right;\n  white-space: pre-wrap;\n}\n</style>\n<small>shape: (6, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>country</th><th>year</th><th>cases</th><th>population</th><th>rate</th></tr><tr><td>str</td><td>i64</td><td>i64</td><td>i64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;Afghanistan&quot;</td><td>1999</td><td>745</td><td>19987071</td><td>0.037274</td></tr><tr><td>&quot;Afghanistan&quot;</td><td>2000</td><td>2666</td><td>20595360</td><td>0.129447</td></tr><tr><td>&quot;Brazil&quot;</td><td>1999</td><td>37737</td><td>172006362</td><td>0.219393</td></tr><tr><td>&quot;Brazil&quot;</td><td>2000</td><td>80488</td><td>174504898</td><td>0.461236</td></tr><tr><td>&quot;China&quot;</td><td>1999</td><td>212258</td><td>1272915272</td><td>0.16675</td></tr><tr><td>&quot;China&quot;</td><td>2000</td><td>213766</td><td>1280428583</td><td>0.166949</td></tr></tbody></table></div>\n```\n:::\n:::\n\n\n::: {#128746f8 .cell execution_count=65}\n``` {.python .cell-code}\n# Compute total cases per year\ntable1.group_by(\"year\").agg(total_cases = pl.col(\"cases\").sum())\n```\n\n::: {.cell-output .cell-output-display execution_count=65}\n```{=html}\n<div><style>\n.dataframe > thead > tr,\n.dataframe > tbody > tr {\n  text-align: right;\n  white-space: pre-wrap;\n}\n</style>\n<small>shape: (2, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>year</th><th>total_cases</th></tr><tr><td>i64</td><td>i64</td></tr></thead><tbody><tr><td>1999</td><td>250740</td></tr><tr><td>2000</td><td>296920</td></tr></tbody></table></div>\n```\n:::\n:::\n\n\n::: {#7ac2a7c5 .cell execution_count=66}\n``` {.python .cell-code}\n# Visualize changes over time\n\ntable1_datefix = table1.with_columns(\n    date = (pl.col(\"year\").cast(pl.String) + \"-01-01\").str.to_date()\n)\n\npx.line(\n    table1_datefix,\n    x=\"date\",\n    y=\"cases\",\n    color=\"country\",\n    symbol=\"country\",\n    title=\"Cases by Year and Country\",\n)\n```\n\n::: {.cell-output .cell-output-display}\n```{=html}\n<iframe\n    scrolling=\"no\"\n    width=\"100%\"\n    height=\"545px\"\n    src=\"iframe_figures/figure_66.html\"\n    frameborder=\"0\"\n    allowfullscreen\n></iframe>\n```\n:::\n:::\n\n\n::: {.callout-tip}\nWhile we are covering the basics of tidy data, I highly recommend reading [Tidy Data](https://vita.had.co.nz/papers/tidy-data.pdf) by Hadley Wickham. It's a short paper on the principles of working with tidy data and it's benefits.\n:::\n\n### Lengthening data\n\nThe principles of tidy data might seem so obvious that you wonder if you’ll ever encounter a dataset that isn’t tidy. Unfortunately, however, most real data is untidy. There are two main reasons:\n\n1. Data is often organized to facilitate some goal other than analysis. For example, it’s common for data to be structured to make data entry, not analysis, easy.\n\n2. Most people aren’t familiar with the principles of tidy data, and it’s hard to derive them yourself unless you spend a lot of time working with data.\n\nThis means that most real analyses will require at least a little tidying. You’ll begin by figuring out what the underlying variables and observations are. Sometimes this is easy; other times you’ll need to consult with the people who originally generated the data. Next, you’ll **pivot** your data into a tidy form, with variables in the columns and observations in the rows.\n\nPolars provides two methods for pivoting data: `DataFrame.pivot()` and `DataFrame.unpivot()`. We'll first start with `DataFrame.unpivot()` because it's the most common case. Let's dive into some examples.\n\n#### Data in column names\n\nThe `billboard` dataset records the billboard rank of songs in the year 2000:\n\n\n\n::: {#77bc487e .cell execution_count=68}\n``` {.python .cell-code}\nbillboard\n```\n\n::: {.cell-output .cell-output-display execution_count=68}\n```{=html}\n<div><style>\n.dataframe > thead > tr,\n.dataframe > tbody > tr {\n  text-align: right;\n  white-space: pre-wrap;\n}\n</style>\n<small>shape: (317, 79)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>artist</th><th>track</th><th>date.entered</th><th>wk1</th><th>wk2</th><th>wk3</th><th>wk4</th><th>wk5</th><th>wk6</th><th>wk7</th><th>wk8</th><th>wk9</th><th>wk10</th><th>wk11</th><th>wk12</th><th>wk13</th><th>wk14</th><th>wk15</th><th>wk16</th><th>wk17</th><th>wk18</th><th>wk19</th><th>wk20</th><th>wk21</th><th>wk22</th><th>wk23</th><th>wk24</th><th>wk25</th><th>wk26</th><th>wk27</th><th>wk28</th><th>wk29</th><th>wk30</th><th>wk31</th><th>wk32</th><th>wk33</th><th>wk34</th><th>&hellip;</th><th>wk40</th><th>wk41</th><th>wk42</th><th>wk43</th><th>wk44</th><th>wk45</th><th>wk46</th><th>wk47</th><th>wk48</th><th>wk49</th><th>wk50</th><th>wk51</th><th>wk52</th><th>wk53</th><th>wk54</th><th>wk55</th><th>wk56</th><th>wk57</th><th>wk58</th><th>wk59</th><th>wk60</th><th>wk61</th><th>wk62</th><th>wk63</th><th>wk64</th><th>wk65</th><th>wk66</th><th>wk67</th><th>wk68</th><th>wk69</th><th>wk70</th><th>wk71</th><th>wk72</th><th>wk73</th><th>wk74</th><th>wk75</th><th>wk76</th></tr><tr><td>str</td><td>str</td><td>date</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>&hellip;</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;2 Pac&quot;</td><td>&quot;Baby Don&#x27;t Cry (Keep...&quot;</td><td>2000-02-26</td><td>87</td><td>82</td><td>72</td><td>77</td><td>87</td><td>94</td><td>99</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>&hellip;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;2Ge+her&quot;</td><td>&quot;The Hardest Part Of ...&quot;</td><td>2000-09-02</td><td>91</td><td>87</td><td>92</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>&hellip;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;3 Doors Down&quot;</td><td>&quot;Kryptonite&quot;</td><td>2000-04-08</td><td>81</td><td>70</td><td>68</td><td>67</td><td>66</td><td>57</td><td>54</td><td>53</td><td>51</td><td>51</td><td>51</td><td>51</td><td>47</td><td>44</td><td>38</td><td>28</td><td>22</td><td>18</td><td>18</td><td>14</td><td>12</td><td>7</td><td>6</td><td>6</td><td>6</td><td>5</td><td>5</td><td>4</td><td>4</td><td>4</td><td>4</td><td>3</td><td>3</td><td>3</td><td>&hellip;</td><td>15</td><td>14</td><td>13</td><td>14</td><td>16</td><td>17</td><td>21</td><td>22</td><td>24</td><td>28</td><td>33</td><td>42</td><td>42</td><td>49</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;3 Doors Down&quot;</td><td>&quot;Loser&quot;</td><td>2000-10-21</td><td>76</td><td>76</td><td>72</td><td>69</td><td>67</td><td>65</td><td>55</td><td>59</td><td>62</td><td>61</td><td>61</td><td>59</td><td>61</td><td>66</td><td>72</td><td>76</td><td>75</td><td>67</td><td>73</td><td>70</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>&hellip;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;Yearwood, Trisha&quot;</td><td>&quot;Real Live Woman&quot;</td><td>2000-04-01</td><td>85</td><td>83</td><td>83</td><td>82</td><td>81</td><td>91</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>&hellip;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;Ying Yang Twins&quot;</td><td>&quot;Whistle While You Tw...&quot;</td><td>2000-03-18</td><td>95</td><td>94</td><td>91</td><td>85</td><td>84</td><td>78</td><td>74</td><td>78</td><td>85</td><td>89</td><td>97</td><td>96</td><td>99</td><td>99</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>&hellip;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;Zombie Nation&quot;</td><td>&quot;Kernkraft 400&quot;</td><td>2000-09-02</td><td>99</td><td>99</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>&hellip;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;matchbox twenty&quot;</td><td>&quot;Bent&quot;</td><td>2000-04-29</td><td>60</td><td>37</td><td>29</td><td>24</td><td>22</td><td>21</td><td>18</td><td>16</td><td>13</td><td>12</td><td>8</td><td>6</td><td>1</td><td>2</td><td>3</td><td>2</td><td>2</td><td>3</td><td>4</td><td>5</td><td>4</td><td>4</td><td>6</td><td>9</td><td>12</td><td>13</td><td>19</td><td>20</td><td>20</td><td>24</td><td>29</td><td>28</td><td>27</td><td>30</td><td>&hellip;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr></tbody></table></div>\n```\n:::\n:::\n\n\nIn this dataset, each observation is a song. The first three columns (`artist`, `track`, and `date.entered`) are variables that describe the song. Then we have 76 columns, `wk1`-`wk76`, that describe the rank of the song in each week. Here, the column names are one variable (the `week`) and the cell values are another (the `rank`).\n\nTo tidy this data, we'll use `DataFrame.unpivot()`:\n\n::: {#75f1ce4f .cell execution_count=69}\n``` {.python .cell-code}\nbillboard.unpivot(\n    index=[\"artist\", \"track\", \"date.entered\"],\n    variable_name=\"week\",\n    value_name=\"rank\"\n)\n```\n\n::: {.cell-output .cell-output-display execution_count=69}\n```{=html}\n<div><style>\n.dataframe > thead > tr,\n.dataframe > tbody > tr {\n  text-align: right;\n  white-space: pre-wrap;\n}\n</style>\n<small>shape: (24_092, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>artist</th><th>track</th><th>date.entered</th><th>week</th><th>rank</th></tr><tr><td>str</td><td>str</td><td>date</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;2 Pac&quot;</td><td>&quot;Baby Don&#x27;t Cry (Keep...&quot;</td><td>2000-02-26</td><td>&quot;wk1&quot;</td><td>&quot;87&quot;</td></tr><tr><td>&quot;2Ge+her&quot;</td><td>&quot;The Hardest Part Of ...&quot;</td><td>2000-09-02</td><td>&quot;wk1&quot;</td><td>&quot;91&quot;</td></tr><tr><td>&quot;3 Doors Down&quot;</td><td>&quot;Kryptonite&quot;</td><td>2000-04-08</td><td>&quot;wk1&quot;</td><td>&quot;81&quot;</td></tr><tr><td>&quot;3 Doors Down&quot;</td><td>&quot;Loser&quot;</td><td>2000-10-21</td><td>&quot;wk1&quot;</td><td>&quot;76&quot;</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;Yearwood, Trisha&quot;</td><td>&quot;Real Live Woman&quot;</td><td>2000-04-01</td><td>&quot;wk76&quot;</td><td>null</td></tr><tr><td>&quot;Ying Yang Twins&quot;</td><td>&quot;Whistle While You Tw...&quot;</td><td>2000-03-18</td><td>&quot;wk76&quot;</td><td>null</td></tr><tr><td>&quot;Zombie Nation&quot;</td><td>&quot;Kernkraft 400&quot;</td><td>2000-09-02</td><td>&quot;wk76&quot;</td><td>null</td></tr><tr><td>&quot;matchbox twenty&quot;</td><td>&quot;Bent&quot;</td><td>2000-04-29</td><td>&quot;wk76&quot;</td><td>null</td></tr></tbody></table></div>\n```\n:::\n:::\n\n\nThere are three key arguments:\n\n- `index` specifies which columns **are not** pivoted, i.e. which columns are variables.\n- `variable_name` names the variable stored in the column names, we named that variable `week`.\n- `value_name` names the variable stored in the cell values, we named that variable `rank`.\n\nNow let's turn our attention to the resulting, longer data frame. What happens if a song is in the top 100 for less than 76 weeks? Take 2 Pack's \"Baby Don't Cry\", for example:\n\n::: {#7378108a .cell execution_count=70}\n``` {.python .cell-code}\nbillboard.unpivot(\n    index=[\"artist\", \"track\", \"date.entered\"],\n    variable_name=\"week\",\n    value_name=\"rank\"\n).filter(\n    pl.col(\"artist\") == \"2 Pac\", # using commas is another way to chain multiple ANDs\n    pl.col(\"track\").str.starts_with(\"Baby Don't Cry\")\n)\n```\n\n::: {.cell-output .cell-output-display execution_count=70}\n```{=html}\n<div><style>\n.dataframe > thead > tr,\n.dataframe > tbody > tr {\n  text-align: right;\n  white-space: pre-wrap;\n}\n</style>\n<small>shape: (76, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>artist</th><th>track</th><th>date.entered</th><th>week</th><th>rank</th></tr><tr><td>str</td><td>str</td><td>date</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;2 Pac&quot;</td><td>&quot;Baby Don&#x27;t Cry (Keep...&quot;</td><td>2000-02-26</td><td>&quot;wk1&quot;</td><td>&quot;87&quot;</td></tr><tr><td>&quot;2 Pac&quot;</td><td>&quot;Baby Don&#x27;t Cry (Keep...&quot;</td><td>2000-02-26</td><td>&quot;wk2&quot;</td><td>&quot;82&quot;</td></tr><tr><td>&quot;2 Pac&quot;</td><td>&quot;Baby Don&#x27;t Cry (Keep...&quot;</td><td>2000-02-26</td><td>&quot;wk3&quot;</td><td>&quot;72&quot;</td></tr><tr><td>&quot;2 Pac&quot;</td><td>&quot;Baby Don&#x27;t Cry (Keep...&quot;</td><td>2000-02-26</td><td>&quot;wk4&quot;</td><td>&quot;77&quot;</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;2 Pac&quot;</td><td>&quot;Baby Don&#x27;t Cry (Keep...&quot;</td><td>2000-02-26</td><td>&quot;wk73&quot;</td><td>null</td></tr><tr><td>&quot;2 Pac&quot;</td><td>&quot;Baby Don&#x27;t Cry (Keep...&quot;</td><td>2000-02-26</td><td>&quot;wk74&quot;</td><td>null</td></tr><tr><td>&quot;2 Pac&quot;</td><td>&quot;Baby Don&#x27;t Cry (Keep...&quot;</td><td>2000-02-26</td><td>&quot;wk75&quot;</td><td>null</td></tr><tr><td>&quot;2 Pac&quot;</td><td>&quot;Baby Don&#x27;t Cry (Keep...&quot;</td><td>2000-02-26</td><td>&quot;wk76&quot;</td><td>null</td></tr></tbody></table></div>\n```\n:::\n:::\n\n\nThe `null` in the bottom of the table suggests that this song wasn't ranked in (at least) weeks 74-76. These `null`s don't really represent unknown observations; they were forced to exist by the structure of the dataset, so we can safely filter them out:\n\n::: {#85938010 .cell execution_count=71}\n``` {.python .cell-code}\nbillboard.unpivot(\n    index=[\"artist\", \"track\", \"date.entered\"],\n    variable_name=\"week\",\n    value_name=\"rank\"\n).drop_nulls(\n    # no arguments will drop any row with `null`\n)\n```\n\n::: {.cell-output .cell-output-display execution_count=71}\n```{=html}\n<div><style>\n.dataframe > thead > tr,\n.dataframe > tbody > tr {\n  text-align: right;\n  white-space: pre-wrap;\n}\n</style>\n<small>shape: (5_307, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>artist</th><th>track</th><th>date.entered</th><th>week</th><th>rank</th></tr><tr><td>str</td><td>str</td><td>date</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;2 Pac&quot;</td><td>&quot;Baby Don&#x27;t Cry (Keep...&quot;</td><td>2000-02-26</td><td>&quot;wk1&quot;</td><td>&quot;87&quot;</td></tr><tr><td>&quot;2Ge+her&quot;</td><td>&quot;The Hardest Part Of ...&quot;</td><td>2000-09-02</td><td>&quot;wk1&quot;</td><td>&quot;91&quot;</td></tr><tr><td>&quot;3 Doors Down&quot;</td><td>&quot;Kryptonite&quot;</td><td>2000-04-08</td><td>&quot;wk1&quot;</td><td>&quot;81&quot;</td></tr><tr><td>&quot;3 Doors Down&quot;</td><td>&quot;Loser&quot;</td><td>2000-10-21</td><td>&quot;wk1&quot;</td><td>&quot;76&quot;</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;Lonestar&quot;</td><td>&quot;Amazed&quot;</td><td>1999-06-05</td><td>&quot;wk63&quot;</td><td>&quot;45&quot;</td></tr><tr><td>&quot;Creed&quot;</td><td>&quot;Higher&quot;</td><td>1999-09-11</td><td>&quot;wk64&quot;</td><td>&quot;50&quot;</td></tr><tr><td>&quot;Lonestar&quot;</td><td>&quot;Amazed&quot;</td><td>1999-06-05</td><td>&quot;wk64&quot;</td><td>&quot;50&quot;</td></tr><tr><td>&quot;Creed&quot;</td><td>&quot;Higher&quot;</td><td>1999-09-11</td><td>&quot;wk65&quot;</td><td>&quot;49&quot;</td></tr></tbody></table></div>\n```\n:::\n:::\n\n\nThe number of rows is now much lower, indicating that many rows with `null`s were dropped.\n\nYou might also wonder what happens if a song is in the top 100 for more than 76 weeks? We can’t tell from this data, but you might guess that additional columns `wk77`, `wk78`, `...` would be added to the dataset.\n\nThis data is now tidy, but we could make future computation a bit easier by converting values of `week` and `rank` from character strings to numbers using `DataFrame.with_columns()`.\n\n::: {#df6bd16e .cell execution_count=72}\n``` {.python .cell-code}\nbillboard_longer = (\n    billboard\n    .unpivot(\n        index=[\"artist\", \"track\", \"date.entered\"],\n        variable_name=\"week\",\n        value_name=\"rank\"\n    ).drop_nulls(\n\n    ).with_columns(\n        pl.col(\"week\").str.extract(r\"(\\d+)\").str.to_integer(),\n        pl.col(\"rank\").str.to_integer()\n    )\n)\n\nbillboard_longer\n```\n\n::: {.cell-output .cell-output-display execution_count=72}\n```{=html}\n<div><style>\n.dataframe > thead > tr,\n.dataframe > tbody > tr {\n  text-align: right;\n  white-space: pre-wrap;\n}\n</style>\n<small>shape: (5_307, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>artist</th><th>track</th><th>date.entered</th><th>week</th><th>rank</th></tr><tr><td>str</td><td>str</td><td>date</td><td>i64</td><td>i64</td></tr></thead><tbody><tr><td>&quot;2 Pac&quot;</td><td>&quot;Baby Don&#x27;t Cry (Keep...&quot;</td><td>2000-02-26</td><td>1</td><td>87</td></tr><tr><td>&quot;2Ge+her&quot;</td><td>&quot;The Hardest Part Of ...&quot;</td><td>2000-09-02</td><td>1</td><td>91</td></tr><tr><td>&quot;3 Doors Down&quot;</td><td>&quot;Kryptonite&quot;</td><td>2000-04-08</td><td>1</td><td>81</td></tr><tr><td>&quot;3 Doors Down&quot;</td><td>&quot;Loser&quot;</td><td>2000-10-21</td><td>1</td><td>76</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;Lonestar&quot;</td><td>&quot;Amazed&quot;</td><td>1999-06-05</td><td>63</td><td>45</td></tr><tr><td>&quot;Creed&quot;</td><td>&quot;Higher&quot;</td><td>1999-09-11</td><td>64</td><td>50</td></tr><tr><td>&quot;Lonestar&quot;</td><td>&quot;Amazed&quot;</td><td>1999-06-05</td><td>64</td><td>50</td></tr><tr><td>&quot;Creed&quot;</td><td>&quot;Higher&quot;</td><td>1999-09-11</td><td>65</td><td>49</td></tr></tbody></table></div>\n```\n:::\n:::\n\n\nNow that we have all the week numbers in one variable and all the rank values in another, we’re in a good position to visualize how song ranks vary over time.\n\n::: {#4879a9f5 .cell execution_count=73}\n``` {.python .cell-code}\npx.line(\n    billboard_longer, x=\"week\", y=\"rank\", line_group=\"track\"\n).update_traces( # we'll learn more about these extra methods in a later module\n    opacity=0.25\n).update_yaxes(\n    autorange=\"reversed\"\n)\n```\n\n::: {.cell-output .cell-output-display}\n```{=html}\n<iframe\n    scrolling=\"no\"\n    width=\"100%\"\n    height=\"545px\"\n    src=\"iframe_figures/figure_73.html\"\n    frameborder=\"0\"\n    allowfullscreen\n></iframe>\n```\n:::\n:::\n\n\nWe can see that very few songs stay in the top 100 for more than 20 weeks.\n\n#### How does pivoting work?\n\nNow that you’ve seen how we can use pivoting to reshape our data, let’s take a little time to gain some intuition about what pivoting does to the data. Let’s start with a very simple dataset to make it easier to see what’s happening. Suppose we have three patients with `id`s A, B, and C, and we take two blood pressure measurements on each patient.\n\n::: {#114eaca9 .cell execution_count=74}\n``` {.python .cell-code}\ndf = pl.from_dict({\n    \"id\":  [\"A\", \"B\", \"C\"],\n    \"bp1\": [100, 140, 120],\n    \"bp2\": [120, 114, 125] \n})\n\ndf\n```\n\n::: {.cell-output .cell-output-display execution_count=74}\n```{=html}\n<div><style>\n.dataframe > thead > tr,\n.dataframe > tbody > tr {\n  text-align: right;\n  white-space: pre-wrap;\n}\n</style>\n<small>shape: (3, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>id</th><th>bp1</th><th>bp2</th></tr><tr><td>str</td><td>i64</td><td>i64</td></tr></thead><tbody><tr><td>&quot;A&quot;</td><td>100</td><td>120</td></tr><tr><td>&quot;B&quot;</td><td>140</td><td>114</td></tr><tr><td>&quot;C&quot;</td><td>120</td><td>125</td></tr></tbody></table></div>\n```\n:::\n:::\n\n\nWe want our new dataset to have three variables: `id` (already exists), `measurement` (the column names), and `value` (the cell values). To achieve this, we need to pivot `df` longer:\n\n::: {#985b42bd .cell execution_count=75}\n``` {.python .cell-code}\ndf.unpivot(\n    index = \"id\",\n    variable_name=\"measurement\",\n    value_name=\"value\"\n).sort(\n    [\"id\", \"measurement\", \"value\"]\n)\n```\n\n::: {.cell-output .cell-output-display execution_count=75}\n```{=html}\n<div><style>\n.dataframe > thead > tr,\n.dataframe > tbody > tr {\n  text-align: right;\n  white-space: pre-wrap;\n}\n</style>\n<small>shape: (6, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>id</th><th>measurement</th><th>value</th></tr><tr><td>str</td><td>str</td><td>i64</td></tr></thead><tbody><tr><td>&quot;A&quot;</td><td>&quot;bp1&quot;</td><td>100</td></tr><tr><td>&quot;A&quot;</td><td>&quot;bp2&quot;</td><td>120</td></tr><tr><td>&quot;B&quot;</td><td>&quot;bp1&quot;</td><td>140</td></tr><tr><td>&quot;B&quot;</td><td>&quot;bp2&quot;</td><td>114</td></tr><tr><td>&quot;C&quot;</td><td>&quot;bp1&quot;</td><td>120</td></tr><tr><td>&quot;C&quot;</td><td>&quot;bp2&quot;</td><td>125</td></tr></tbody></table></div>\n```\n:::\n:::\n\n\nHow does the reshaping work? It’s easier to see if we think about it column by column. As shown below, the values in a column that was already a variable in the original dataset (`id`) need to be repeated, once for each column that is pivoted.\n\n![Columns that are already variables need to be repeated, once for each column that is pivoted.](images/unpivot-variables.png)\n\nThe column names become values in a new variable, whose name is defined by `variable_name`, as shown below. THey need to be repeated once for each row in the original dataset.\n\n![The column names of pivoted columns become values in a new column. The values need to be repeated once for each row of the original dataset.](images/unpivot-column-names.png)\n\nThe cell values also become values in a new variable, with a name defined by `values_name`. They are unwound row by row, as shown below.\n\n![The number of values is preserved (not repeated), but unwound row-by-row.](images/unpivot-cell-values.png)\n\n#### More variables in column names\n\nA more challenging situation occurs when you have multiple pieces of information crammed into the column names, and you would like to store these in separate new variables. For example, take the `who` dataset, the source of `table1` and friends you saw above:\n\n\n\n::: {#6a2d985f .cell execution_count=77}\n``` {.python .cell-code}\nwho2.glimpse()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRows: 7240\nColumns: 58\n$ country    <str> 'Afghanistan', 'Afghanistan', 'Afghanistan', 'Afghanistan', 'Afghanistan', 'Afghanistan', 'Afghanistan', 'Afghanistan', 'Afghanistan', 'Afghanistan'\n$ year       <i64> 1980, 1981, 1982, 1983, 1984, 1985, 1986, 1987, 1988, 1989\n$ sp_m_014   <i64> None, None, None, None, None, None, None, None, None, None\n$ sp_m_1524  <i64> None, None, None, None, None, None, None, None, None, None\n$ sp_m_2534  <i64> None, None, None, None, None, None, None, None, None, None\n$ sp_m_3544  <i64> None, None, None, None, None, None, None, None, None, None\n$ sp_m_4554  <i64> None, None, None, None, None, None, None, None, None, None\n$ sp_m_5564  <i64> None, None, None, None, None, None, None, None, None, None\n$ sp_m_65    <i64> None, None, None, None, None, None, None, None, None, None\n$ sp_f_014   <i64> None, None, None, None, None, None, None, None, None, None\n$ sp_f_1524  <i64> None, None, None, None, None, None, None, None, None, None\n$ sp_f_2534  <i64> None, None, None, None, None, None, None, None, None, None\n$ sp_f_3544  <i64> None, None, None, None, None, None, None, None, None, None\n$ sp_f_4554  <i64> None, None, None, None, None, None, None, None, None, None\n$ sp_f_5564  <i64> None, None, None, None, None, None, None, None, None, None\n$ sp_f_65    <i64> None, None, None, None, None, None, None, None, None, None\n$ sn_m_014   <i64> None, None, None, None, None, None, None, None, None, None\n$ sn_m_1524  <i64> None, None, None, None, None, None, None, None, None, None\n$ sn_m_2534  <i64> None, None, None, None, None, None, None, None, None, None\n$ sn_m_3544  <i64> None, None, None, None, None, None, None, None, None, None\n$ sn_m_4554  <i64> None, None, None, None, None, None, None, None, None, None\n$ sn_m_5564  <i64> None, None, None, None, None, None, None, None, None, None\n$ sn_m_65    <i64> None, None, None, None, None, None, None, None, None, None\n$ sn_f_014   <i64> None, None, None, None, None, None, None, None, None, None\n$ sn_f_1524  <i64> None, None, None, None, None, None, None, None, None, None\n$ sn_f_2534  <i64> None, None, None, None, None, None, None, None, None, None\n$ sn_f_3544  <i64> None, None, None, None, None, None, None, None, None, None\n$ sn_f_4554  <i64> None, None, None, None, None, None, None, None, None, None\n$ sn_f_5564  <i64> None, None, None, None, None, None, None, None, None, None\n$ sn_f_65    <i64> None, None, None, None, None, None, None, None, None, None\n$ ep_m_014   <i64> None, None, None, None, None, None, None, None, None, None\n$ ep_m_1524  <i64> None, None, None, None, None, None, None, None, None, None\n$ ep_m_2534  <i64> None, None, None, None, None, None, None, None, None, None\n$ ep_m_3544  <i64> None, None, None, None, None, None, None, None, None, None\n$ ep_m_4554  <i64> None, None, None, None, None, None, None, None, None, None\n$ ep_m_5564  <i64> None, None, None, None, None, None, None, None, None, None\n$ ep_m_65    <i64> None, None, None, None, None, None, None, None, None, None\n$ ep_f_014   <i64> None, None, None, None, None, None, None, None, None, None\n$ ep_f_1524  <i64> None, None, None, None, None, None, None, None, None, None\n$ ep_f_2534  <i64> None, None, None, None, None, None, None, None, None, None\n$ ep_f_3544  <i64> None, None, None, None, None, None, None, None, None, None\n$ ep_f_4554  <i64> None, None, None, None, None, None, None, None, None, None\n$ ep_f_5564  <i64> None, None, None, None, None, None, None, None, None, None\n$ ep_f_65    <i64> None, None, None, None, None, None, None, None, None, None\n$ rel_m_014  <i64> None, None, None, None, None, None, None, None, None, None\n$ rel_m_1524 <i64> None, None, None, None, None, None, None, None, None, None\n$ rel_m_2534 <i64> None, None, None, None, None, None, None, None, None, None\n$ rel_m_3544 <i64> None, None, None, None, None, None, None, None, None, None\n$ rel_m_4554 <i64> None, None, None, None, None, None, None, None, None, None\n$ rel_m_5564 <i64> None, None, None, None, None, None, None, None, None, None\n$ rel_m_65   <i64> None, None, None, None, None, None, None, None, None, None\n$ rel_f_014  <i64> None, None, None, None, None, None, None, None, None, None\n$ rel_f_1524 <i64> None, None, None, None, None, None, None, None, None, None\n$ rel_f_2534 <i64> None, None, None, None, None, None, None, None, None, None\n$ rel_f_3544 <i64> None, None, None, None, None, None, None, None, None, None\n$ rel_f_4554 <i64> None, None, None, None, None, None, None, None, None, None\n$ rel_f_5564 <i64> None, None, None, None, None, None, None, None, None, None\n$ rel_f_65   <i64> None, None, None, None, None, None, None, None, None, None\n\n```\n:::\n:::\n\n\nThis dataset, collected by the World Health Organization, records information about tuberculosis diagnoses. There are two columns that are already variables and are easy to interpret: `country` and `year`. They are followed by 56 columns like `sp_m_014`, `ep_m_4554`, and `rel_m_3544`. If you stare at these columns for long enough, you’ll notice there’s a pattern. Each column name is made up of three pieces separated by `_`. The first piece, `sp`/`rel`/`ep`, describes the method used for the diagnosis, the second piece, `m`/`f` is the gender (coded as a binary variable in this dataset), and the third piece, `014`/`1524`/`2534`/`3544`/`4554`/`5564`/`65` is the age range (`014` represents 0-14, for example).\n\nSo in this case, we have six pieces of information recorded in `who2`: the country and the year (already columns); the method of diagnosis, the gender category, and the age range category (contained in the other column names); and the count of patients in that category (cell values). \n\nTo organize these six pieces of information in six separate columns, first we use `DataFrame.unpivot()` like before, then we have to do some data wrangling using [`list` expressions](https://docs.pola.rs/api/python/stable/reference/expressions/api/polars.Expr.list.get.html) to split the information from the column names into separate columns:\n\n1. Unpivot:\n\n::: {#57e84b7a .cell execution_count=78}\n``` {.python .cell-code}\nstep1 = who2.unpivot(\n    index=[\"country\", \"year\"],\n    variable_name=\"key\",\n    value_name=\"count\"\n)\n\nstep1\n```\n\n::: {.cell-output .cell-output-display execution_count=78}\n```{=html}\n<div><style>\n.dataframe > thead > tr,\n.dataframe > tbody > tr {\n  text-align: right;\n  white-space: pre-wrap;\n}\n</style>\n<small>shape: (405_440, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>country</th><th>year</th><th>key</th><th>count</th></tr><tr><td>str</td><td>i64</td><td>str</td><td>i64</td></tr></thead><tbody><tr><td>&quot;Afghanistan&quot;</td><td>1980</td><td>&quot;sp_m_014&quot;</td><td>null</td></tr><tr><td>&quot;Afghanistan&quot;</td><td>1981</td><td>&quot;sp_m_014&quot;</td><td>null</td></tr><tr><td>&quot;Afghanistan&quot;</td><td>1982</td><td>&quot;sp_m_014&quot;</td><td>null</td></tr><tr><td>&quot;Afghanistan&quot;</td><td>1983</td><td>&quot;sp_m_014&quot;</td><td>null</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;Zimbabwe&quot;</td><td>2010</td><td>&quot;rel_f_65&quot;</td><td>null</td></tr><tr><td>&quot;Zimbabwe&quot;</td><td>2011</td><td>&quot;rel_f_65&quot;</td><td>null</td></tr><tr><td>&quot;Zimbabwe&quot;</td><td>2012</td><td>&quot;rel_f_65&quot;</td><td>null</td></tr><tr><td>&quot;Zimbabwe&quot;</td><td>2013</td><td>&quot;rel_f_65&quot;</td><td>725</td></tr></tbody></table></div>\n```\n:::\n:::\n\n\n2. Split the `key` column into `diagnosis`, `gender`, and `age` columns:\n\n::: {#378f0ee6 .cell execution_count=79}\n``` {.python .cell-code}\nstep2 = step1.with_columns(\n    pl.col(\"key\").str.split(\"_\")\n)\n\nstep2\n```\n\n::: {.cell-output .cell-output-display execution_count=79}\n```{=html}\n<div><style>\n.dataframe > thead > tr,\n.dataframe > tbody > tr {\n  text-align: right;\n  white-space: pre-wrap;\n}\n</style>\n<small>shape: (405_440, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>country</th><th>year</th><th>key</th><th>count</th></tr><tr><td>str</td><td>i64</td><td>list[str]</td><td>i64</td></tr></thead><tbody><tr><td>&quot;Afghanistan&quot;</td><td>1980</td><td>[&quot;sp&quot;, &quot;m&quot;, &quot;014&quot;]</td><td>null</td></tr><tr><td>&quot;Afghanistan&quot;</td><td>1981</td><td>[&quot;sp&quot;, &quot;m&quot;, &quot;014&quot;]</td><td>null</td></tr><tr><td>&quot;Afghanistan&quot;</td><td>1982</td><td>[&quot;sp&quot;, &quot;m&quot;, &quot;014&quot;]</td><td>null</td></tr><tr><td>&quot;Afghanistan&quot;</td><td>1983</td><td>[&quot;sp&quot;, &quot;m&quot;, &quot;014&quot;]</td><td>null</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;Zimbabwe&quot;</td><td>2010</td><td>[&quot;rel&quot;, &quot;f&quot;, &quot;65&quot;]</td><td>null</td></tr><tr><td>&quot;Zimbabwe&quot;</td><td>2011</td><td>[&quot;rel&quot;, &quot;f&quot;, &quot;65&quot;]</td><td>null</td></tr><tr><td>&quot;Zimbabwe&quot;</td><td>2012</td><td>[&quot;rel&quot;, &quot;f&quot;, &quot;65&quot;]</td><td>null</td></tr><tr><td>&quot;Zimbabwe&quot;</td><td>2013</td><td>[&quot;rel&quot;, &quot;f&quot;, &quot;65&quot;]</td><td>725</td></tr></tbody></table></div>\n```\n:::\n:::\n\n\n3. Extract each list element into a new column:\n\n::: {#d7b81efc .cell execution_count=80}\n``` {.python .cell-code}\nstep3 = step2.select(\n    pl.col(\"country\"),\n    pl.col(\"year\"),\n    pl.col(\"key\").list.get(0).alias(\"diagnosis\"), # Polars also uses 0-indexing\n    pl.col(\"key\").list.get(1).alias(\"gender\"),\n    pl.col(\"key\").list.get(2).alias(\"age\"),\n    pl.col(\"count\")\n)\n\nstep3\n```\n\n::: {.cell-output .cell-output-display execution_count=80}\n```{=html}\n<div><style>\n.dataframe > thead > tr,\n.dataframe > tbody > tr {\n  text-align: right;\n  white-space: pre-wrap;\n}\n</style>\n<small>shape: (405_440, 6)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>country</th><th>year</th><th>diagnosis</th><th>gender</th><th>age</th><th>count</th></tr><tr><td>str</td><td>i64</td><td>str</td><td>str</td><td>str</td><td>i64</td></tr></thead><tbody><tr><td>&quot;Afghanistan&quot;</td><td>1980</td><td>&quot;sp&quot;</td><td>&quot;m&quot;</td><td>&quot;014&quot;</td><td>null</td></tr><tr><td>&quot;Afghanistan&quot;</td><td>1981</td><td>&quot;sp&quot;</td><td>&quot;m&quot;</td><td>&quot;014&quot;</td><td>null</td></tr><tr><td>&quot;Afghanistan&quot;</td><td>1982</td><td>&quot;sp&quot;</td><td>&quot;m&quot;</td><td>&quot;014&quot;</td><td>null</td></tr><tr><td>&quot;Afghanistan&quot;</td><td>1983</td><td>&quot;sp&quot;</td><td>&quot;m&quot;</td><td>&quot;014&quot;</td><td>null</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;Zimbabwe&quot;</td><td>2010</td><td>&quot;rel&quot;</td><td>&quot;f&quot;</td><td>&quot;65&quot;</td><td>null</td></tr><tr><td>&quot;Zimbabwe&quot;</td><td>2011</td><td>&quot;rel&quot;</td><td>&quot;f&quot;</td><td>&quot;65&quot;</td><td>null</td></tr><tr><td>&quot;Zimbabwe&quot;</td><td>2012</td><td>&quot;rel&quot;</td><td>&quot;f&quot;</td><td>&quot;65&quot;</td><td>null</td></tr><tr><td>&quot;Zimbabwe&quot;</td><td>2013</td><td>&quot;rel&quot;</td><td>&quot;f&quot;</td><td>&quot;65&quot;</td><td>725</td></tr></tbody></table></div>\n```\n:::\n:::\n\n\nAll together:\n\n::: {#3e7c14e8 .cell execution_count=81}\n``` {.python .cell-code}\n(\n    who2.unpivot(\n        index=[\"country\", \"year\"], variable_name=\"key\", value_name=\"count\"\n    )\n    .with_columns(\n        pl.col(\"key\").str.split(\"_\")\n    )\n    .select(\n        pl.col(\"country\"),\n        pl.col(\"year\"),\n        pl.col(\"key\").list.get(0).alias(\"diagnosis\"),\n        pl.col(\"key\").list.get(1).alias(\"gender\"),\n        pl.col(\"key\").list.get(2).alias(\"age\"),\n        pl.col(\"count\")\n    )\n)\n```\n:::\n\n\nWhile the above steps break down the process to understand easier, here is a more concise, albeit more advanced, way to achieve the same results:\n\n::: {#4836ec63 .cell execution_count=82}\n``` {.python .cell-code}\n(\n    who2.unpivot(\n        index=[\"country\", \"year\"], \n        variable_name=\"key\", \n        value_name=\"count\"\n    )\n    .with_columns(\n        pl.col(\"key\")\n        .str.split(\"_\")\n        .list.to_struct(fields=[\"diagnosis\", \"gender\", \"age\"])\n    )\n    .unnest(\"key\")\n)\n```\n\n::: {.cell-output .cell-output-display execution_count=81}\n```{=html}\n<div><style>\n.dataframe > thead > tr,\n.dataframe > tbody > tr {\n  text-align: right;\n  white-space: pre-wrap;\n}\n</style>\n<small>shape: (405_440, 6)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>country</th><th>year</th><th>diagnosis</th><th>gender</th><th>age</th><th>count</th></tr><tr><td>str</td><td>i64</td><td>str</td><td>str</td><td>str</td><td>i64</td></tr></thead><tbody><tr><td>&quot;Afghanistan&quot;</td><td>1980</td><td>&quot;sp&quot;</td><td>&quot;m&quot;</td><td>&quot;014&quot;</td><td>null</td></tr><tr><td>&quot;Afghanistan&quot;</td><td>1981</td><td>&quot;sp&quot;</td><td>&quot;m&quot;</td><td>&quot;014&quot;</td><td>null</td></tr><tr><td>&quot;Afghanistan&quot;</td><td>1982</td><td>&quot;sp&quot;</td><td>&quot;m&quot;</td><td>&quot;014&quot;</td><td>null</td></tr><tr><td>&quot;Afghanistan&quot;</td><td>1983</td><td>&quot;sp&quot;</td><td>&quot;m&quot;</td><td>&quot;014&quot;</td><td>null</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;Zimbabwe&quot;</td><td>2010</td><td>&quot;rel&quot;</td><td>&quot;f&quot;</td><td>&quot;65&quot;</td><td>null</td></tr><tr><td>&quot;Zimbabwe&quot;</td><td>2011</td><td>&quot;rel&quot;</td><td>&quot;f&quot;</td><td>&quot;65&quot;</td><td>null</td></tr><tr><td>&quot;Zimbabwe&quot;</td><td>2012</td><td>&quot;rel&quot;</td><td>&quot;f&quot;</td><td>&quot;65&quot;</td><td>null</td></tr><tr><td>&quot;Zimbabwe&quot;</td><td>2013</td><td>&quot;rel&quot;</td><td>&quot;f&quot;</td><td>&quot;65&quot;</td><td>725</td></tr></tbody></table></div>\n```\n:::\n:::\n\n\nConceptually, this is only a minor variation on the simpler case you’ve already seen. The figure below shows the basic idea: now, instead of the column names pivoting into a single column, they pivot into multiple columns.\n\n![Pivoting columns with multiple pieces of information in the names means that each column name now fills in values in multiple output columns.](images/unpivot-multiple-names.png)\n\n### Widening data\n\nSo far we've used `DataFrame.unpivot()` to solve the common class of problems where values have ended up in column names. Next we’ll pivot (HA HA) to `DataFrame.pivot()`, which makes datasets **wider** by increasing columns and reducing rows and helps when one observation is spread across multiple rows. This seems to arise less commonly in the wild, but it does seem to crop up a lot when dealing with governmental data.\n\nWe’ll start by looking at `cms_patient_experience`, a dataset from the Centers of Medicare and Medicaid services that collects data about patient experiences:\n\n\n\n::: {#a2cca2cd .cell execution_count=84}\n``` {.python .cell-code}\ncms_patient_experience\n```\n\n::: {.cell-output .cell-output-display execution_count=83}\n```{=html}\n<div><style>\n.dataframe > thead > tr,\n.dataframe > tbody > tr {\n  text-align: right;\n  white-space: pre-wrap;\n}\n</style>\n<small>shape: (500, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>org_pac_id</th><th>org_nm</th><th>measure_cd</th><th>measure_title</th><th>prf_rate</th></tr><tr><td>str</td><td>str</td><td>str</td><td>str</td><td>i64</td></tr></thead><tbody><tr><td>&quot;0446157747&quot;</td><td>&quot;USC CARE MEDICAL GROUP INC&quot;</td><td>&quot;CAHPS_GRP_1&quot;</td><td>&quot;CAHPS for MIPS SSM: Getting Ti…</td><td>63</td></tr><tr><td>&quot;0446157747&quot;</td><td>&quot;USC CARE MEDICAL GROUP INC&quot;</td><td>&quot;CAHPS_GRP_2&quot;</td><td>&quot;CAHPS for MIPS SSM: How Well P…</td><td>87</td></tr><tr><td>&quot;0446157747&quot;</td><td>&quot;USC CARE MEDICAL GROUP INC&quot;</td><td>&quot;CAHPS_GRP_3&quot;</td><td>&quot;CAHPS for MIPS SSM: Patient&#x27;s …</td><td>86</td></tr><tr><td>&quot;0446157747&quot;</td><td>&quot;USC CARE MEDICAL GROUP INC&quot;</td><td>&quot;CAHPS_GRP_5&quot;</td><td>&quot;CAHPS for MIPS SSM: Health Pro…</td><td>57</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;9931011434&quot;</td><td>&quot;PATIENT FIRST RICHMOND MEDICAL…</td><td>&quot;CAHPS_GRP_2&quot;</td><td>&quot;CAHPS for MIPS SSM: How Well P…</td><td>null</td></tr><tr><td>&quot;9931011434&quot;</td><td>&quot;PATIENT FIRST RICHMOND MEDICAL…</td><td>&quot;CAHPS_GRP_3&quot;</td><td>&quot;CAHPS for MIPS SSM: Patient&#x27;s …</td><td>null</td></tr><tr><td>&quot;9931011434&quot;</td><td>&quot;PATIENT FIRST RICHMOND MEDICAL…</td><td>&quot;CAHPS_GRP_5&quot;</td><td>&quot;CAHPS for MIPS SSM: Health Pro…</td><td>45</td></tr><tr><td>&quot;9931011434&quot;</td><td>&quot;PATIENT FIRST RICHMOND MEDICAL…</td><td>&quot;CAHPS_GRP_12&quot;</td><td>&quot;CAHPS for MIPS SSM: Stewardshi…</td><td>19</td></tr></tbody></table></div>\n```\n:::\n:::\n\n\nThe core unit being studied is an organization, but each organization is spread across six rows, with one row for each measurement taken in the survey organization. We can see the complete set of values for `measure_cd` and `measure_title` by using `DataFrame.unique().select()`:\n\n::: {#8da1ef07 .cell execution_count=85}\n``` {.python .cell-code}\ncols = [\"measure_cd\", \"measure_title\"]\n\ncms_patient_experience.unique(subset=cols).select(cols).sort(cols)\n```\n\n::: {.cell-output .cell-output-display execution_count=84}\n```{=html}\n<div><style>\n.dataframe > thead > tr,\n.dataframe > tbody > tr {\n  text-align: right;\n  white-space: pre-wrap;\n}\n</style>\n<small>shape: (6, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>measure_cd</th><th>measure_title</th></tr><tr><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;CAHPS_GRP_1&quot;</td><td>&quot;CAHPS for MIPS SSM: Getting Ti…</td></tr><tr><td>&quot;CAHPS_GRP_12&quot;</td><td>&quot;CAHPS for MIPS SSM: Stewardshi…</td></tr><tr><td>&quot;CAHPS_GRP_2&quot;</td><td>&quot;CAHPS for MIPS SSM: How Well P…</td></tr><tr><td>&quot;CAHPS_GRP_3&quot;</td><td>&quot;CAHPS for MIPS SSM: Patient&#x27;s …</td></tr><tr><td>&quot;CAHPS_GRP_5&quot;</td><td>&quot;CAHPS for MIPS SSM: Health Pro…</td></tr><tr><td>&quot;CAHPS_GRP_8&quot;</td><td>&quot;CAHPS for MIPS SSM: Courteous …</td></tr></tbody></table></div>\n```\n:::\n:::\n\n\nNeither of these columns will make particularly great variable names: `measure_cd` doesn’t hint at the meaning of the variable and `measure_title` is a long sentence containing spaces. We’ll use `measure_cd` as the source for our new column names for now, but in a real analysis you might want to create your own variable names that are both short and meaningful.\n\n`DataFrame.pivot()` has a similar, but different, interface than `DataFrame.unpivot()`: you still select the `index` columns (the columns that remain), but now you select which column the `values` will come from, and which column the names come from (`on`).\n\n::: {#777911bb .cell execution_count=86}\n``` {.python .cell-code}\ncms_patient_experience.pivot(\n    index=[\"org_pac_id\", \"org_nm\"],\n    on=[\"measure_cd\"], # Notice we don't use `measure_title`\n    values=\"prf_rate\"\n)\n```\n\n::: {.cell-output .cell-output-display execution_count=85}\n```{=html}\n<div><style>\n.dataframe > thead > tr,\n.dataframe > tbody > tr {\n  text-align: right;\n  white-space: pre-wrap;\n}\n</style>\n<small>shape: (95, 8)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>org_pac_id</th><th>org_nm</th><th>CAHPS_GRP_1</th><th>CAHPS_GRP_2</th><th>CAHPS_GRP_3</th><th>CAHPS_GRP_5</th><th>CAHPS_GRP_8</th><th>CAHPS_GRP_12</th></tr><tr><td>str</td><td>str</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td></tr></thead><tbody><tr><td>&quot;0446157747&quot;</td><td>&quot;USC CARE MEDICAL GROUP INC&quot;</td><td>63</td><td>87</td><td>86</td><td>57</td><td>85</td><td>24</td></tr><tr><td>&quot;0446162697&quot;</td><td>&quot;ASSOCIATION OF UNIVERSITY PHYS…</td><td>59</td><td>85</td><td>83</td><td>63</td><td>88</td><td>22</td></tr><tr><td>&quot;0547164295&quot;</td><td>&quot;BEAVER MEDICAL GROUP PC&quot;</td><td>49</td><td>null</td><td>75</td><td>44</td><td>73</td><td>12</td></tr><tr><td>&quot;0749333730&quot;</td><td>&quot;CAPE PHYSICIANS ASSOCIATES PA&quot;</td><td>67</td><td>84</td><td>85</td><td>65</td><td>82</td><td>24</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;9830008770&quot;</td><td>&quot;WASHINGTON UNIVERSITY&quot;</td><td>65</td><td>null</td><td>null</td><td>61</td><td>null</td><td>28</td></tr><tr><td>&quot;9830093640&quot;</td><td>&quot;COOPERATIVE HEALTHCARE SERVICE…</td><td>65</td><td>87</td><td>78</td><td>52</td><td>null</td><td>25</td></tr><tr><td>&quot;9830094515&quot;</td><td>&quot;SUTTER VALLEY MEDICAL FOUNDATI…</td><td>60</td><td>null</td><td>88</td><td>55</td><td>null</td><td>24</td></tr><tr><td>&quot;9931011434&quot;</td><td>&quot;PATIENT FIRST RICHMOND MEDICAL…</td><td>80</td><td>null</td><td>null</td><td>45</td><td>null</td><td>19</td></tr></tbody></table></div>\n```\n:::\n:::\n\n\n#### How does `DataFrame.pivot()` work?\n\nTo understand how `DataFrame.pivot()` works, let’s again start with a very simple dataset. This time we have two patients with `id`s A and B, we have three blood pressure measurements on patient A and two on patient B:\n\n::: {#af02ecd9 .cell execution_count=87}\n``` {.python .cell-code}\ndf = pl.from_dict({\n    \"id\": [\"A\", \"B\", \"B\", \"A\", \"A\"],\n    \"measurement\": [\"bp1\", \"bp1\", \"bp2\", \"bp2\", \"bp3\"],\n    \"value\": [100, 140, 115, 120, 105]\n})\n```\n:::\n\n\nWe’ll take the values from the `value` column and the names from the `measurement` column:\n\n::: {#12c101e2 .cell execution_count=88}\n``` {.python .cell-code}\ndf.pivot(on=\"measurement\", values=\"value\") # unused cols get put in `index`\n```\n\n::: {.cell-output .cell-output-display execution_count=87}\n```{=html}\n<div><style>\n.dataframe > thead > tr,\n.dataframe > tbody > tr {\n  text-align: right;\n  white-space: pre-wrap;\n}\n</style>\n<small>shape: (2, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>id</th><th>bp1</th><th>bp2</th><th>bp3</th></tr><tr><td>str</td><td>i64</td><td>i64</td><td>i64</td></tr></thead><tbody><tr><td>&quot;A&quot;</td><td>100</td><td>120</td><td>105</td></tr><tr><td>&quot;B&quot;</td><td>140</td><td>115</td><td>null</td></tr></tbody></table></div>\n```\n:::\n:::\n\n\nTo begin the process, `DataFrame.pivot()` needs to first figure out what will go in the rows and columns. The new column names will be the unique values of `measurement`.\n\n::: {#440c5374 .cell execution_count=89}\n``` {.python .cell-code}\ndf.select(\"measurement\").unique()\n```\n\n::: {.cell-output .cell-output-display execution_count=88}\n```{=html}\n<div><style>\n.dataframe > thead > tr,\n.dataframe > tbody > tr {\n  text-align: right;\n  white-space: pre-wrap;\n}\n</style>\n<small>shape: (3, 1)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>measurement</th></tr><tr><td>str</td></tr></thead><tbody><tr><td>&quot;bp1&quot;</td></tr><tr><td>&quot;bp3&quot;</td></tr><tr><td>&quot;bp2&quot;</td></tr></tbody></table></div>\n```\n:::\n:::\n\n\nBy default, the rows in the output are determined by all the variables that aren’t going into the new names or values. These are called the `index` columns. Here there is only one column, but in general there can be any number.\n\n::: {#947ecc4f .cell execution_count=90}\n``` {.python .cell-code}\ndf.select(pl.exclude(\"measurement\", \"value\")).unique()\n```\n\n::: {.cell-output .cell-output-display execution_count=89}\n```{=html}\n<div><style>\n.dataframe > thead > tr,\n.dataframe > tbody > tr {\n  text-align: right;\n  white-space: pre-wrap;\n}\n</style>\n<small>shape: (2, 1)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>id</th></tr><tr><td>str</td></tr></thead><tbody><tr><td>&quot;A&quot;</td></tr><tr><td>&quot;B&quot;</td></tr></tbody></table></div>\n```\n:::\n:::\n\n\n`DataFrame.pivot()` then combines these results to generate an empty data frame:\n\n::: {#db281f7a .cell execution_count=91}\n``` {.python .cell-code}\ndf.select(pl.exclude(\"measurement\", \"value\")).unique().with_columns(\n    x=pl.lit(None), y=pl.lit(None), z=pl.lit(None)\n)\n```\n\n::: {.cell-output .cell-output-display execution_count=90}\n```{=html}\n<div><style>\n.dataframe > thead > tr,\n.dataframe > tbody > tr {\n  text-align: right;\n  white-space: pre-wrap;\n}\n</style>\n<small>shape: (2, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>id</th><th>x</th><th>y</th><th>z</th></tr><tr><td>str</td><td>null</td><td>null</td><td>null</td></tr></thead><tbody><tr><td>&quot;A&quot;</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;B&quot;</td><td>null</td><td>null</td><td>null</td></tr></tbody></table></div>\n```\n:::\n:::\n\n\nIt then fills in all the missing values using the data in the input. In this case, not every cell in the output has a corresponding value in the input as there’s no third blood pressure measurement for patient B, so that cell remains missing. \n\n#### Data and variable names in the column headers\n\nWe will now see an example where we need to unpivot and pivot in the same set of steps to tidy our data. This step up in complexity is when the column names include a mix of variable values and variable names. For example, take the `household` dataset:\n\n::: {#9df5f197 .cell execution_count=92}\n``` {.python .cell-code}\nhousehold = pl.from_dict({\n    \"family\": [1, 2, 3, 4, 5],\n    \"dob_child1\": [\"1998-11-26\", \"1996-06-22\", \"2002-07-11\", \"2004-10-10\", \"2000-12-05\"],\n    \"dob_child2\": [\"2000-01-29\", None, \"2004-04-05\", \"2009-08-27\", \"2005-02-28\"],\n    \"name_child1\": [\"Susan\", \"Mark\", \"Sam\", \"Craig\", \"Parker\"],\n    \"name_child2\": [\"Jose\", None, \"Seth\", \"Khai\", \"Gracie\"]\n}).with_columns(\n    cs.starts_with(\"dob\").str.to_date()\n)\n\nhousehold\n```\n\n::: {.cell-output .cell-output-display execution_count=91}\n```{=html}\n<div><style>\n.dataframe > thead > tr,\n.dataframe > tbody > tr {\n  text-align: right;\n  white-space: pre-wrap;\n}\n</style>\n<small>shape: (5, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>family</th><th>dob_child1</th><th>dob_child2</th><th>name_child1</th><th>name_child2</th></tr><tr><td>i64</td><td>date</td><td>date</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>1</td><td>1998-11-26</td><td>2000-01-29</td><td>&quot;Susan&quot;</td><td>&quot;Jose&quot;</td></tr><tr><td>2</td><td>1996-06-22</td><td>null</td><td>&quot;Mark&quot;</td><td>null</td></tr><tr><td>3</td><td>2002-07-11</td><td>2004-04-05</td><td>&quot;Sam&quot;</td><td>&quot;Seth&quot;</td></tr><tr><td>4</td><td>2004-10-10</td><td>2009-08-27</td><td>&quot;Craig&quot;</td><td>&quot;Khai&quot;</td></tr><tr><td>5</td><td>2000-12-05</td><td>2005-02-28</td><td>&quot;Parker&quot;</td><td>&quot;Gracie&quot;</td></tr></tbody></table></div>\n```\n:::\n:::\n\n\nThis dataset contains data about five families, with the names and dates of birth of up to two children. The new challenge in this dataset is that the column names contain the names of two variables (`dob`, `name`) and the values of another (`child`, with values 1 or 2).\n\n::: {#478ad4c6 .cell execution_count=93}\n``` {.python .cell-code}\n(\n    # First, unpivot the data frame to create rows for each family-column combination\n    household.unpivot(index=\"family\")\n\n    # Extract the base column name (dob/name) and the child number\n    .with_columns(\n        pl.col(\"variable\")\n        .str.split(\"_\")\n        .list.to_struct(fields=[\"base_col\", \"child\"])\n    )\n    .unnest(\"variable\")\n\n    # Pivot the data to create separate columns for each base_col (dob, name)\n    .pivot(index=[\"family\", \"child\"], on=\"base_col\", values=\"value\")\n\n    # Filter out rows with null values\n    .drop_nulls()\n\n    # Clean up results\n    .sort([\"family\", \"child\"])\n    .with_columns(pl.col(\"dob\").str.to_date())\n)\n```\n\n::: {.cell-output .cell-output-display execution_count=92}\n```{=html}\n<div><style>\n.dataframe > thead > tr,\n.dataframe > tbody > tr {\n  text-align: right;\n  white-space: pre-wrap;\n}\n</style>\n<small>shape: (9, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>family</th><th>child</th><th>dob</th><th>name</th></tr><tr><td>i64</td><td>str</td><td>date</td><td>str</td></tr></thead><tbody><tr><td>1</td><td>&quot;child1&quot;</td><td>1998-11-26</td><td>&quot;Susan&quot;</td></tr><tr><td>1</td><td>&quot;child2&quot;</td><td>2000-01-29</td><td>&quot;Jose&quot;</td></tr><tr><td>2</td><td>&quot;child1&quot;</td><td>1996-06-22</td><td>&quot;Mark&quot;</td></tr><tr><td>3</td><td>&quot;child1&quot;</td><td>2002-07-11</td><td>&quot;Sam&quot;</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>4</td><td>&quot;child1&quot;</td><td>2004-10-10</td><td>&quot;Craig&quot;</td></tr><tr><td>4</td><td>&quot;child2&quot;</td><td>2009-08-27</td><td>&quot;Khai&quot;</td></tr><tr><td>5</td><td>&quot;child1&quot;</td><td>2000-12-05</td><td>&quot;Parker&quot;</td></tr><tr><td>5</td><td>&quot;child2&quot;</td><td>2005-02-28</td><td>&quot;Gracie&quot;</td></tr></tbody></table></div>\n```\n:::\n:::\n\n\nWe use `DataFrame.drop_nulls()` since the shape of the input forces the creation of explicit missing variables (e.g., for families that only have one child).\n\n### Summary\n\nIn this section, you learned about tidy data: data that has variables in columns and observations in rows. Tidy data makes working in the Polars easier, because it’s a consistent structure understood by most functions, the main challenge is transforming the data from whatever structure you receive it in to a tidy format. To that end, you learned about `DataFrame.unpivot()` and `DataFrame.pivot()` which allow you to tidy up many untidy datasets.\n\nAnother challenge is that, for a given dataset, it can be impossible to label the longer or the wider version as the \"tidy\" one. This is partly a reflection of our definition of tidy data, where we said tidy data has one variable in each column, but we didn’t actually define what a variable is (and it’s surprisingly hard to do so). It’s totally fine to be pragmatic and to say a variable is whatever makes your analysis easiest. So if you’re stuck figuring out how to do some computation, consider switching up the organization of your data; don’t be afraid to untidy, transform, and re-tidy as needed!\n\n## Data import & export\n\nWorking with data provided by Python packages is a great way to learn data science tools, but at some point, you'll want to apply what you've learned to your own data. In this section, you'll learn the basics of reading data files into Python and how to export them for others (or yourself in the future) to use.\n\nSpecifically, this chapter will focus on reading plain-text rectangular files. We'll start with practical advice for handling features like column names, types, and missing data. You will then learn about reading data from multiple files at once and writing data from Python to a file. Finally, you'll learn how to handcraft data frames in Python, and export them with Polars functions.\n\n::: {#b61ba681 .cell execution_count=94}\n``` {.python .cell-code}\nimport polars as pl\nimport io # we'll use this to \"create\" CSVs within Python examples\n```\n:::\n\n\n### Reading data from a file\n\nTo begin, we'll focus on the most common rectangular data file type: CSV, which is short for comma-separated values. Here is what a simple CSV file looks like. The first row, commonly called the header row, gives the column names, and the following six rows provide the data. The columns are separated, aka delimited, by commas.\n\n```\nStudent ID,Full Name,favourite.food,mealPlan,AGE\n1,Sunil Huffmann,Strawberry yoghurt,Lunch only,4\n2,Barclay Lynn,French fries,Lunch only,5\n3,Jayendra Lyne,N/A,Breakfast and lunch,7\n4,Leon Rossini,Anchovies,Lunch only,\n5,Chidiegwu Dunkel,Pizza,Breakfast and lunch,five\n6,Güvenç Attila,Ice cream,Lunch only,6\n```\n\nThe following table shows a representation of the same data as a table:\n\n| Student ID | Full Name         | favourite.food     | mealPlan            | AGE  |\n|------------|-------------------|--------------------|---------------------|------|\n| 1          | Sunil Huffmann    | Strawberry yoghurt | Lunch only          | 4    |\n| 2          | Barclay Lynn      | French fries       | Lunch only          | 5    |\n| 3          | Jayendra Lyne     | N/A                | Breakfast and lunch | 7    |\n| 4          | Leon Rossini      | Anchovies          | Lunch only          | NULL |\n| 5          | Chidiegwu Dunkel  | Pizza              | Breakfast and lunch | five |\n| 6          | Guvenc Attila     | Ice cream          | Lunch only          | 6    |\n\nWe can read this file into Python using `pl.read_csv()`. The first argument is the most important: the path to the file. You can think about the path as the address of the file: the file is called `students.csv` and it lives in the `data` folder.\n\n::: {#bae8a868 .cell execution_count=95}\n``` {.python .cell-code}\nstudents = pl.read_csv(\"data/students.csv\")\n```\n:::\n\n\nThe code above will work if you have the students.csv file in a data folder in your project. You can also read it directly from a URL:\n\n```python\nstudents = pl.read_csv(\"https://raw.githubusercontent.com/hadley/r4ds/main/data/students.csv\")\n```\n\nWhen you run `pl.read_csv()`, Polars will scan the file and automatically infer column types based on the data it contains. Polars doesn't print a detailed message about column specifications by default, but you can examine the schema to see the inferred types:\n\n::: {#a674e3ff .cell execution_count=96}\n``` {.python .cell-code}\nstudents.schema.to_frame()\n```\n\n::: {.cell-output .cell-output-display execution_count=95}\n```{=html}\n<div><style>\n.dataframe > thead > tr,\n.dataframe > tbody > tr {\n  text-align: right;\n  white-space: pre-wrap;\n}\n</style>\n<small>shape: (0, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>Student ID</th><th>Full Name</th><th>favourite.food</th><th>mealPlan</th><th>AGE</th></tr><tr><td>i64</td><td>str</td><td>str</td><td>str</td><td>str</td></tr></thead><tbody></tbody></table></div>\n```\n:::\n:::\n\n\n#### Practical advice\n\nOnce you read data in, the first step usually involves transforming it in some way to make it easier to work with in the rest of your analysis. Let's take another look at the students data with that in mind.\n\n::: {#621acd3f .cell execution_count=97}\n``` {.python .cell-code}\nstudents\n```\n\n::: {.cell-output .cell-output-display execution_count=96}\n```{=html}\n<div><style>\n.dataframe > thead > tr,\n.dataframe > tbody > tr {\n  text-align: right;\n  white-space: pre-wrap;\n}\n</style>\n<small>shape: (6, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>Student ID</th><th>Full Name</th><th>favourite.food</th><th>mealPlan</th><th>AGE</th></tr><tr><td>i64</td><td>str</td><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>1</td><td>&quot;Sunil Huffmann&quot;</td><td>&quot;Strawberry yoghurt&quot;</td><td>&quot;Lunch only&quot;</td><td>&quot;4&quot;</td></tr><tr><td>2</td><td>&quot;Barclay Lynn&quot;</td><td>&quot;French fries&quot;</td><td>&quot;Lunch only&quot;</td><td>&quot;5&quot;</td></tr><tr><td>3</td><td>&quot;Jayendra Lyne&quot;</td><td>&quot;N/A&quot;</td><td>&quot;Breakfast and lunch&quot;</td><td>&quot;7&quot;</td></tr><tr><td>4</td><td>&quot;Leon Rossini&quot;</td><td>&quot;Anchovies&quot;</td><td>&quot;Lunch only&quot;</td><td>null</td></tr><tr><td>5</td><td>&quot;Chidiegwu Dunkel&quot;</td><td>&quot;Pizza&quot;</td><td>&quot;Breakfast and lunch&quot;</td><td>&quot;five&quot;</td></tr><tr><td>6</td><td>&quot;Güvenç Attila&quot;</td><td>&quot;Ice cream&quot;</td><td>&quot;Lunch only&quot;</td><td>&quot;6&quot;</td></tr></tbody></table></div>\n```\n:::\n:::\n\n\nIn the `favourite.food` column, there's an entry \"N/A\" that should be interpreted as a real `None` that Python will recognize as \"not available\". This is something we can address using the `null_values` argument. By default, Polars only recognizes empty strings and the string \"null\" (case-insensitive) as missing values.\n\n::: {#9ef786cb .cell execution_count=98}\n``` {.python .cell-code}\nstudents = pl.read_csv(\n    \"data/students.csv\", \n    null_values=[\"N/A\", \"\"]\n)\n\nstudents\n```\n\n::: {.cell-output .cell-output-display execution_count=97}\n```{=html}\n<div><style>\n.dataframe > thead > tr,\n.dataframe > tbody > tr {\n  text-align: right;\n  white-space: pre-wrap;\n}\n</style>\n<small>shape: (6, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>Student ID</th><th>Full Name</th><th>favourite.food</th><th>mealPlan</th><th>AGE</th></tr><tr><td>i64</td><td>str</td><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>1</td><td>&quot;Sunil Huffmann&quot;</td><td>&quot;Strawberry yoghurt&quot;</td><td>&quot;Lunch only&quot;</td><td>&quot;4&quot;</td></tr><tr><td>2</td><td>&quot;Barclay Lynn&quot;</td><td>&quot;French fries&quot;</td><td>&quot;Lunch only&quot;</td><td>&quot;5&quot;</td></tr><tr><td>3</td><td>&quot;Jayendra Lyne&quot;</td><td>null</td><td>&quot;Breakfast and lunch&quot;</td><td>&quot;7&quot;</td></tr><tr><td>4</td><td>&quot;Leon Rossini&quot;</td><td>&quot;Anchovies&quot;</td><td>&quot;Lunch only&quot;</td><td>null</td></tr><tr><td>5</td><td>&quot;Chidiegwu Dunkel&quot;</td><td>&quot;Pizza&quot;</td><td>&quot;Breakfast and lunch&quot;</td><td>&quot;five&quot;</td></tr><tr><td>6</td><td>&quot;Güvenç Attila&quot;</td><td>&quot;Ice cream&quot;</td><td>&quot;Lunch only&quot;</td><td>&quot;6&quot;</td></tr></tbody></table></div>\n```\n:::\n:::\n\n\nYou might also notice that `Student ID` and `Full Name` columns contain spaces, which can make them awkward to work with in code. In Polars, you can refer to these columns using either bracket notation or with the `.` accessor, but the latter won't work with spaces or special characters:\n\n::: {#c0d6d5d2 .cell execution_count=99}\n``` {.python .cell-code}\n# Works with spaces\nfirst_student_name = students[\"Full Name\"][0]\nprint(first_student_name)\n\n# Won't work with spaces\nfirst_student_name = students.Full Name[0]  # Syntax error!\n```\n\n::: {.cell-output .cell-output-error}\n\n::: {.ansi-escaped-output}\n```{=html}\n<pre><span class=\"ansi-cyan-fg ansi-bold\">  Cell </span><span class=\"ansi-green-fg ansi-bold\">In[98], line 6</span>\n<span class=\"ansi-yellow-fg ansi-bold\">    first_student_name = students.Full Name[0]  # Syntax error!</span>\n<span class=\"ansi-white-fg ansi-bold\">                                       ^</span>\n<span class=\"ansi-red-fg ansi-bold\">SyntaxError</span><span class=\"ansi-red-fg ansi-bold\">:</span> invalid syntax\n</pre>\n```\n:::\n\n:::\n:::\n\n\nIt's often a good idea to rename these columns to follow Python naming conventions. Here's how you can rename specific columns:\n\n::: {#ff1eedd6 .cell execution_count=100}\n``` {.python .cell-code}\nstudents = students.rename({\n    \"Student ID\": \"student_id\",\n    \"Full Name\": \"full_name\"\n})\n\nstudents\n```\n\n::: {.cell-output .cell-output-display execution_count=99}\n```{=html}\n<div><style>\n.dataframe > thead > tr,\n.dataframe > tbody > tr {\n  text-align: right;\n  white-space: pre-wrap;\n}\n</style>\n<small>shape: (6, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>student_id</th><th>full_name</th><th>favourite.food</th><th>mealPlan</th><th>AGE</th></tr><tr><td>i64</td><td>str</td><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>1</td><td>&quot;Sunil Huffmann&quot;</td><td>&quot;Strawberry yoghurt&quot;</td><td>&quot;Lunch only&quot;</td><td>&quot;4&quot;</td></tr><tr><td>2</td><td>&quot;Barclay Lynn&quot;</td><td>&quot;French fries&quot;</td><td>&quot;Lunch only&quot;</td><td>&quot;5&quot;</td></tr><tr><td>3</td><td>&quot;Jayendra Lyne&quot;</td><td>null</td><td>&quot;Breakfast and lunch&quot;</td><td>&quot;7&quot;</td></tr><tr><td>4</td><td>&quot;Leon Rossini&quot;</td><td>&quot;Anchovies&quot;</td><td>&quot;Lunch only&quot;</td><td>null</td></tr><tr><td>5</td><td>&quot;Chidiegwu Dunkel&quot;</td><td>&quot;Pizza&quot;</td><td>&quot;Breakfast and lunch&quot;</td><td>&quot;five&quot;</td></tr><tr><td>6</td><td>&quot;Güvenç Attila&quot;</td><td>&quot;Ice cream&quot;</td><td>&quot;Lunch only&quot;</td><td>&quot;6&quot;</td></tr></tbody></table></div>\n```\n:::\n:::\n\n\nAn alternative approach is to use a function to clean all column names at once. Polars doesn't have a built-in function for this, but we can use a special shortcut called a lambda function to do this in one line. Think of a lambda function as a mini-function that you can write directly where you need it, without having to define it separately. It's like giving Polars quick instructions on how to transform each column name.\n\n::: {#d1585923 .cell execution_count=101}\n``` {.python .cell-code}\nstudents = (\n    students.rename(\n        lambda col_name: col_name.lower().replace(\" \", \"_\").replace(\".\", \"_\")\n    )\n)\n```\n:::\n\n\nWith this code, we are telling Polars to take each **column name** (not the values of the columns), call it `col`, and do these three things to it:\n\n1. Convert it to lowercase\n2. Replace any spaces with underscores\n3. Replace any periods with underscores\n\nNote that these are the string methods we learned earlier in this course, not functions that come from Polars. `col_name` has the type `str`.\n\nLike in `for` loops, it doesn't matter what the looping (or lambda) variable is called. I just called it `col_name` because that *is* what we are effecting. I could've also called it `x` and it would work the same:\n\n```python\nstudents = (\n    students.rename(\n        lambda x: x.lower().replace(\" \", \"_\").replace(\".\", \"_\")\n    )\n)\n```\n\nIf you wanted to use a regular function, you could do something like this:\n\n```python\ndef clean_col_name(col_name):\n    return col_name.lower().replace(\" \", \"_\").replace(\".\", \"_\")\n\nstudents = students.rename(clean_column_name) \n# Note: no parentheses here, we're passing the function itself\n```\n\nWhen would you want to use a named/user-defined function over a lambda function? It comes down to how many times you would repeat the steps. If you are working with only one data frame, a lambda function might be quicker to write, but if you are going to clean multiple data frames in the same script, creating a named function to use over again would be the better method.\n\n::: {.callout-note}\nYou can use this code snippet to help you with your labs and tests. You don't need to fully understand lambda functions for this course, but you can think of this specific pattern as a helpful 'recipe' for cleaning column names in one step while keeping your code clean and readable.\nIf you ever need to customize how column names are cleaned, you can just adjust what happens inside the lambda function. The Polars [documentation](https://docs.pola.rs/api/python/stable/reference/dataframe/api/polars.DataFrame.rename.html) for `DataFrame.rename()` has another example using lambda functions to rename columns.\n:::\n\nAnother common task after reading in data is to consider variable types. For example, `meal_plan` is a categorical variable with a known set of possible values, which in Python should be represented as a category:\n\n::: {#90bfdb6f .cell execution_count=102}\n``` {.python .cell-code}\nstudents = students.with_columns(\n    pl.col(\"mealplan\").cast(pl.Categorical)\n)\nstudents\n```\n\n::: {.cell-output .cell-output-display execution_count=101}\n```{=html}\n<div><style>\n.dataframe > thead > tr,\n.dataframe > tbody > tr {\n  text-align: right;\n  white-space: pre-wrap;\n}\n</style>\n<small>shape: (6, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>student_id</th><th>full_name</th><th>favourite_food</th><th>mealplan</th><th>age</th></tr><tr><td>i64</td><td>str</td><td>str</td><td>cat</td><td>str</td></tr></thead><tbody><tr><td>1</td><td>&quot;Sunil Huffmann&quot;</td><td>&quot;Strawberry yoghurt&quot;</td><td>&quot;Lunch only&quot;</td><td>&quot;4&quot;</td></tr><tr><td>2</td><td>&quot;Barclay Lynn&quot;</td><td>&quot;French fries&quot;</td><td>&quot;Lunch only&quot;</td><td>&quot;5&quot;</td></tr><tr><td>3</td><td>&quot;Jayendra Lyne&quot;</td><td>null</td><td>&quot;Breakfast and lunch&quot;</td><td>&quot;7&quot;</td></tr><tr><td>4</td><td>&quot;Leon Rossini&quot;</td><td>&quot;Anchovies&quot;</td><td>&quot;Lunch only&quot;</td><td>null</td></tr><tr><td>5</td><td>&quot;Chidiegwu Dunkel&quot;</td><td>&quot;Pizza&quot;</td><td>&quot;Breakfast and lunch&quot;</td><td>&quot;five&quot;</td></tr><tr><td>6</td><td>&quot;Güvenç Attila&quot;</td><td>&quot;Ice cream&quot;</td><td>&quot;Lunch only&quot;</td><td>&quot;6&quot;</td></tr></tbody></table></div>\n```\n:::\n:::\n\n\nBefore you analyze this dataset, you'll probably want to fix the age column. Currently, `age` contains mixed types because one observation is typed out as \"five\" instead of the number 5:\n\n::: {#d5ad2ba0 .cell execution_count=103}\n``` {.python .cell-code}\nstudents = students.with_columns(\n    age=pl.when(pl.col(\"age\") == \"five\")\n    .then(pl.lit(5))\n    .otherwise(pl.col(\"age\").cast(pl.Int64, strict=False))\n) # This is conceptually very similar to Python's built in if-elif-else\n\nstudents\n```\n\n::: {.cell-output .cell-output-display execution_count=102}\n```{=html}\n<div><style>\n.dataframe > thead > tr,\n.dataframe > tbody > tr {\n  text-align: right;\n  white-space: pre-wrap;\n}\n</style>\n<small>shape: (6, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>student_id</th><th>full_name</th><th>favourite_food</th><th>mealplan</th><th>age</th></tr><tr><td>i64</td><td>str</td><td>str</td><td>cat</td><td>i64</td></tr></thead><tbody><tr><td>1</td><td>&quot;Sunil Huffmann&quot;</td><td>&quot;Strawberry yoghurt&quot;</td><td>&quot;Lunch only&quot;</td><td>4</td></tr><tr><td>2</td><td>&quot;Barclay Lynn&quot;</td><td>&quot;French fries&quot;</td><td>&quot;Lunch only&quot;</td><td>5</td></tr><tr><td>3</td><td>&quot;Jayendra Lyne&quot;</td><td>null</td><td>&quot;Breakfast and lunch&quot;</td><td>7</td></tr><tr><td>4</td><td>&quot;Leon Rossini&quot;</td><td>&quot;Anchovies&quot;</td><td>&quot;Lunch only&quot;</td><td>null</td></tr><tr><td>5</td><td>&quot;Chidiegwu Dunkel&quot;</td><td>&quot;Pizza&quot;</td><td>&quot;Breakfast and lunch&quot;</td><td>5</td></tr><tr><td>6</td><td>&quot;Güvenç Attila&quot;</td><td>&quot;Ice cream&quot;</td><td>&quot;Lunch only&quot;</td><td>6</td></tr></tbody></table></div>\n```\n:::\n:::\n\n\nThe Polars code above uses a conditional expression with `when()`, `then()`, and `otherwise()` to handle the special case, then attempts to cast the column to a floating-point number. The `strict=False` parameter tells Polars to convert values that can be parsed as numbers and set the rest to `None`.\n\n#### Other arguments\n\nUsually, `pl.read_csv()` uses the first line of the data for the column names, which is a very common convention. But it's not uncommon for a few lines of metadata to be included at the top of the file. You can use `skip_rows` to skip the first n lines:\n\n::: {#1a621584 .cell execution_count=104}\n``` {.python .cell-code}\ncsv_data = \"\"\"The first line of metadata\nThe second line of metadata\nx,y,z \n1,2,3\"\"\"\n\npl.read_csv(io.StringIO(csv_data), skip_rows=2)\n```\n\n::: {.cell-output .cell-output-display execution_count=103}\n```{=html}\n<div><style>\n.dataframe > thead > tr,\n.dataframe > tbody > tr {\n  text-align: right;\n  white-space: pre-wrap;\n}\n</style>\n<small>shape: (1, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>x</th><th>y</th><th>z </th></tr><tr><td>i64</td><td>i64</td><td>i64</td></tr></thead><tbody><tr><td>1</td><td>2</td><td>3</td></tr></tbody></table></div>\n```\n:::\n:::\n\n\nIn other cases, the data might not have column names. You can use `has_header=False` to tell Polars not to treat the first row as headings:\n\n::: {#1d6e2969 .cell execution_count=105}\n``` {.python .cell-code}\ncsv_data = \"\"\"1,2,3\n4,5,6\"\"\"\n\npl.read_csv(io.StringIO(csv_data), has_header=False)\n```\n\n::: {.cell-output .cell-output-display execution_count=104}\n```{=html}\n<div><style>\n.dataframe > thead > tr,\n.dataframe > tbody > tr {\n  text-align: right;\n  white-space: pre-wrap;\n}\n</style>\n<small>shape: (2, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>column_1</th><th>column_2</th><th>column_3</th></tr><tr><td>i64</td><td>i64</td><td>i64</td></tr></thead><tbody><tr><td>1</td><td>2</td><td>3</td></tr><tr><td>4</td><td>5</td><td>6</td></tr></tbody></table></div>\n```\n:::\n:::\n\n\nBy default, Polars will name the columns \"column_1\", \"column_2\", etc. You can provide your own column names with the `new_columns` parameter:\n\n::: {#8cea7d74 .cell execution_count=106}\n``` {.python .cell-code}\ncsv_data = \"\"\"1,2,3\n4,5,6\"\"\"\n\npl.read_csv(\n    io.StringIO(csv_data), \n    has_header=False,\n    new_columns=[\"x\", \"y\", \"z\"]\n)\n```\n\n::: {.cell-output .cell-output-display execution_count=105}\n```{=html}\n<div><style>\n.dataframe > thead > tr,\n.dataframe > tbody > tr {\n  text-align: right;\n  white-space: pre-wrap;\n}\n</style>\n<small>shape: (2, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>x</th><th>y</th><th>z</th></tr><tr><td>i64</td><td>i64</td><td>i64</td></tr></thead><tbody><tr><td>1</td><td>2</td><td>3</td></tr><tr><td>4</td><td>5</td><td>6</td></tr></tbody></table></div>\n```\n:::\n:::\n\n\nThese arguments are all you need to know to read the majority of CSV files that you'll encounter in practice. (For the rest, you'll need to carefully inspect your .csv file and read the documentation for `pl.read_csv()`'s many other arguments.)\n\n#### Other file types\n\nOnce you've mastered `read_csv()`, using Polars' other functions is straightforward; it's just a matter of knowing which function to reach for:\n\n- `read_csv()` reads comma-separated files.\n- `read_csv()` can also read semicolon-separated files by setting `separator=\";\"`.\n- `read_csv()` can read tab-delimited files by setting `separator=\"\\t\"`, or you can use the alias `read_tsv()`.\n- `read_csv()` can read files with any delimiter by setting the `separator` parameter.\n- `read_ndjson()` reads newline-delimited JSON files.\n- `read_parquet()` reads Apache Parquet files, a columnar storage format that is typically faster and more space-efficient than CSV.\n- `read_ipc()` or `read_arrow()` reads Arrow IPC files, which provide high-performance interoperability between different systems.\n- `read_excel()` reads Excel files (learn more about the different Excel features [here](https://docs.pola.rs/user-guide/io/excel/)).\n- `read_avro()` reads Avro files.\n\n### Controlling column types\n\nA CSV file doesn't contain any information about the type of each variable (i.e., whether it's a boolean, number, string, etc.), so Polars will try to guess the type. This section describes how the guessing process works, how to resolve some common problems that cause it to fail, and how to supply the column types yourself.\n\n#### Guessing types\n\nPolars uses a heuristic to figure out the column types. By default, it samples a certain number of rows from the file and tries to infer the type based on the values it sees. You can control this with the `infer_schema_length` parameter.\n\nThe type inference generally follows these rules:\n- If values are \"true\" or \"false\" (case-insensitive), it's a boolean.\n- If values are all integers, it's an integer type.\n- If values have decimals but are all numeric, it's a floating-point type.\n- If values match a date or datetime pattern, it's a date or datetime type.\n- Otherwise, it's a string type.\n\nYou can see that behavior with a simple example:\n\n::: {#2d82e6db .cell execution_count=107}\n``` {.python .cell-code}\ncsv_data = \"\"\"logical,numeric,date,string\nTRUE,1,2021-01-15,abc\nfalse,4.5,2021-02-15,def\nT,Inf,2021-02-16,ghi\"\"\"\n\npl.read_csv(io.StringIO(csv_data))\n```\n\n::: {.cell-output .cell-output-display execution_count=106}\n```{=html}\n<div><style>\n.dataframe > thead > tr,\n.dataframe > tbody > tr {\n  text-align: right;\n  white-space: pre-wrap;\n}\n</style>\n<small>shape: (3, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>logical</th><th>numeric</th><th>date</th><th>string</th></tr><tr><td>str</td><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;TRUE&quot;</td><td>&quot;1&quot;</td><td>&quot;2021-01-15&quot;</td><td>&quot;abc&quot;</td></tr><tr><td>&quot;false&quot;</td><td>&quot;4.5&quot;</td><td>&quot;2021-02-15&quot;</td><td>&quot;def&quot;</td></tr><tr><td>&quot;T&quot;</td><td>&quot;Inf&quot;</td><td>&quot;2021-02-16&quot;</td><td>&quot;ghi&quot;</td></tr></tbody></table></div>\n```\n:::\n:::\n\n\nThis heuristic works well if you have a clean dataset, but in real life, you'll encounter a variety of challenges that require special handling.\n\n#### Missing values, column types, and problems\n\nThe most common way column detection fails is that a column contains unexpected values, and you get a string column instead of a more specific type. One of the most common causes is a missing value recorded using something other than the `None` that Polars expects.\n\nTake this simple 1-column CSV file as an example:\n\n::: {#34b0216f .cell execution_count=108}\n``` {.python .cell-code}\nsimple_csv = \"\"\"x\n10\n.\n20\n30\"\"\"\n\n# Read without specifying null values\npl.read_csv(io.StringIO(simple_csv))\n```\n\n::: {.cell-output .cell-output-display execution_count=107}\n```{=html}\n<div><style>\n.dataframe > thead > tr,\n.dataframe > tbody > tr {\n  text-align: right;\n  white-space: pre-wrap;\n}\n</style>\n<small>shape: (4, 1)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>x</th></tr><tr><td>str</td></tr></thead><tbody><tr><td>&quot;10&quot;</td></tr><tr><td>&quot;.&quot;</td></tr><tr><td>&quot;20&quot;</td></tr><tr><td>&quot;30&quot;</td></tr></tbody></table></div>\n```\n:::\n:::\n\n\nIf we read it without any additional arguments, `x` becomes a string column. In this very small example, you can easily see the missing value `.`. But what if you have thousands of rows with only a few missing values represented by `.`s scattered throughout?\n\nIn Polars, you can specify the column type and tell it what values should be treated as null:\n\n::: {#bdd1020a .cell execution_count=109}\n``` {.python .cell-code}\npl.read_csv(\n    io.StringIO(simple_csv),\n    schema_overrides={\"x\": pl.Int64},\n    null_values=[\".\"],\n)\n```\n\n::: {.cell-output .cell-output-display execution_count=108}\n```{=html}\n<div><style>\n.dataframe > thead > tr,\n.dataframe > tbody > tr {\n  text-align: right;\n  white-space: pre-wrap;\n}\n</style>\n<small>shape: (4, 1)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>x</th></tr><tr><td>i64</td></tr></thead><tbody><tr><td>10</td></tr><tr><td>null</td></tr><tr><td>20</td></tr><tr><td>30</td></tr></tbody></table></div>\n```\n:::\n:::\n\n\n#### Column types\n\nPolars provides many data types that you can specify:\n\n- `pl.Boolean`: For logical values (True/False)\n- `pl.Int8`, `pl.Int16`, `pl.Int32`, `pl.Int64`: For integers of different sizes\n- `pl.UInt8`, `pl.UInt16`, `pl.UInt32`, `pl.UInt64`: For unsigned integers (positive only)\n- `pl.Float32`, `pl.Float64`: For floating-point numbers\n- `pl.Decimal`: For precise decimal arithmetic\n- `pl.Utf8`: For string data\n- `pl.Categorical`: For categorical (factor) data\n- `pl.Date`, `pl.Time`, `pl.Datetime`: For date and time data\n- `pl.Object`: For Python objects that don't fit the other types\n- `pl.Binary`: For binary data\n- `pl.Struct`: For nested data structures\n\nYou can specify column types in two ways:\n\n1. Using the `schema` or `schema_overrides` parameter when reading data\n2. Using `cast()` to convert columns after reading\n\n::: {#78212620 .cell execution_count=110}\n``` {.python .cell-code}\n# Specify types when reading\ncsv_data = \"\"\"x,y,z\n1,2,3\"\"\"\n\ndf = pl.read_csv(\n    io.StringIO(csv_data),\n    schema_overrides={\n        \"x\": pl.Int32,\n        \"y\": pl.Float64,\n        \"z\": pl.Utf8\n    }\n)\nprint(df.schema)\n\n# Or convert after reading\ndf = pl.read_csv(io.StringIO(csv_data))\ndf = df.with_columns([\n    pl.col(\"x\").cast(pl.Int32),\n    pl.col(\"y\").cast(pl.Float64),\n    pl.col(\"z\").cast(pl.Utf8)\n])\nprint(df.schema)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nSchema({'x': Int32, 'y': Float64, 'z': String})\nSchema({'x': Int32, 'y': Float64, 'z': String})\n```\n:::\n:::\n\n\nYou can also specify a schema for all columns at once:\n\n::: {#492de9eb .cell execution_count=111}\n``` {.python .cell-code}\nschema = {\"x\": pl.Int32, \"y\": pl.Float64, \"z\": pl.Utf8}\ndf = pl.read_csv(io.StringIO(csv_data), schema=schema)\nprint(df.schema)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nSchema({'x': Int32, 'y': Float64, 'z': String})\n```\n:::\n:::\n\n\nIf you want to select only specific columns when reading a file, you can use the `columns` parameter:\n\n::: {#9053b65b .cell execution_count=112}\n``` {.python .cell-code}\ndf = pl.read_csv(io.StringIO(csv_data), columns=[\"x\"])\nprint(df)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nshape: (1, 1)\n┌─────┐\n│ x   │\n│ --- │\n│ i64 │\n╞═════╡\n│ 1   │\n└─────┘\n```\n:::\n:::\n\n\n### Reading data from multiple files\n\nSometimes your data is split across multiple files instead of being contained in a single file. For example, you might have sales data for multiple months, with each month's data in a separate file: `01-sales.csv` for January, `02-sales.csv` for February, and `03-sales.csv` for March.\n\nWith Polars, you can read these files one by one and then concatenate them:\n\n```python\n# List of sales files\nsales_files = [\n    \"data/01-sales.csv\",\n    \"data/02-sales.csv\",\n    \"data/03-sales.csv\"\n]\n\n# Read and concatenate via list comprehension\ndfs = [pl.read_csv(file).with_columns(pl.lit(os.path.basename(file)).alias(\"file\")) \n       for file in sales_files]\nsales = pl.concat(dfs)\nprint(sales)\n```\n\n::: {.callout-tip}\nThis method uses something called List Comprehension, which you can learn more about [here](https://www.w3schools.com/python/python_lists_comprehension.asp).\n:::\n\nYou can download these files from the URLs mentioned in the original chapter, or read them directly:\n\n```python\nsales_files = [\n    \"https://pos.it/r4ds-01-sales\",\n    \"https://pos.it/r4ds-02-sales\",\n    \"https://pos.it/r4ds-03-sales\"\n]\n\ndfs = [pl.read_csv(file).with_columns(pl.lit(file).alias(\"file\")) \n       for file in sales_files]\nsales = pl.concat(dfs)\nprint(sales)\n```\n\nIf you have many files you want to read in, you can use the `glob` module to find the files by matching a pattern:\n\n```python\nimport glob\n\nsales_files = glob.glob(\"data/*-sales.csv\")\nsales_files\n```\n\n### Writing to a file\n\nPolars provides several functions for writing data to disk. The most common are `write_csv()` and `write_parquet()`. The most important arguments to these functions are the `DataFrame` to save and the file path where you want to save it.\n\n```python\nstudents.write_csv(\"students.csv\")\n```\n\nNow let's read that CSV file back in. Note that the variable type information you set up is lost when you save to CSV because you're starting over with reading from a plain text file. This makes CSVs somewhat unreliable for caching interim results—you need to recreate the column specification every time you load in. There are two better alternatives:\n\n1.[Parquet files](https://www.databricks.com/glossary/what-is-parquet) maintain the column types and are generally faster and more space-efficient:\n\n```python\nstudents.write_parquet(\"students.parquet\")\nparquet_students = pl.read_parquet(\"students.parquet\")\n```\n\n2. For Python-specific caching, you can use the [pickle format](https://www.geeksforgeeks.org/understanding-python-pickling-example/) through libraries like `joblib`:\n\n```python\nimport joblib\n\njoblib.dump(students, \"students.joblib\")\njoblib_students = joblib.load(\"students.joblib\")\nprint(joblib_students)\n```\n\nParquet is usually preferable because it's cross-language compatible, more efficient, and maintains your data types.\n\n### Data entry\n\nSometimes you'll need to assemble a `DataFrame` \"by hand\" with a little data entry in your Python script. Polars provides a simple way to create data frames from dictionaries where each key is a column name and each value is a list of values:\n\n::: {#35a7094d .cell execution_count=113}\n``` {.python .cell-code}\ndf = pl.DataFrame({\n    \"x\": [1, 2, 5],\n    \"y\": [\"h\", \"m\", \"g\"],\n    \"z\": [0.08, 0.83, 0.60]\n})\n\ndf\n```\n\n::: {.cell-output .cell-output-display execution_count=112}\n```{=html}\n<div><style>\n.dataframe > thead > tr,\n.dataframe > tbody > tr {\n  text-align: right;\n  white-space: pre-wrap;\n}\n</style>\n<small>shape: (3, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>x</th><th>y</th><th>z</th></tr><tr><td>i64</td><td>str</td><td>f64</td></tr></thead><tbody><tr><td>1</td><td>&quot;h&quot;</td><td>0.08</td></tr><tr><td>2</td><td>&quot;m&quot;</td><td>0.83</td></tr><tr><td>5</td><td>&quot;g&quot;</td><td>0.6</td></tr></tbody></table></div>\n```\n:::\n:::\n\n\nYou can also create a data frame from a list of dictionaries, where each dictionary represents a row:\n\n::: {#474537eb .cell execution_count=114}\n``` {.python .cell-code}\ndf = pl.DataFrame([\n    {\"x\": 1, \"y\": \"h\", \"z\": 0.08},\n    {\"x\": 2, \"y\": \"m\", \"z\": 0.83},\n    {\"x\": 5, \"y\": \"g\", \"z\": 0.60}\n])\n\ndf\n```\n\n::: {.cell-output .cell-output-display execution_count=113}\n```{=html}\n<div><style>\n.dataframe > thead > tr,\n.dataframe > tbody > tr {\n  text-align: right;\n  white-space: pre-wrap;\n}\n</style>\n<small>shape: (3, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>x</th><th>y</th><th>z</th></tr><tr><td>i64</td><td>str</td><td>f64</td></tr></thead><tbody><tr><td>1</td><td>&quot;h&quot;</td><td>0.08</td></tr><tr><td>2</td><td>&quot;m&quot;</td><td>0.83</td></tr><tr><td>5</td><td>&quot;g&quot;</td><td>0.6</td></tr></tbody></table></div>\n```\n:::\n:::\n\n\n### Summary\n\nIn this section, you've learned how to load CSV files with Polars' `pl.read_csv()` and how to do your own data entry by creating DataFrames from dictionaries and lists. You've learned how CSV files work, some of the problems you might encounter, and how to overcome them.\n\nWe'll revisit data import in various formats throughout your Python data science journey, including Excel files, databases, Parquet files, JSON, and data from websites. \n\nPolars is an excellent choice for data handling, as it's designed to take advantage of modern hardware through parallel processing and memory efficiency. As you become more familiar with Python data science tools, you'll appreciate Polars' performance benefits and elegant API design.\n\n## Exercises\n\n1. Does it matter what order you used `DataFrame.filter()` and `DataFrame.sort()` if you’re using both? Why/why not? Think about the results and how much work the functions would have to do.\n\n2. What happens if you specify the name of the same variable multiple times in a `DataFrame.select()` call?\n\n3. Using the `penguins` dataset, make a scatter plot of `bill_depth_mm` vs. `bill_length_mm`. That is, make a scatter plot with `bill_depth_mm` on the y-axis and `bill_length_mm` on the x-axis. Describe the relationship between these two variables.\n\n4. From the `flights` dataset, compare `dep_time`, `sched_dep_time`, and `dep_delay`. How would you expect those three numbers to be related?\n\n5. In a single pipeline for each condition, find all `flights` that meet the condition:\n\n    - Had an arrival delay of two or more hours\n    - Flew to Houston (IAH or HOU)\n    - Were operated by United, American, or Delta\n    - Departed in summer (July, August, and September)\n    - Arrived more than two hours late but didn’t leave late\n    - Were delayed by at least an hour, but made up over 30 minutes in flight\n\n6. Find the flights that are most delayed upon departure from each destination.\n\n7. How do delays vary over the course of the day? Illustrate your answer with a plot.\n\n",
    "supporting": [
      "05-intro-to-data-science_files\\figure-html"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\" data-relocate-top=\"true\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}