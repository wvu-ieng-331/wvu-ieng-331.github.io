[
  {
    "objectID": "learning-modules/05-intro-to-data-science.html",
    "href": "learning-modules/05-intro-to-data-science.html",
    "title": "05 | Introduction to Data Science",
    "section": "",
    "text": "In this beginning chapter, we will cover the fundamentals of data\nanalysis in the form of importing,\ntidying, transforming, and\nvisualizing data, as shown below:\n\n\n\nIn this learning module, you’ll learn how to import, tidy,\ntransform, and visualize data.\n\n\nBy the end of this module, you will be able to:\n\nImport data from various file formats into Python using Polars\nClean and reshape datasets to facilitate analysis\nTransform data through filtering, sorting, and creating new\nvariables\nGroup and aggregate data to identify patterns and trends\nVisualize distributions and relationships using Plotly Express\nApply tidy data principles to structure datasets effectively\n\n\n\nAt this point, you will need to install a few more Python\npackages:\n\n\nterminal\n\nuv add polars[all] plotly[express] statsmodels palmerpenguins nycflights13 billboard\n\nOnce installed, import the following:\n\nimport plotly.express as px\nimport polars as pl\nimport palmerpenguins",
    "crumbs": [
      "Learning Modules",
      "05 | Introduction to Data Science"
    ]
  },
  {
    "objectID": "learning-modules/05-intro-to-data-science.html#overview",
    "href": "learning-modules/05-intro-to-data-science.html#overview",
    "title": "05 | Introduction to Data Science",
    "section": "",
    "text": "In this beginning chapter, we will cover the fundamentals of data\nanalysis in the form of importing,\ntidying, transforming, and\nvisualizing data, as shown below:\n\n\n\nIn this learning module, you’ll learn how to import, tidy,\ntransform, and visualize data.\n\n\nBy the end of this module, you will be able to:\n\nImport data from various file formats into Python using Polars\nClean and reshape datasets to facilitate analysis\nTransform data through filtering, sorting, and creating new\nvariables\nGroup and aggregate data to identify patterns and trends\nVisualize distributions and relationships using Plotly Express\nApply tidy data principles to structure datasets effectively\n\n\n\nAt this point, you will need to install a few more Python\npackages:\n\n\nterminal\n\nuv add polars[all] plotly[express] statsmodels palmerpenguins nycflights13 billboard\n\nOnce installed, import the following:\n\nimport plotly.express as px\nimport polars as pl\nimport palmerpenguins",
    "crumbs": [
      "Learning Modules",
      "05 | Introduction to Data Science"
    ]
  },
  {
    "objectID": "learning-modules/05-intro-to-data-science.html#data-visualization",
    "href": "learning-modules/05-intro-to-data-science.html#data-visualization",
    "title": "05 | Introduction to Data Science",
    "section": "2 Data\nvisualization",
    "text": "2 Data\nvisualization\nPython has several systems for making graphs, but we will be focusing\non Plotly, specifically Plotly Express.\nPlotly Express contains functions that can create entire plots at once,\nand makes it easy to create most common figures.\nThis section will teach you how to visualize your data using\nPlotly Express, walking through visualizing\ndistributions of single variables, as well as relationships between two\nor more variables.\n\n2.1 The\npenguins data frame\nThe dataset we will be working with is a commonly used one,\naffectionately referred to as the Palmer Penguins, which includes body\nmeasurements for penguins on three islands in the Palmer Archipelago. A\ndata frame is a rectangular collection of variables (in\nthe columns) and observations (in the rows). penguins\ncontains 344 observations collected and made available by Dr. Kristen\nGorman and the Palmer Station, Antarctica.\nLet’s define some term:\n\nA variable is a quantity, quality, or property that\nyou can measure.\nA value is the state of a variable when you measure\nit. The value of a variable may change from measurement to\nmeasurement.\nAn observation is a set of measurements made under\nsimilar conditions (you usually make all of the measurements in an\nobservation at the same time and on the same object). An observation\nwill contain several values, each associated with a different variable.\nWe’ll sometimes refer to an observation as a data point.\nTabular data is a set of values, each associated\nwith a variable and an observation. Tabular data is tidy if\neach value is placed in its own “cell”, each variable in its own column,\nand each observation in its own row.\n\nIn this context, a variable refers to an attribute of all the\npenguins, and an observation refers to all the attributes of a single\npenguin.\nWe will use palmerpenguins package to get the\npenguins data, and convert it to a polars data\nframe:\n\npenguins = pl.from_pandas(palmerpenguins.load_penguins())\n\nThe reason we convert to a Polars data frame is because we want to\nuse the tools and methods that come with Polars:\n\ntype(penguins)\n\npolars.dataframe.frame.DataFrame\n\n\nDepending on what tool/IDE you’re using Python with, just having the\nvariable name (penguins) as the last line will print a\nformatted view of the data. If not, you can also use\nprint() to use Polars’ native formatting:\n\npenguins\n\n\nshape: (344, 8)\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\n\n\nstr\nstr\nf64\nf64\nf64\nf64\nstr\ni64\n\n\n\n\n\"Adelie\"\n\"Torgersen\"\n39.1\n18.7\n181.0\n3750.0\n\"male\"\n2007\n\n\n\"Adelie\"\n\"Torgersen\"\n39.5\n17.4\n186.0\n3800.0\n\"female\"\n2007\n\n\n\"Adelie\"\n\"Torgersen\"\n40.3\n18.0\n195.0\n3250.0\n\"female\"\n2007\n\n\n\"Adelie\"\n\"Torgersen\"\nnull\nnull\nnull\nnull\nnull\n2007\n\n\n…\n…\n…\n…\n…\n…\n…\n…\n\n\n\"Chinstrap\"\n\"Dream\"\n43.5\n18.1\n202.0\n3400.0\n\"female\"\n2009\n\n\n\"Chinstrap\"\n\"Dream\"\n49.6\n18.2\n193.0\n3775.0\n\"male\"\n2009\n\n\n\"Chinstrap\"\n\"Dream\"\n50.8\n19.0\n210.0\n4100.0\n\"male\"\n2009\n\n\n\"Chinstrap\"\n\"Dream\"\n50.2\n18.7\n198.0\n3775.0\n\"female\"\n2009\n\n\n\n\n\n\n\nprint(penguins)\n\nshape: (344, 8)\n┌───────────┬───────────┬──────────────┬──────────────┬──────────────┬─────────────┬────────┬──────┐\n│ species   ┆ island    ┆ bill_length_ ┆ bill_depth_m ┆ flipper_leng ┆ body_mass_g ┆ sex    ┆ year │\n│ ---       ┆ ---       ┆ mm           ┆ m            ┆ th_mm        ┆ ---         ┆ ---    ┆ ---  │\n│ str       ┆ str       ┆ ---          ┆ ---          ┆ ---          ┆ f64         ┆ str    ┆ i64  │\n│           ┆           ┆ f64          ┆ f64          ┆ f64          ┆             ┆        ┆      │\n╞═══════════╪═══════════╪══════════════╪══════════════╪══════════════╪═════════════╪════════╪══════╡\n│ Adelie    ┆ Torgersen ┆ 39.1         ┆ 18.7         ┆ 181.0        ┆ 3750.0      ┆ male   ┆ 2007 │\n│ Adelie    ┆ Torgersen ┆ 39.5         ┆ 17.4         ┆ 186.0        ┆ 3800.0      ┆ female ┆ 2007 │\n│ Adelie    ┆ Torgersen ┆ 40.3         ┆ 18.0         ┆ 195.0        ┆ 3250.0      ┆ female ┆ 2007 │\n│ Adelie    ┆ Torgersen ┆ null         ┆ null         ┆ null         ┆ null        ┆ null   ┆ 2007 │\n│ …         ┆ …         ┆ …            ┆ …            ┆ …            ┆ …           ┆ …      ┆ …    │\n│ Chinstrap ┆ Dream     ┆ 43.5         ┆ 18.1         ┆ 202.0        ┆ 3400.0      ┆ female ┆ 2009 │\n│ Chinstrap ┆ Dream     ┆ 49.6         ┆ 18.2         ┆ 193.0        ┆ 3775.0      ┆ male   ┆ 2009 │\n│ Chinstrap ┆ Dream     ┆ 50.8         ┆ 19.0         ┆ 210.0        ┆ 4100.0      ┆ male   ┆ 2009 │\n│ Chinstrap ┆ Dream     ┆ 50.2         ┆ 18.7         ┆ 198.0        ┆ 3775.0      ┆ female ┆ 2009 │\n└───────────┴───────────┴──────────────┴──────────────┴──────────────┴─────────────┴────────┴──────┘\n\n\nThis data frame contains 8 columns. For an alternative view, use\nDataFrame.glimpse(), which is helpful for wide tables that\nhave many columns:\n\npenguins.glimpse()\n\nRows: 344\nColumns: 8\n$ species           &lt;str&gt; 'Adelie', 'Adelie', 'Adelie', 'Adelie', 'Adelie', 'Adelie', 'Adelie', 'Adelie', 'Adelie', 'Adelie'\n$ island            &lt;str&gt; 'Torgersen', 'Torgersen', 'Torgersen', 'Torgersen', 'Torgersen', 'Torgersen', 'Torgersen', 'Torgersen', 'Torgersen', 'Torgersen'\n$ bill_length_mm    &lt;f64&gt; 39.1, 39.5, 40.3, None, 36.7, 39.3, 38.9, 39.2, 34.1, 42.0\n$ bill_depth_mm     &lt;f64&gt; 18.7, 17.4, 18.0, None, 19.3, 20.6, 17.8, 19.6, 18.1, 20.2\n$ flipper_length_mm &lt;f64&gt; 181.0, 186.0, 195.0, None, 193.0, 190.0, 181.0, 195.0, 193.0, 190.0\n$ body_mass_g       &lt;f64&gt; 3750.0, 3800.0, 3250.0, None, 3450.0, 3650.0, 3625.0, 4675.0, 3475.0, 4250.0\n$ sex               &lt;str&gt; 'male', 'female', 'female', None, 'female', 'male', 'female', 'male', None, None\n$ year              &lt;i64&gt; 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007\n\n\n\nAmong these variables are:\n\nspecies: a penguin’s species (Adelie, Chinstrap, or\nGentoo).\nflipper_length_mm: length of a penguin’s flipper, in\nmillimeters.\nbody_mass_g: body mass of a penguin, in grams.\n\n\n\n2.2\nFirst visualization\nOur goal is to recreate the following visual that displays the\nrelationship between flipper lengths and body masses of these penguins,\ntaking into consideration the species of the penguin.\n\n\n        \n        \n        \n\n\n\n\n\n\n\n2.3\nUsing Plotly Express\nWith Plotly Express, you begin a plot by calling a plotting function\nfrom the module, commonly referred to as px. You can then\nadd arguments to your plot function for more customization.\nAt it’s most basic form, the plotting function creates a blank\ncanvas with a grid since we’ve given it no data.\n\npx.scatter()\n\n\n\n\nNext, we need to actually provide data, along with the appropriate\nnumber of variables depending on the type of plot we are trying to\ncreate.\n\npx.scatter(data_frame=penguins, x=\"flipper_length_mm\", y=\"body_mass_g\")\n\n\n\n\npx.scatter() creates a scatter plot, and\nwe will learn many more plot types through out the course. You can learn\nmore about the different plots Plotly Express offers at their gallery.\nThis doesn’t match our “final goal” yet, but using this plot\nwe can start answering the question that motivated our exploration:\n“What does the relationship between flipper length and body mass look\nlike?” The relationship appears to be positive (as flipper length\nincreases, so does body mass), fairly linear (the points are clustered\naround a line instead of a curve), and moderately strong (there isn’t\ntoo much scatter around such a line). Penguins with longer flippers are\ngenerally larger in terms of their body mass.\nBefore we go further, I want to point out that this dataset has some\nmissing values for flipper_length_mm and\nbody_mass_g, but Plotly does not warn you about this when\ncreating the plot. If one and/or other variable is missing data, we\ncannot plot that.\n\n\n2.4\nAdding aesthetics and layers\nScatter plots are useful for displaying the relationship between two\nnumerical variables, but it’s always a good idea to be skeptical of any\napparent relationship between two variables and ask if there may be\nother variables that explain or change the nature of this apparent\nrelationship. For example, does the relationship between flipper length\nand body mass differ by species? Let’s incorporate species into our plot\nand see if this reveals any additional insights into the apparent\nrelationship between these variables. We will do this by representing\nspecies with different colored points.\nTo achieve this, we will use some of the other arguments that\npx.scatter() provides for us, like color:\n\npx.scatter(\n    data_frame=penguins, \n    x=\"flipper_length_mm\", \n    y=\"body_mass_g\", \n    color=\"species\"\n)\n\n\n\n\nWhen a categorical variable is mapped to an aesthetic, Plotly will\nautomatically assign a unique value of the aesthetic (here, a unique\ncolor) to each unique level of the variable (each of the three species),\na process known as scaling. Plotly will also add a\nlegend that explains which value correspond to which levels.\nNow let’s add another layer, a trendline displaying the relationship\nbetween body mass and flipper length. px.scatter() has an\nargument for this, trendline, and a couple other arguments\nthat modify its behavior. Specifically, we want to draw a line of best\nfit using Ordinary Least Squares (ols). You can see the other options,\nand more info about this plotting function with\n?px.scatter() or in the online documentation.\n\npx.scatter(\n    data_frame=penguins, \n    x=\"flipper_length_mm\", \n    y=\"body_mass_g\", \n    color=\"species\",\n    trendline=\"ols\"\n)\n\n\n\n\nWe’ve added lines, but this plot doesn’t look like our final goal,\nwhich only has one line for the entire dataset, opposed to separate\nlines for each of the penguin species. px.scatter() has an\nargument, trendline_scope, which controls how the trendline\nis drawn when there are groups, in this case created when we used\ncolor=\"species\". The default for\ntrendline_scope is \"trace\", which draws a line\nper color, symbol, facet, etc., and \"overall\", which\ncomputes one trendline for the entire dataset,a nd replicates across all\nfacets.\n\npx.scatter(\n    data_frame=penguins, \n    x=\"flipper_length_mm\", \n    y=\"body_mass_g\", \n    color=\"species\",\n    trendline=\"ols\",\n    trendline_scope=\"overall\"\n)\n\n\n\n\nNow we have something that is very close to our final plot, thought\nit’s not there yet. We still need to use different shapes for each\nspecies and improve the labels.\nIt’s generally not a good idea to represent information only using\ncolors on a plot as people perceive colors differently do to color\nblindness or other color vision difference. px.scatter()\nallows us to control the shapes of the dots using the\nsymbol argument.\n\npx.scatter(\n    penguins,\n    x=\"flipper_length_mm\",\n    y=\"body_mass_g\",\n    color=\"species\",\n    symbol=\"species\",\n    trendline=\"ols\",\n    trendline_scope=\"overall\",\n)\n\n\n\n\nNote that the legend is automatically updated to reflect the\ndifferent shapes of the points as well.\nFinally, we can use title, subtitle, and\nlabels arguments to update our labels. title\nand subtitle just take a string, adding labels are bit more\nadvanced. labels takes a dictionary with key:value combos\nfor each of the labels on the plot that you would like to change. In our\nplot, we want to update the labels for the x-axis, y-axis, and the\nlegend, but we refer to them by their current label, not their\nposition:\n\npx.scatter(\n    penguins,\n    x=\"flipper_length_mm\",\n    y=\"body_mass_g\",\n    color=\"species\",\n    symbol=\"species\",\n    trendline=\"ols\",\n    trendline_scope=\"overall\",\n    title=\"Body mass and flipper length\",\n    subtitle=\"Dimensions for Adelie, Chinstrap, and Gentoo Penguins\",\n    labels={\n        \"species\":\"Species\",\n        \"body_mass_g\":\"Body mass (g)\",\n        \"flipper_length_mm\":\"Flipper length (mm)\"\n    }\n)\n\n\n\n\nNow we have our final plot. If you haven’t noticed already, Plotly\ncreates interactive plots, you can hover over certain data\npoints to see their values, use the legend as a filter, and so on. In\nthe top right of every plot, you will see a menu with some options.\n\n\n2.5\nVisualizing distributions\nHow you visualize the distribution of a variable depends on the type\nof the variable: categorical or numerical.\n\n2.5.1\nA categorical variable\nA value is categorical if it can only take one of a\nsmall set of values. To examine the distribution of a categorical\nvariable, you can use a bar chart. The height\nof the bars displays how many observations occurred with each\nx value.\n\npx.bar(penguins, x=\"species\")\n\n\n\n\npx.bar() will result in one rectangle drawn per\nrow of input, which can result in the striped look above. To\ncombine these rectangles into on color per position, we can\npre-calculate the count as and use it as the\ny value:\n\n# we'll learn more about this Polars code later\npenguins_count = penguins.group_by(\"species\").len(\"count\")\nprint(penguins_count)\n\npx.bar(penguins_count, x=\"species\", y=\"count\")\n\nshape: (3, 2)\n┌───────────┬───────┐\n│ species   ┆ count │\n│ ---       ┆ ---   │\n│ str       ┆ u32   │\n╞═══════════╪═══════╡\n│ Adelie    ┆ 152   │\n│ Gentoo    ┆ 124   │\n│ Chinstrap ┆ 68    │\n└───────────┴───────┘\n\n\n\n\n\nThe order of categorical values in axes, legends, and facets depends\non the order in which these values are first encountered in\ndata_frame. It’s often preferable to re-order the bars\nbased on their frequency, which we can do with the\ncategory_orders argument. category_orders\ntakes a dictionary where the keys correspond to column names, and the\nvalues should be lists of strings corresponding to the specific display\norder desired\n\npx.bar(\n    penguins_count,\n    x=\"species\", \n    y=\"count\",\n    category_orders={\"species\": [\"Adelie\", \"Gentoo\", \"Chinstrap\"]}\n)\n\n\n\n\nWhile it’s easy enough to manually sort three columns, this could\nbecome very tedious for more columns. Here is one programmatic way you\ncould sort the columns:\n\npenguins_sorted = (\n    penguins_count\n    .sort(by=\"count\", descending=True)\n    .get_column(\"species\")\n)\n\nprint(penguins_sorted)\n\npx.bar(\n    penguins_count,\n    x=\"species\", \n    y=\"count\",\n    category_orders={\"species\": penguins_sorted}\n)\n\nshape: (3,)\nSeries: 'species' [str]\n[\n    \"Adelie\"\n    \"Gentoo\"\n    \"Chinstrap\"\n]\n\n\n\n\n\nWe will dive into the data manipulation code later, this is just to\nshow what’s possible.\n\n\n2.5.2\nA numerical variable\nA variable is numerical (or quantitative) if it can\ntake on a wide range of numerical values, and it is sensible to add,\nsubtract, or take averages with those values. Numerical variables can be\ncontinuous or discrete.\nOne common visualization for distributions of continuous variables is\na histogram.\n\npx.histogram(penguins, x=\"body_mass_g\")\n\n\n\n\nA histogram divides the x-axis into equally spaced bins and then uses\nthe heigh of the bar to display the number observations that fall in\neach bin. In the graph above, the tallest bar shows that 39 observations\nhave a body_mass_g value between 3,500 and 3,700 grams,\nwhich are the left and right edges of the bar.\nWhen working with histograms, it’s a good idea to use different\nnumber of bins to reveal different patterns in the data. In the plots\nbelow, X bars is too many, resulting in narrow bars. Similarly, 3 bins\nis too few, resulting in all the data being binned into huge categories\nthat make it difficult to determine the shape of the distribution. A bin\nnumber of 20 provides a sensible balance.\npx.histogram(penguins, x=\"body_mass_g\", nbins=200)\npx.histogram(penguins, x=\"body_mass_g\", nbins=3)\npx.histogram(penguins, x=\"body_mass_g\", nbins=20)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAn alternative visualization for distributions of numerical variables\nis a density\nplot. A density plot is a smoothed-out version of a histogram and a\npractical alternative, particularly for continuous data that comes from\nan underlying smooth distribution. At the time of writing, Plotly\nExpress doesn’t have a quick way to create a density plot, but it does\noffer very customizable violin plots, which we can\nmake to look like a density plot if we would like.\n\npx.violin(penguins, x=\"body_mass_g\")\n\n\n\n\nThe density plot is similar to the violin plot, with only one side,\nand the peaks are more exaggerated:\n\npx.violin(\n    penguins, \n    x=\"body_mass_g\", # plots the variable across the x-axis\n    range_y=[\n        0,   # limits the bottom of y-axis, removing reflection\n        0.25 # limits the top of y-axis, stretching the peaks\n    ]\n)\n\n\n\n\nWhile this workaround works, sticking to the original violin plot I\nthink looks better, and we can add some extra arguments to see more\ndetails:\n\npx.violin(penguins, x=\"body_mass_g\", points=\"all\")\n\n\n\n\nPlay around with different arguments and see what you like best!\nAs an analogy to understand these plots vs a histogram, imagine a\nhistogram made out of wooden blocks. Then, imagine that you drop a\ncooked spaghetti string over it. The shape the spaghetti will take\ndraped over blocks can be thought of as the shape of the density curve.\nIt shows fewer details than a histogram but can make it easier to\nquickly glean the shape of the distribution, particularly with respect\nto modes and skewness.\n\n\n\n2.6\nVisualizing relationships\nTo visualize a relationship we need to have at least two variables\nmapped to aesthetics of a plot. In the following sections you will learn\nabout commonly used plots for visualizing relationships between two or\nmore variables and the plots used for creating them.\n\n2.6.1\nA numerical and a categorical variable\nTo visualize the relationship between a numerical and a categorical\nvariable we can use side-by-side box plots. A boxplot is a type of\nvisual shorthand for measures of position (percentiles) that describe a\ndistribution. It is also useful for identifying potential outliers. Each\nboxplot consists of:\n\nA box that indicates the range of the middle half of the data, a\ndistance known as the inter-quartile range (IQR), stretching from the\n25th percentile of the distribution to the 75th percentile. In the\nmiddle of the box is a line that displays the median, i.e. 50th\npercentile, of the distribution. These three lines give you a sense of\nthe spread of the distribution and whether or not the distribution is\nsymmetric about the median or skewed to one side.\nVisual points that display observations that fall more than 1.5\ntimes the IQR from either edge of the box. These outlying points are\nunusual so are plotted individually.\nA line (or whisker) that extends from each end of the box and\ngoes to the farthest non-outlier point in the distribution.\n\n\n\n\n“Diagram depicting how a boxplot is created.”\n\n\nLet’s take a look at the distribution of body mass by species using\npx.box()\n\npx.box(penguins, x=\"species\", y=\"body_mass_g\")\n\n\n\n\nAlternatively, we can make violin plots with multiple groups:\n\npx.violin(penguins, x=\"body_mass_g\", color=\"species\", box=True)\n\n\n\n\nAs we’ve seen before, there are many ways to see and code what we are\nlooking for.\n\n\n2.6.2\nTwo categorical variables\nWe can use stacked bar plots to visualize the relationship between\ntwo categorical variables. For example, the following two stacked bar\nplots both display the relationship between island and\nspecies, or specifically, visualizing the distribution of\nspecies within each island.\nThe first plot shows the frequencies of each species of penguins on\neach island. The plot of frequencies shows that there are equal numbers\nof Adelies on each island. But we don’t have a good sense of the\npercentage balance within each island.\n\npx.bar(penguins, x=\"island\", color=\"species\")\n\n\n\n\nor\n\ndata = penguins.group_by([\"island\", \"species\"]).len(\"count\")\ndata_order = data.group_by(\"island\").agg(pl.col(\"count\").sum()).sort(by=\"count\", descending=True).get_column(\"island\")\n\n\npx.bar(\n    data, x=\"island\", y=\"count\", color=\"species\",\n    category_orders = {\"island\": data_order, \"species\": data_order}\n)\n\n\n\n\n\n\n2.6.3\nTwo numerical variables\nSo far we’ve seen scatter plots for visualizing the relationship\nbetween two numerical variables. A scatter plot is probably the most\ncommonly used plot for visualizing the relationship between to numerical\nvariables.\n\npx.scatter(penguins, x=\"flipper_length_mm\", y=\"body_mass_g\")\n\n\n\n\n\n\n2.6.4\nThree or more variables\nAs we saw before, we can incorporate more variables into a plot by\nmapping them to additional aesthetics. For example, in the following\nplot, the colors of points represent species and the shapes represent\nislands.\n\npx.scatter(\n    penguins, \n    x=\"flipper_length_mm\", y=\"body_mass_g\",\n    color=\"species\", symbol=\"island\"\n)\n\n\n\n\nHowever adding too many aesthetic mappings to a plot makes it\ncluttered and difficult to make sense of. Another way, which is\nparticularly useful for categorical variables, is to split your plot\ninto facets, subplots that each display one subset of\nthe data.\nMost Plotly Express functions provide arguments to facet, just make\nsure to check the documentation.\n\npx.scatter(\n    penguins, \n    x=\"flipper_length_mm\", y=\"body_mass_g\",\n    color=\"species\", symbol=\"island\",\n    facet_col=\"island\"\n)\n\n\n\n\n\n\n\n2.7\nSummary\nIn this section, you’ve learned the basics of data visualization with\nPlotly Express. We started with the basic idea that underpins Plotly\nExpress: a visualization is a mapping from variables in your data to\naesthetic properties like position, color, size and shape. You then\nlearned about increasing the complexity with more arguments in the\nPlotly functions. You also learned about commonly used plots for\nvisualizing the distribution of a single variable as well as for\nvisualizing relationships between two or more variables, by leveraging\nadditional aesthetic mappings and/or splitting your plot into small\nmultiples using faceting.",
    "crumbs": [
      "Learning Modules",
      "05 | Introduction to Data Science"
    ]
  },
  {
    "objectID": "learning-modules/05-intro-to-data-science.html#data-transformation",
    "href": "learning-modules/05-intro-to-data-science.html#data-transformation",
    "title": "05 | Introduction to Data Science",
    "section": "3 Data\ntransformation",
    "text": "3 Data\ntransformation\nVisualization is an important tool for generating insight, but it’s\nrare that you get the data in exactly the right form you need to make\nthe graph you want. Often you’ll need to create some new variables or\nsummaries to answer your questions with your data, or maybe you just\nwant to rename the variables or reorder the observations to make the\ndata a little easier to work with. We’ve already seen examples of this\nabove when creating the bar charts. In this section, we’ll see how to do\nthat with the Polars package.\nThe goal of this section is to give you an overview of all the key\ntools for transforming a data frame. We’ll start with functions that\noperate on rows and then columns of a data frame, then circle back to\ntalk more about method chaining, an important tool that you use to\ncombine functions. We will then introduce the ability to work with\ngroups. We will end the section with a case study that showcases these\nfunctions in action.\n\n3.1 The\nflights data frame\nTo explore basic Polars methods and expressions, we will use the\nflights data frame from the nycflights13\npackage. This dataset contains all 336,776 flights that departed from\nNew York City in 2013.\n\nimport nycflights13\nimport polars as pl\n\nflights = (\n    pl\n    .from_pandas(nycflights13.flights)\n    .with_columns(pl.col(\"time_hour\").str.to_datetime(\"%FT%TZ\"))\n) # We will learn what's going on here in later this section\n\nflights\n\n\nshape: (336_776, 19)\n\n\n\nyear\nmonth\nday\ndep_time\nsched_dep_time\ndep_delay\narr_time\nsched_arr_time\narr_delay\ncarrier\nflight\ntailnum\norigin\ndest\nair_time\ndistance\nhour\nminute\ntime_hour\n\n\ni64\ni64\ni64\nf64\ni64\nf64\nf64\ni64\nf64\nstr\ni64\nstr\nstr\nstr\nf64\ni64\ni64\ni64\ndatetime[μs]\n\n\n\n\n2013\n1\n1\n517.0\n515\n2.0\n830.0\n819\n11.0\n\"UA\"\n1545\n\"N14228\"\n\"EWR\"\n\"IAH\"\n227.0\n1400\n5\n15\n2013-01-01 10:00:00\n\n\n2013\n1\n1\n533.0\n529\n4.0\n850.0\n830\n20.0\n\"UA\"\n1714\n\"N24211\"\n\"LGA\"\n\"IAH\"\n227.0\n1416\n5\n29\n2013-01-01 10:00:00\n\n\n2013\n1\n1\n542.0\n540\n2.0\n923.0\n850\n33.0\n\"AA\"\n1141\n\"N619AA\"\n\"JFK\"\n\"MIA\"\n160.0\n1089\n5\n40\n2013-01-01 10:00:00\n\n\n2013\n1\n1\n544.0\n545\n-1.0\n1004.0\n1022\n-18.0\n\"B6\"\n725\n\"N804JB\"\n\"JFK\"\n\"BQN\"\n183.0\n1576\n5\n45\n2013-01-01 10:00:00\n\n\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n\n\n2013\n9\n30\nnull\n2200\nnull\nnull\n2312\nnull\n\"9E\"\n3525\nnull\n\"LGA\"\n\"SYR\"\nnull\n198\n22\n0\n2013-10-01 02:00:00\n\n\n2013\n9\n30\nnull\n1210\nnull\nnull\n1330\nnull\n\"MQ\"\n3461\n\"N535MQ\"\n\"LGA\"\n\"BNA\"\nnull\n764\n12\n10\n2013-09-30 16:00:00\n\n\n2013\n9\n30\nnull\n1159\nnull\nnull\n1344\nnull\n\"MQ\"\n3572\n\"N511MQ\"\n\"LGA\"\n\"CLE\"\nnull\n419\n11\n59\n2013-09-30 15:00:00\n\n\n2013\n9\n30\nnull\n840\nnull\nnull\n1020\nnull\n\"MQ\"\n3531\n\"N839MQ\"\n\"LGA\"\n\"RDU\"\nnull\n431\n8\n40\n2013-09-30 12:00:00\n\n\n\n\n\n\nflights is a Polars DataFrame.\nDifferent packages have their own version of a data frame with their own\nmethods, functions, etc., but in this course, we will be using Polars.\nPolars provides its own way of working with data frames, as well as\nimporting, exporting, printing, and much more, including the previously\nshown DataFrame.glimpse() method:\n\nflights.glimpse()\n\nRows: 336776\nColumns: 19\n$ year                    &lt;i64&gt; 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013\n$ month                   &lt;i64&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1\n$ day                     &lt;i64&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1\n$ dep_time                &lt;f64&gt; 517.0, 533.0, 542.0, 544.0, 554.0, 554.0, 555.0, 557.0, 557.0, 558.0\n$ sched_dep_time          &lt;i64&gt; 515, 529, 540, 545, 600, 558, 600, 600, 600, 600\n$ dep_delay               &lt;f64&gt; 2.0, 4.0, 2.0, -1.0, -6.0, -4.0, -5.0, -3.0, -3.0, -2.0\n$ arr_time                &lt;f64&gt; 830.0, 850.0, 923.0, 1004.0, 812.0, 740.0, 913.0, 709.0, 838.0, 753.0\n$ sched_arr_time          &lt;i64&gt; 819, 830, 850, 1022, 837, 728, 854, 723, 846, 745\n$ arr_delay               &lt;f64&gt; 11.0, 20.0, 33.0, -18.0, -25.0, 12.0, 19.0, -14.0, -8.0, 8.0\n$ carrier                 &lt;str&gt; 'UA', 'UA', 'AA', 'B6', 'DL', 'UA', 'B6', 'EV', 'B6', 'AA'\n$ flight                  &lt;i64&gt; 1545, 1714, 1141, 725, 461, 1696, 507, 5708, 79, 301\n$ tailnum                 &lt;str&gt; 'N14228', 'N24211', 'N619AA', 'N804JB', 'N668DN', 'N39463', 'N516JB', 'N829AS', 'N593JB', 'N3ALAA'\n$ origin                  &lt;str&gt; 'EWR', 'LGA', 'JFK', 'JFK', 'LGA', 'EWR', 'EWR', 'LGA', 'JFK', 'LGA'\n$ dest                    &lt;str&gt; 'IAH', 'IAH', 'MIA', 'BQN', 'ATL', 'ORD', 'FLL', 'IAD', 'MCO', 'ORD'\n$ air_time                &lt;f64&gt; 227.0, 227.0, 160.0, 183.0, 116.0, 150.0, 158.0, 53.0, 140.0, 138.0\n$ distance                &lt;i64&gt; 1400, 1416, 1089, 1576, 762, 719, 1065, 229, 944, 733\n$ hour                    &lt;i64&gt; 5, 5, 5, 5, 6, 5, 6, 6, 6, 6\n$ minute                  &lt;i64&gt; 15, 29, 40, 45, 0, 58, 0, 0, 0, 0\n$ time_hour      &lt;datetime[μs]&gt; 2013-01-01 10:00:00, 2013-01-01 10:00:00, 2013-01-01 10:00:00, 2013-01-01 10:00:00, 2013-01-01 11:00:00, 2013-01-01 10:00:00, 2013-01-01 11:00:00, 2013-01-01 11:00:00, 2013-01-01 11:00:00, 2013-01-01 11:00:00\n\n\n\nIn both views, the variable names are followed by abbreviations that\ntell you the type of each variable: i64 is short for\ninteger, f64 is short for float, str is short\nfor string, and datetime[μs] for date-time (in this case,\ndown to the micro-seconds).\nWe’re going to learn the primary methods (or contexts as Polars calls\nthem) which will allow yo uto solve the vast majority of your data\nmanipulation challenges. Before we discuss their individual differences,\nit’s worth stating what they have in common:\n\nThe methods are always attached (or chained) to a data frame.\nThe arguments typically describe which columns to operate on.\nThe output is a new data frame (for the most part, ex:\ngroup_by).\n\nBecause each method does one thing well, solving complex problems\nwill usually require combining multiple methods, and we will do so with\nsomething called “method chaining”. You’ve already seen this before,\nthis is when we attach multiple methods together without creating a\nplaceholder variable between steps. You can think of each .\noperator of saying “then”. This should help you get a sense of the\nfollowing code without understanding the details:\n\nflights.filter(\n    pl.col(\"dest\") == \"IAH\"\n).group_by(\n    [\"year\", \"month\", \"day\"]\n).agg( # \"aggregate\", or summarize\n    arr_delay=pl.col(\"arr_delay\").mean()\n)\n\n\nshape: (365, 4)\n\n\n\nyear\nmonth\nday\narr_delay\n\n\ni64\ni64\ni64\nf64\n\n\n\n\n2013\n11\n27\n-0.73913\n\n\n2013\n12\n16\n-8.181818\n\n\n2013\n9\n11\n-20.55\n\n\n2013\n8\n3\n-3.944444\n\n\n…\n…\n…\n…\n\n\n2013\n2\n22\n7.35\n\n\n2013\n10\n5\n-12.466667\n\n\n2013\n10\n29\n1.0\n\n\n2013\n10\n30\n9.571429\n\n\n\n\n\n\nWe can also write the previous code in a cleaner format. When\nsurrounded by parenthesis, the . operator does not have to\n“touch” the closing method before it:\n(\n    flights\n    .filter(pl.col(\"dest\") == \"IAH\")\n    .group_by([\"year\", \"month\", \"day\"])\n    .agg(arr_delay=pl.col(\"arr_delay\").mean())\n)\nIf we didn’t use method chaining, we would have to create a bunch of\nintermediate objects:\n\nflights1 = flights.filter(pl.col(\"dest\") == \"IAH\")\nflights2 = flights1.group_by([\"year\", \"month\", \"day\"])\nflights3 = flights2.agg(arr_delay=pl.col(\"arr_delay\").mean())\n\nWhile all of these have their time and place, method chaining\ngenerally produces data analysis code that is easier to write and\nread.\nWe can organize these contexts (methods) based on what they operate\non: rows, columns,\ngroups, or tables.\n\n\n3.2\nRows\nThe most important contexts that operate on rows of a dataset are\nDataFrame.filter(), which changes which rows are present\nwithout changing their order, and DataFrame.sort(), which\nchanges the order of the rows without changing which are present. Both\nmethods only affect the rows, and the columns are left unchanged. We’ll\nalso see DataFrame.unique() which returns rows with unique\nvalues. Unlike DataFrame.sort() and\nDataFrame.filter(), it can also optionally modify the\ncolumns.\n\n3.2.1\nDataFrame.filter()\nDataFrame.filter()\nallows you to keep rows based on the values of the columns. The\narguments (also known as predicates) are the conditions that must be\ntrue to keep the row. For example, we could find all flights that\ndeparted more than 120 minutes late:\n\nflights.filter(pl.col(\"dep_delay\") &gt; 120)\n\n\nshape: (9_723, 19)\n\n\n\nyear\nmonth\nday\ndep_time\nsched_dep_time\ndep_delay\narr_time\nsched_arr_time\narr_delay\ncarrier\nflight\ntailnum\norigin\ndest\nair_time\ndistance\nhour\nminute\ntime_hour\n\n\ni64\ni64\ni64\nf64\ni64\nf64\nf64\ni64\nf64\nstr\ni64\nstr\nstr\nstr\nf64\ni64\ni64\ni64\ndatetime[μs]\n\n\n\n\n2013\n1\n1\n848.0\n1835\n853.0\n1001.0\n1950\n851.0\n\"MQ\"\n3944\n\"N942MQ\"\n\"JFK\"\n\"BWI\"\n41.0\n184\n18\n35\n2013-01-01 23:00:00\n\n\n2013\n1\n1\n957.0\n733\n144.0\n1056.0\n853\n123.0\n\"UA\"\n856\n\"N534UA\"\n\"EWR\"\n\"BOS\"\n37.0\n200\n7\n33\n2013-01-01 12:00:00\n\n\n2013\n1\n1\n1114.0\n900\n134.0\n1447.0\n1222\n145.0\n\"UA\"\n1086\n\"N76502\"\n\"LGA\"\n\"IAH\"\n248.0\n1416\n9\n0\n2013-01-01 14:00:00\n\n\n2013\n1\n1\n1540.0\n1338\n122.0\n2020.0\n1825\n115.0\n\"B6\"\n705\n\"N570JB\"\n\"JFK\"\n\"SJU\"\n193.0\n1598\n13\n38\n2013-01-01 18:00:00\n\n\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n\n\n2013\n9\n30\n1951.0\n1649\n182.0\n2157.0\n1903\n174.0\n\"EV\"\n4294\n\"N13988\"\n\"EWR\"\n\"SAV\"\n95.0\n708\n16\n49\n2013-09-30 20:00:00\n\n\n2013\n9\n30\n2053.0\n1815\n158.0\n2310.0\n2054\n136.0\n\"EV\"\n5292\n\"N600QX\"\n\"EWR\"\n\"ATL\"\n91.0\n746\n18\n15\n2013-09-30 22:00:00\n\n\n2013\n9\n30\n2159.0\n1845\n194.0\n2344.0\n2030\n194.0\n\"9E\"\n3320\n\"N906XJ\"\n\"JFK\"\n\"BUF\"\n50.0\n301\n18\n45\n2013-09-30 22:00:00\n\n\n2013\n9\n30\n2235.0\n2001\n154.0\n59.0\n2249\n130.0\n\"B6\"\n1083\n\"N804JB\"\n\"JFK\"\n\"MCO\"\n123.0\n944\n20\n1\n2013-10-01 00:00:00\n\n\n\n\n\n\nWe can use all of the same boolean expressions we’ve learned\nprevious, as well as chain them with & (instead of\nand), | (instead of or), and\n~ (instead of not). Note that Polars is picky\nabout ambiguity, so each condition we check for also has it’s own\nparenthesis, similar to what we might use in a calculator to make sure\nthe order of operations is being followed exactly as we want:\n\n# Flights that departed on January 1\nflights.filter(\n    (pl.col(\"month\") == 1) & (pl.col(\"day\") == 1)\n)\n\n\nshape: (842, 19)\n\n\n\nyear\nmonth\nday\ndep_time\nsched_dep_time\ndep_delay\narr_time\nsched_arr_time\narr_delay\ncarrier\nflight\ntailnum\norigin\ndest\nair_time\ndistance\nhour\nminute\ntime_hour\n\n\ni64\ni64\ni64\nf64\ni64\nf64\nf64\ni64\nf64\nstr\ni64\nstr\nstr\nstr\nf64\ni64\ni64\ni64\ndatetime[μs]\n\n\n\n\n2013\n1\n1\n517.0\n515\n2.0\n830.0\n819\n11.0\n\"UA\"\n1545\n\"N14228\"\n\"EWR\"\n\"IAH\"\n227.0\n1400\n5\n15\n2013-01-01 10:00:00\n\n\n2013\n1\n1\n533.0\n529\n4.0\n850.0\n830\n20.0\n\"UA\"\n1714\n\"N24211\"\n\"LGA\"\n\"IAH\"\n227.0\n1416\n5\n29\n2013-01-01 10:00:00\n\n\n2013\n1\n1\n542.0\n540\n2.0\n923.0\n850\n33.0\n\"AA\"\n1141\n\"N619AA\"\n\"JFK\"\n\"MIA\"\n160.0\n1089\n5\n40\n2013-01-01 10:00:00\n\n\n2013\n1\n1\n544.0\n545\n-1.0\n1004.0\n1022\n-18.0\n\"B6\"\n725\n\"N804JB\"\n\"JFK\"\n\"BQN\"\n183.0\n1576\n5\n45\n2013-01-01 10:00:00\n\n\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n\n\n2013\n1\n1\nnull\n1630\nnull\nnull\n1815\nnull\n\"EV\"\n4308\n\"N18120\"\n\"EWR\"\n\"RDU\"\nnull\n416\n16\n30\n2013-01-01 21:00:00\n\n\n2013\n1\n1\nnull\n1935\nnull\nnull\n2240\nnull\n\"AA\"\n791\n\"N3EHAA\"\n\"LGA\"\n\"DFW\"\nnull\n1389\n19\n35\n2013-01-02 00:00:00\n\n\n2013\n1\n1\nnull\n1500\nnull\nnull\n1825\nnull\n\"AA\"\n1925\n\"N3EVAA\"\n\"LGA\"\n\"MIA\"\nnull\n1096\n15\n0\n2013-01-01 20:00:00\n\n\n2013\n1\n1\nnull\n600\nnull\nnull\n901\nnull\n\"B6\"\n125\n\"N618JB\"\n\"JFK\"\n\"FLL\"\nnull\n1069\n6\n0\n2013-01-01 11:00:00\n\n\n\n\n\n\n\n# Flights that departed in January or February\nflights.filter(\n    (pl.col(\"month\") == 1) | (pl.col(\"month\") == 2)\n)\n\n\nshape: (51_955, 19)\n\n\n\nyear\nmonth\nday\ndep_time\nsched_dep_time\ndep_delay\narr_time\nsched_arr_time\narr_delay\ncarrier\nflight\ntailnum\norigin\ndest\nair_time\ndistance\nhour\nminute\ntime_hour\n\n\ni64\ni64\ni64\nf64\ni64\nf64\nf64\ni64\nf64\nstr\ni64\nstr\nstr\nstr\nf64\ni64\ni64\ni64\ndatetime[μs]\n\n\n\n\n2013\n1\n1\n517.0\n515\n2.0\n830.0\n819\n11.0\n\"UA\"\n1545\n\"N14228\"\n\"EWR\"\n\"IAH\"\n227.0\n1400\n5\n15\n2013-01-01 10:00:00\n\n\n2013\n1\n1\n533.0\n529\n4.0\n850.0\n830\n20.0\n\"UA\"\n1714\n\"N24211\"\n\"LGA\"\n\"IAH\"\n227.0\n1416\n5\n29\n2013-01-01 10:00:00\n\n\n2013\n1\n1\n542.0\n540\n2.0\n923.0\n850\n33.0\n\"AA\"\n1141\n\"N619AA\"\n\"JFK\"\n\"MIA\"\n160.0\n1089\n5\n40\n2013-01-01 10:00:00\n\n\n2013\n1\n1\n544.0\n545\n-1.0\n1004.0\n1022\n-18.0\n\"B6\"\n725\n\"N804JB\"\n\"JFK\"\n\"BQN\"\n183.0\n1576\n5\n45\n2013-01-01 10:00:00\n\n\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n\n\n2013\n2\n28\nnull\n905\nnull\nnull\n1115\nnull\n\"MQ\"\n4478\n\"N722MQ\"\n\"LGA\"\n\"DTW\"\nnull\n502\n9\n5\n2013-02-28 14:00:00\n\n\n2013\n2\n28\nnull\n1115\nnull\nnull\n1310\nnull\n\"MQ\"\n4485\n\"N725MQ\"\n\"LGA\"\n\"CMH\"\nnull\n479\n11\n15\n2013-02-28 16:00:00\n\n\n2013\n2\n28\nnull\n830\nnull\nnull\n1205\nnull\n\"UA\"\n1480\nnull\n\"EWR\"\n\"SFO\"\nnull\n2565\n8\n30\n2013-02-28 13:00:00\n\n\n2013\n2\n28\nnull\n840\nnull\nnull\n1147\nnull\n\"UA\"\n443\nnull\n\"JFK\"\n\"LAX\"\nnull\n2475\n8\n40\n2013-02-28 13:00:00\n\n\n\n\n\n\nThere’s a useful shortcut when you’re combining | and\n==: Expr.is_in(). It keeps rows where the\nvariable equals one of the values on the right:\n\n# A shorter way to select flights that departed in January or February\nflights.filter(\n    pl.col(\"month\").is_in([1, 2])\n)\n\n\nshape: (51_955, 19)\n\n\n\nyear\nmonth\nday\ndep_time\nsched_dep_time\ndep_delay\narr_time\nsched_arr_time\narr_delay\ncarrier\nflight\ntailnum\norigin\ndest\nair_time\ndistance\nhour\nminute\ntime_hour\n\n\ni64\ni64\ni64\nf64\ni64\nf64\nf64\ni64\nf64\nstr\ni64\nstr\nstr\nstr\nf64\ni64\ni64\ni64\ndatetime[μs]\n\n\n\n\n2013\n1\n1\n517.0\n515\n2.0\n830.0\n819\n11.0\n\"UA\"\n1545\n\"N14228\"\n\"EWR\"\n\"IAH\"\n227.0\n1400\n5\n15\n2013-01-01 10:00:00\n\n\n2013\n1\n1\n533.0\n529\n4.0\n850.0\n830\n20.0\n\"UA\"\n1714\n\"N24211\"\n\"LGA\"\n\"IAH\"\n227.0\n1416\n5\n29\n2013-01-01 10:00:00\n\n\n2013\n1\n1\n542.0\n540\n2.0\n923.0\n850\n33.0\n\"AA\"\n1141\n\"N619AA\"\n\"JFK\"\n\"MIA\"\n160.0\n1089\n5\n40\n2013-01-01 10:00:00\n\n\n2013\n1\n1\n544.0\n545\n-1.0\n1004.0\n1022\n-18.0\n\"B6\"\n725\n\"N804JB\"\n\"JFK\"\n\"BQN\"\n183.0\n1576\n5\n45\n2013-01-01 10:00:00\n\n\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n\n\n2013\n2\n28\nnull\n905\nnull\nnull\n1115\nnull\n\"MQ\"\n4478\n\"N722MQ\"\n\"LGA\"\n\"DTW\"\nnull\n502\n9\n5\n2013-02-28 14:00:00\n\n\n2013\n2\n28\nnull\n1115\nnull\nnull\n1310\nnull\n\"MQ\"\n4485\n\"N725MQ\"\n\"LGA\"\n\"CMH\"\nnull\n479\n11\n15\n2013-02-28 16:00:00\n\n\n2013\n2\n28\nnull\n830\nnull\nnull\n1205\nnull\n\"UA\"\n1480\nnull\n\"EWR\"\n\"SFO\"\nnull\n2565\n8\n30\n2013-02-28 13:00:00\n\n\n2013\n2\n28\nnull\n840\nnull\nnull\n1147\nnull\n\"UA\"\n443\nnull\n\"JFK\"\n\"LAX\"\nnull\n2475\n8\n40\n2013-02-28 13:00:00\n\n\n\n\n\n\nWhen you run DataFrame.filter(), Polars executes the\nfiltering operation, creating a new DataFrame, and then prints it. It\ndoesn’t modify the existing flights dataset because Polars\nnever modifies the input (unless when explicitly chosen). To save the\nresult, you need to use the assignment operator, =:\n\njan1 = flights.filter((pl.col(\"month\") == 1) & (pl.col(\"day\") == 1))\njan1\n\n\nshape: (842, 19)\n\n\n\nyear\nmonth\nday\ndep_time\nsched_dep_time\ndep_delay\narr_time\nsched_arr_time\narr_delay\ncarrier\nflight\ntailnum\norigin\ndest\nair_time\ndistance\nhour\nminute\ntime_hour\n\n\ni64\ni64\ni64\nf64\ni64\nf64\nf64\ni64\nf64\nstr\ni64\nstr\nstr\nstr\nf64\ni64\ni64\ni64\ndatetime[μs]\n\n\n\n\n2013\n1\n1\n517.0\n515\n2.0\n830.0\n819\n11.0\n\"UA\"\n1545\n\"N14228\"\n\"EWR\"\n\"IAH\"\n227.0\n1400\n5\n15\n2013-01-01 10:00:00\n\n\n2013\n1\n1\n533.0\n529\n4.0\n850.0\n830\n20.0\n\"UA\"\n1714\n\"N24211\"\n\"LGA\"\n\"IAH\"\n227.0\n1416\n5\n29\n2013-01-01 10:00:00\n\n\n2013\n1\n1\n542.0\n540\n2.0\n923.0\n850\n33.0\n\"AA\"\n1141\n\"N619AA\"\n\"JFK\"\n\"MIA\"\n160.0\n1089\n5\n40\n2013-01-01 10:00:00\n\n\n2013\n1\n1\n544.0\n545\n-1.0\n1004.0\n1022\n-18.0\n\"B6\"\n725\n\"N804JB\"\n\"JFK\"\n\"BQN\"\n183.0\n1576\n5\n45\n2013-01-01 10:00:00\n\n\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n\n\n2013\n1\n1\nnull\n1630\nnull\nnull\n1815\nnull\n\"EV\"\n4308\n\"N18120\"\n\"EWR\"\n\"RDU\"\nnull\n416\n16\n30\n2013-01-01 21:00:00\n\n\n2013\n1\n1\nnull\n1935\nnull\nnull\n2240\nnull\n\"AA\"\n791\n\"N3EHAA\"\n\"LGA\"\n\"DFW\"\nnull\n1389\n19\n35\n2013-01-02 00:00:00\n\n\n2013\n1\n1\nnull\n1500\nnull\nnull\n1825\nnull\n\"AA\"\n1925\n\"N3EVAA\"\n\"LGA\"\n\"MIA\"\nnull\n1096\n15\n0\n2013-01-01 20:00:00\n\n\n2013\n1\n1\nnull\n600\nnull\nnull\n901\nnull\n\"B6\"\n125\n\"N618JB\"\n\"JFK\"\n\"FLL\"\nnull\n1069\n6\n0\n2013-01-01 11:00:00\n\n\n\n\n\n\n\n\n3.2.2\nDataFrame.sort()\nDataFrame.sort()\nchanges the order of the rows based on the value of the columns. It\ntakes a data frame and a set of column names (or more complicated\nexpressions) to order by. If you provide more than one column name, each\nadditional column will be used to break ties in the values of the\npreceding columns. For example, the following code sorts by the\ndeparture time, which is spread over four columns. We get the earliest\nyears first, then within a year, the earliest months, etc.\n\nflights.sort(by=[\"year\", \"month\", \"day\", \"dep_time\"])\n\n\nshape: (336_776, 19)\n\n\n\nyear\nmonth\nday\ndep_time\nsched_dep_time\ndep_delay\narr_time\nsched_arr_time\narr_delay\ncarrier\nflight\ntailnum\norigin\ndest\nair_time\ndistance\nhour\nminute\ntime_hour\n\n\ni64\ni64\ni64\nf64\ni64\nf64\nf64\ni64\nf64\nstr\ni64\nstr\nstr\nstr\nf64\ni64\ni64\ni64\ndatetime[μs]\n\n\n\n\n2013\n1\n1\nnull\n1935\nnull\nnull\n2240\nnull\n\"AA\"\n791\n\"N3EHAA\"\n\"LGA\"\n\"DFW\"\nnull\n1389\n19\n35\n2013-01-02 00:00:00\n\n\n2013\n1\n1\nnull\n1500\nnull\nnull\n1825\nnull\n\"AA\"\n1925\n\"N3EVAA\"\n\"LGA\"\n\"MIA\"\nnull\n1096\n15\n0\n2013-01-01 20:00:00\n\n\n2013\n1\n1\nnull\n1630\nnull\nnull\n1815\nnull\n\"EV\"\n4308\n\"N18120\"\n\"EWR\"\n\"RDU\"\nnull\n416\n16\n30\n2013-01-01 21:00:00\n\n\n2013\n1\n1\nnull\n600\nnull\nnull\n901\nnull\n\"B6\"\n125\n\"N618JB\"\n\"JFK\"\n\"FLL\"\nnull\n1069\n6\n0\n2013-01-01 11:00:00\n\n\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n\n\n2013\n12\n31\n2328.0\n2330\n-2.0\n412.0\n409\n3.0\n\"B6\"\n1389\n\"N651JB\"\n\"EWR\"\n\"SJU\"\n198.0\n1608\n23\n30\n2014-01-01 04:00:00\n\n\n2013\n12\n31\n2332.0\n2245\n47.0\n58.0\n3\n55.0\n\"B6\"\n486\n\"N334JB\"\n\"JFK\"\n\"ROC\"\n60.0\n264\n22\n45\n2014-01-01 03:00:00\n\n\n2013\n12\n31\n2355.0\n2359\n-4.0\n430.0\n440\n-10.0\n\"B6\"\n1503\n\"N509JB\"\n\"JFK\"\n\"SJU\"\n195.0\n1598\n23\n59\n2014-01-01 04:00:00\n\n\n2013\n12\n31\n2356.0\n2359\n-3.0\n436.0\n445\n-9.0\n\"B6\"\n745\n\"N665JB\"\n\"JFK\"\n\"PSE\"\n200.0\n1617\n23\n59\n2014-01-01 04:00:00\n\n\n\n\n\n\nYou can use positional arguments to sort by multiple columns in the\nsame way:\n\nflights.sort(\n    by=[\"year\", \"month\", \"day\", \"dep_time\"],\n    descending=[False, False, False, True]\n)\n\n\nshape: (336_776, 19)\n\n\n\nyear\nmonth\nday\ndep_time\nsched_dep_time\ndep_delay\narr_time\nsched_arr_time\narr_delay\ncarrier\nflight\ntailnum\norigin\ndest\nair_time\ndistance\nhour\nminute\ntime_hour\n\n\ni64\ni64\ni64\nf64\ni64\nf64\nf64\ni64\nf64\nstr\ni64\nstr\nstr\nstr\nf64\ni64\ni64\ni64\ndatetime[μs]\n\n\n\n\n2013\n1\n1\nnull\n600\nnull\nnull\n901\nnull\n\"B6\"\n125\n\"N618JB\"\n\"JFK\"\n\"FLL\"\nnull\n1069\n6\n0\n2013-01-01 11:00:00\n\n\n2013\n1\n1\nnull\n1500\nnull\nnull\n1825\nnull\n\"AA\"\n1925\n\"N3EVAA\"\n\"LGA\"\n\"MIA\"\nnull\n1096\n15\n0\n2013-01-01 20:00:00\n\n\n2013\n1\n1\nnull\n1935\nnull\nnull\n2240\nnull\n\"AA\"\n791\n\"N3EHAA\"\n\"LGA\"\n\"DFW\"\nnull\n1389\n19\n35\n2013-01-02 00:00:00\n\n\n2013\n1\n1\nnull\n1630\nnull\nnull\n1815\nnull\n\"EV\"\n4308\n\"N18120\"\n\"EWR\"\n\"RDU\"\nnull\n416\n16\n30\n2013-01-01 21:00:00\n\n\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n\n\n2013\n12\n31\n459.0\n500\n-1.0\n655.0\n651\n4.0\n\"US\"\n1895\n\"N557UW\"\n\"EWR\"\n\"CLT\"\n95.0\n529\n5\n0\n2013-12-31 10:00:00\n\n\n2013\n12\n31\n26.0\n2245\n101.0\n129.0\n2353\n96.0\n\"B6\"\n108\n\"N374JB\"\n\"JFK\"\n\"PWM\"\n50.0\n273\n22\n45\n2014-01-01 03:00:00\n\n\n2013\n12\n31\n18.0\n2359\n19.0\n449.0\n444\n5.0\n\"DL\"\n412\n\"N713TW\"\n\"JFK\"\n\"SJU\"\n192.0\n1598\n23\n59\n2014-01-01 04:00:00\n\n\n2013\n12\n31\n13.0\n2359\n14.0\n439.0\n437\n2.0\n\"B6\"\n839\n\"N566JB\"\n\"JFK\"\n\"BQN\"\n189.0\n1576\n23\n59\n2014-01-01 04:00:00\n\n\n\n\n\n\nNote that the number of rows has not changed, we’re only arranging\nthe data, we’re not filtering it.\n\n\n3.2.3\nDataFrame.unique()\nDataFrame.unique()\nfinds all the unique rows in a dataset, so technically, it primarily\noperates on the rows. Most of the time, however, you’ll want the\ndistinct combination of some variables, so you can also optionally\nsupply column names:\n\n# Remove duplicate rows, if any\nflights.unique()\n\n\nshape: (336_776, 19)\n\n\n\nyear\nmonth\nday\ndep_time\nsched_dep_time\ndep_delay\narr_time\nsched_arr_time\narr_delay\ncarrier\nflight\ntailnum\norigin\ndest\nair_time\ndistance\nhour\nminute\ntime_hour\n\n\ni64\ni64\ni64\nf64\ni64\nf64\nf64\ni64\nf64\nstr\ni64\nstr\nstr\nstr\nf64\ni64\ni64\ni64\ndatetime[μs]\n\n\n\n\n2013\n6\n29\n2003.0\n1958\n5.0\n2205.0\n2245\n-40.0\n\"UA\"\n1555\n\"N36207\"\n\"EWR\"\n\"SAN\"\n289.0\n2425\n19\n58\n2013-06-29 23:00:00\n\n\n2013\n8\n30\n539.0\n545\n-6.0\n932.0\n921\n11.0\n\"B6\"\n939\n\"N524JB\"\n\"JFK\"\n\"BQN\"\n192.0\n1576\n5\n45\n2013-08-30 09:00:00\n\n\n2013\n10\n7\n556.0\n600\n-4.0\n702.0\n659\n3.0\n\"US\"\n2167\n\"N766US\"\n\"LGA\"\n\"DCA\"\n46.0\n214\n6\n0\n2013-10-07 10:00:00\n\n\n2013\n2\n13\n1352.0\n1400\n-8.0\n1447.0\n1503\n-16.0\n\"US\"\n2130\n\"N945UW\"\n\"LGA\"\n\"BOS\"\n38.0\n184\n14\n0\n2013-02-13 19:00:00\n\n\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n\n\n2013\n5\n8\n1556.0\n1355\n121.0\n1806.0\n1604\n122.0\n\"EV\"\n4115\n\"N14916\"\n\"EWR\"\n\"SAV\"\n104.0\n708\n13\n55\n2013-05-08 17:00:00\n\n\n2013\n9\n24\n1349.0\n1359\n-10.0\n1452.0\n1511\n-19.0\n\"B6\"\n118\n\"N281JB\"\n\"JFK\"\n\"BOS\"\n40.0\n187\n13\n59\n2013-09-24 17:00:00\n\n\n2013\n8\n3\n2151.0\n2150\n1.0\n38.0\n45\n-7.0\n\"B6\"\n1201\n\"N729JB\"\n\"JFK\"\n\"FLL\"\n137.0\n1069\n21\n50\n2013-08-04 01:00:00\n\n\n2013\n3\n19\n1600.0\n1600\n0.0\n1841.0\n1838\n3.0\n\"DL\"\n847\n\"N648DL\"\n\"LGA\"\n\"ATL\"\n116.0\n762\n16\n0\n2013-03-19 20:00:00\n\n\n\n\n\n\n\n# Find all unique origin and destination pairs\nflights.unique(subset=[\"origin\", \"dest\"])\n\n\nshape: (224, 19)\n\n\n\nyear\nmonth\nday\ndep_time\nsched_dep_time\ndep_delay\narr_time\nsched_arr_time\narr_delay\ncarrier\nflight\ntailnum\norigin\ndest\nair_time\ndistance\nhour\nminute\ntime_hour\n\n\ni64\ni64\ni64\nf64\ni64\nf64\nf64\ni64\nf64\nstr\ni64\nstr\nstr\nstr\nf64\ni64\ni64\ni64\ndatetime[μs]\n\n\n\n\n2013\n1\n1\n1353.0\n1357\n-4.0\n1549.0\n1525\n24.0\n\"EV\"\n4171\n\"N14105\"\n\"EWR\"\n\"MSN\"\n152.0\n799\n13\n57\n2013-01-01 18:00:00\n\n\n2013\n1\n1\n1522.0\n1530\n-8.0\n1731.0\n1725\n6.0\n\"MQ\"\n4146\n\"N902MQ\"\n\"JFK\"\n\"CMH\"\n98.0\n483\n15\n30\n2013-01-01 20:00:00\n\n\n2013\n1\n2\n2044.0\n2005\n39.0\n2229.0\n2158\n31.0\n\"EV\"\n5114\n\"N371CA\"\n\"LGA\"\n\"BHM\"\n143.0\n866\n20\n5\n2013-01-03 01:00:00\n\n\n2013\n1\n1\n914.0\n900\n14.0\n1058.0\n1043\n15.0\n\"UA\"\n783\n\"N810UA\"\n\"EWR\"\n\"CLE\"\n85.0\n404\n9\n0\n2013-01-01 14:00:00\n\n\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n\n\n2013\n1\n1\n615.0\n615\n0.0\n833.0\n842\n-9.0\n\"DL\"\n575\n\"N326NB\"\n\"EWR\"\n\"ATL\"\n120.0\n746\n6\n15\n2013-01-01 11:00:00\n\n\n2013\n11\n2\n1519.0\n1459\n20.0\n1654.0\n1702\n-8.0\n\"DL\"\n567\n\"N329NB\"\n\"JFK\"\n\"STL\"\n129.0\n892\n14\n59\n2013-11-02 18:00:00\n\n\n2013\n10\n1\n955.0\n1000\n-5.0\n1156.0\n1234\n-38.0\n\"9E\"\n3574\n\"N913XJ\"\n\"LGA\"\n\"IND\"\n93.0\n660\n10\n0\n2013-10-01 14:00:00\n\n\n2013\n1\n1\n2016.0\n1930\n46.0\nnull\n2220\nnull\n\"EV\"\n4204\n\"N14168\"\n\"EWR\"\n\"OKC\"\nnull\n1325\n19\n30\n2013-01-02 00:00:00\n\n\n\n\n\n\nIt should be noted that the default argument for keep is\nany, which does not give any guarantee of which\nunique rows are kept. If you dataset is ordered, you might want\nto use one of the other options for keep.\nIf you want the number of occurrences instead, you’ll need to use a\ncombination of DataFrame.group_by along with a\nGroupBy.agg().\n\n\n\n3.3\nColumns\nThere are two important contexts that affect the columns without\nchanging the rows: DataFrame.with_columns(), which creates\nnew columns that are derived from the existing columns, &\nselect(), which changes which columns are present.\n\n3.3.1\nDataFrame.with_columns()\nThe job of DataFrame.with_columns()\nis to add new columns. In the Data Wrangling module, you will learn a\nlarge set of functions that you can use to manipulate different types of\nvariables. For new, we’ll stick with basic algebra, which allows us to\ncompute the gain, how much time a delayed flight made up in\nthe air, and the speed in miles per hour:\n\nflights.with_columns(\n    gain = pl.col(\"dep_delay\") - pl.col(\"arr_delay\"),\n    speed = pl.col(\"distance\") / pl.col(\"air_time\") * 60\n)\n\n\nshape: (336_776, 21)\n\n\n\nyear\nmonth\nday\ndep_time\nsched_dep_time\ndep_delay\narr_time\nsched_arr_time\narr_delay\ncarrier\nflight\ntailnum\norigin\ndest\nair_time\ndistance\nhour\nminute\ntime_hour\ngain\nspeed\n\n\ni64\ni64\ni64\nf64\ni64\nf64\nf64\ni64\nf64\nstr\ni64\nstr\nstr\nstr\nf64\ni64\ni64\ni64\ndatetime[μs]\nf64\nf64\n\n\n\n\n2013\n1\n1\n517.0\n515\n2.0\n830.0\n819\n11.0\n\"UA\"\n1545\n\"N14228\"\n\"EWR\"\n\"IAH\"\n227.0\n1400\n5\n15\n2013-01-01 10:00:00\n-9.0\n370.044053\n\n\n2013\n1\n1\n533.0\n529\n4.0\n850.0\n830\n20.0\n\"UA\"\n1714\n\"N24211\"\n\"LGA\"\n\"IAH\"\n227.0\n1416\n5\n29\n2013-01-01 10:00:00\n-16.0\n374.273128\n\n\n2013\n1\n1\n542.0\n540\n2.0\n923.0\n850\n33.0\n\"AA\"\n1141\n\"N619AA\"\n\"JFK\"\n\"MIA\"\n160.0\n1089\n5\n40\n2013-01-01 10:00:00\n-31.0\n408.375\n\n\n2013\n1\n1\n544.0\n545\n-1.0\n1004.0\n1022\n-18.0\n\"B6\"\n725\n\"N804JB\"\n\"JFK\"\n\"BQN\"\n183.0\n1576\n5\n45\n2013-01-01 10:00:00\n17.0\n516.721311\n\n\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n\n\n2013\n9\n30\nnull\n2200\nnull\nnull\n2312\nnull\n\"9E\"\n3525\nnull\n\"LGA\"\n\"SYR\"\nnull\n198\n22\n0\n2013-10-01 02:00:00\nnull\nnull\n\n\n2013\n9\n30\nnull\n1210\nnull\nnull\n1330\nnull\n\"MQ\"\n3461\n\"N535MQ\"\n\"LGA\"\n\"BNA\"\nnull\n764\n12\n10\n2013-09-30 16:00:00\nnull\nnull\n\n\n2013\n9\n30\nnull\n1159\nnull\nnull\n1344\nnull\n\"MQ\"\n3572\n\"N511MQ\"\n\"LGA\"\n\"CLE\"\nnull\n419\n11\n59\n2013-09-30 15:00:00\nnull\nnull\n\n\n2013\n9\n30\nnull\n840\nnull\nnull\n1020\nnull\n\"MQ\"\n3531\n\"N839MQ\"\n\"LGA\"\n\"RDU\"\nnull\n431\n8\n40\n2013-09-30 12:00:00\nnull\nnull\n\n\n\n\n\n\nNote that since we haven’t assigned the result of the above\ncomputation back to flights, the new variables\ngain and speed will only be printed but will\nnot be stored in a data frame. And if we want them to be available in a\ndata frame for future use, we should think carefully about whether we\nwant the result to be assigned back to flights, overwriting\nthe original data frame with many more variables, or to a new object.\nOften, the right answer is a new object that is named informatively to\nindicate its contents, e.g., delay_gain, but you might also\nhave good reasons for overwriting flights.\n\n\n3.3.2\nDataFrame.select()\nIt’s not uncommon to get datasets with hundreds or even thousands of\nvariables. In this situation, the first challenge is often just focusing\non the variables you’re interested in. DataFrame.select()\nallows you to rapidly zoom in on a useful subset using operations based\non the names of the variables:\n\nSelect columns by name:\n\n\nflights.select(\"year\")\n\n\nshape: (336_776, 1)\n\n\n\nyear\n\n\ni64\n\n\n\n\n2013\n\n\n2013\n\n\n2013\n\n\n2013\n\n\n…\n\n\n2013\n\n\n2013\n\n\n2013\n\n\n2013\n\n\n\n\n\n\n\nSelect multiple columns by passing a list of column names:\n\n\nflights.select([\"year\", \"month\", \"day\"])\n\n\nshape: (336_776, 3)\n\n\n\nyear\nmonth\nday\n\n\ni64\ni64\ni64\n\n\n\n\n2013\n1\n1\n\n\n2013\n1\n1\n\n\n2013\n1\n1\n\n\n2013\n1\n1\n\n\n…\n…\n…\n\n\n2013\n9\n30\n\n\n2013\n9\n30\n\n\n2013\n9\n30\n\n\n2013\n9\n30\n\n\n\n\n\n\n\nMultiple columns can also be selected using positional arguments\ninstead of a list. Expressions are also accepted:\n\n\nflights.select(\n    pl.col(\"year\"),\n    pl.col(\"month\"),\n    month_add_one = pl.col(\"month\") + 1 # Adds 1 to the values of \"month\"\n)\n\n\nshape: (336_776, 3)\n\n\n\nyear\nmonth\nmonth_add_one\n\n\ni64\ni64\ni64\n\n\n\n\n2013\n1\n2\n\n\n2013\n1\n2\n\n\n2013\n1\n2\n\n\n2013\n1\n2\n\n\n…\n…\n…\n\n\n2013\n9\n10\n\n\n2013\n9\n10\n\n\n2013\n9\n10\n\n\n2013\n9\n10\n\n\n\n\n\n\nPolars also provides more advanced way to select columns using its Selectors.\nSelectors allow for more intuitive selection of columns from DataFrame\nobjects based on their name, type, or other properties. They unify and\nbuild on the related functionality that is available through the\npl.col() expression and can also broadcast expressions over\nthe selected columns.\nSelectors are available as functions imported from\npolars.selectors. Typical/recommended usage is to import\nthe module as cs and employ selectors from there.\n\nimport polars.selectors as cs\nimport polars as pl\n\nThere are a number of selectors you can use within select:\n\ncs.starts_with(\"abc\"): matches column names that begin\nwith “abc”.\ncs.ends_with(\"xyz\"): matches column names that end with\n“xyz”.\ncs.contains(\"ijk\"): matches column names that contain\n“ijk”.\ncs.matches(r\"\\d{3}\"): matches column names using regex,\ncolumns with three digits repeating in the name in this case.\ncs.temporal(): matches columns with temporal (time)\ndata types.\ncs.string(): matches columns with string data\ntypes.\n\nThese are just a few, you can see all the selectors with examples in\nthe documentation, or by looking at the options after typing\ncs. in your editor.\nYou can combine selectors with the following set\noperations:\n\n\n\nOperation\nExpression\n\n\n\n\nUNION\nA | B\n\n\nINTERSECTION\nA & B\n\n\nDIFFERENCE\nA - B\n\n\nSYMMETRIC DIFFERENCE\nA ^ B\n\n\nCOMPLEMENT\n~A\n\n\n\n\nflights.select(cs.temporal() | cs.string())\n\n\nshape: (336_776, 5)\n\n\n\ncarrier\ntailnum\norigin\ndest\ntime_hour\n\n\nstr\nstr\nstr\nstr\ndatetime[μs]\n\n\n\n\n\"UA\"\n\"N14228\"\n\"EWR\"\n\"IAH\"\n2013-01-01 10:00:00\n\n\n\"UA\"\n\"N24211\"\n\"LGA\"\n\"IAH\"\n2013-01-01 10:00:00\n\n\n\"AA\"\n\"N619AA\"\n\"JFK\"\n\"MIA\"\n2013-01-01 10:00:00\n\n\n\"B6\"\n\"N804JB\"\n\"JFK\"\n\"BQN\"\n2013-01-01 10:00:00\n\n\n…\n…\n…\n…\n…\n\n\n\"9E\"\nnull\n\"LGA\"\n\"SYR\"\n2013-10-01 02:00:00\n\n\n\"MQ\"\n\"N535MQ\"\n\"LGA\"\n\"BNA\"\n2013-09-30 16:00:00\n\n\n\"MQ\"\n\"N511MQ\"\n\"LGA\"\n\"CLE\"\n2013-09-30 15:00:00\n\n\n\"MQ\"\n\"N839MQ\"\n\"LGA\"\n\"RDU\"\n2013-09-30 12:00:00\n\n\n\n\n\n\nNote that both individual selector results and selector set\noperations will always return matching columns in the same order as the\nunderlying DataFrame schema.\n\n\n\n3.4\nGroups\nSo far, we’ve learned about contexts (DataFrame methods) that work\nwith rows and columns. Polars gets even more powerful when\nyou add in the ability to work with groups. In this section, we’ll focus\non the most important contexts: DataFrame.group_by(),\nDataFrame.agg(), and the various slice-ing\ncontexts.\n\n3.4.1\nDataFrame.group_by()\nUse DataFrame.group_by()\nto divide your dataset into groups meaningful for your analysis:\n\nflights.group_by(\"month\")\n\n&lt;polars.dataframe.group_by.GroupBy at 0x29dc0cc6ff0&gt;\n\n\nAs you can see, DataFrame.group_by() doesn’t change the\ndata, but returns a GroupBy\nobject. This acts like a DataFrame, but subsequent\noperations will now work “by month”, and comes with some extra\nmethods.\n\n\n3.4.2\nGroupBy.agg()\nThe most important grouped operation is an aggregation, which, if\nbeing used to calculate a single summary statistic, reduces the data\nframe to have a single row for each group. In Polars, this operation is\nperformed by GroupBy.agg(),\nas shown by the following example, which computes the average departure\ndelay by month:\n\n(\n    flights\n    .group_by(\"month\")\n    .agg(avg_delay = pl.col(\"dep_delay\").mean())\n)\n\n\nshape: (12, 2)\n\n\n\nmonth\navg_delay\n\n\ni64\nf64\n\n\n\n\n1\n10.036665\n\n\n10\n6.243988\n\n\n12\n16.576688\n\n\n6\n20.846332\n\n\n…\n…\n\n\n3\n13.227076\n\n\n11\n5.435362\n\n\n5\n12.986859\n\n\n9\n6.722476\n\n\n\n\n\n\nThere are two things to note:\n\nPolars automatically drops the missing values in\ndep_delay when calculating the mean.\nPolars has a few different methods called mean(), but\nthey do different things depending on root object\n(DataFrame, GroupBy, Expr,\netc.)\n\nYou can create any number of aggregations in a single call to\nGroupBy.agg(). You’ll learn various useful summaries in\nlater modules, but one very useful summary is pl.len(),\nwhich returns the number of rows in each group:\n\n(\n    flights\n    .group_by(\"month\")\n    .agg(\n        avg_delay = pl.col(\"dep_delay\").mean(),\n        n = pl.len()\n    )\n    .sort(\"month\")\n)\n\n\nshape: (12, 3)\n\n\n\nmonth\navg_delay\nn\n\n\ni64\nf64\nu32\n\n\n\n\n1\n10.036665\n27004\n\n\n2\n10.816843\n24951\n\n\n3\n13.227076\n28834\n\n\n4\n13.938038\n28330\n\n\n…\n…\n…\n\n\n9\n6.722476\n27574\n\n\n10\n6.243988\n28889\n\n\n11\n5.435362\n27268\n\n\n12\n16.576688\n28135\n\n\n\n\n\n\nMeans and counts can get you a surprisingly long way in data\nscience!\n\n\n3.4.3\nSlicing functions\nThere are a few ways Polars provides for you to extract specific rows\nwithin each group:\n\nGroupBy.head(n = 1) takes the first row from each\ngroup. (Also works with DataFrame)\nGroupBy.tail(n = 1) takes the last row from each group.\n(Also works with DataFrame)\n\nGroupBy also provides some powerful aggregations for\nwhole groups, like:\n\nflights.group_by(\"dest\").max() # shows max value for each group and column\nflights.group_by(\"dest\").min() # shows min value for each group and column\n\n\nshape: (105, 19)\n\n\n\ndest\nyear\nmonth\nday\ndep_time\nsched_dep_time\ndep_delay\narr_time\nsched_arr_time\narr_delay\ncarrier\nflight\ntailnum\norigin\nair_time\ndistance\nhour\nminute\ntime_hour\n\n\nstr\ni64\ni64\ni64\nf64\ni64\nf64\nf64\ni64\nf64\nstr\ni64\nstr\nstr\nf64\ni64\ni64\ni64\ndatetime[μs]\n\n\n\n\n\"MVY\"\n2013\n5\n1\n817.0\n829\n-18.0\n914.0\n946\n-33.0\n\"9E\"\n1338\n\"N178JB\"\n\"JFK\"\n30.0\n173\n8\n10\n2013-05-16 17:00:00\n\n\n\"JAC\"\n2013\n1\n1\n802.0\n800\n-13.0\n1111.0\n1102\n-17.0\n\"DL\"\n1162\n\"N13716\"\n\"EWR\"\n248.0\n1874\n8\n0\n2013-01-01 13:00:00\n\n\n\"MCO\"\n2013\n1\n1\n2.0\n550\n-21.0\n1.0\n3\n-63.0\n\"AA\"\n4\n\"D942DN\"\n\"EWR\"\n107.0\n937\n5\n0\n2013-01-01 11:00:00\n\n\n\"MHT\"\n2013\n1\n1\n6.0\n647\n-17.0\n1.0\n800\n-37.0\n\"9E\"\n3255\n\"N10156\"\n\"EWR\"\n31.0\n195\n6\n0\n2013-01-01 18:00:00\n\n\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n\n\n\"BWI\"\n2013\n1\n1\n8.0\n600\n-18.0\n5.0\n30\n-53.0\n\"9E\"\n63\n\"N10156\"\n\"EWR\"\n31.0\n169\n6\n0\n2013-01-01 11:00:00\n\n\n\"BDL\"\n2013\n1\n1\n15.0\n527\n-15.0\n3.0\n628\n-43.0\n\"EV\"\n471\n\"N10156\"\n\"EWR\"\n20.0\n116\n5\n0\n2013-01-01 18:00:00\n\n\n\"MDW\"\n2013\n1\n1\n1.0\n600\n-13.0\n1.0\n715\n-49.0\n\"WN\"\n1\n\"N200WN\"\n\"EWR\"\n92.0\n711\n6\n0\n2013-01-01 13:00:00\n\n\n\"ANC\"\n2013\n7\n3\n1613.0\n1615\n-2.0\n1906.0\n1953\n-47.0\n\"UA\"\n887\n\"N528UA\"\n\"EWR\"\n388.0\n3370\n16\n15\n2013-07-06 20:00:00\n\n\n\n\n\n\nIf you want the top/bottom k number of rows (optionally\nby group), use the DataFrame.top_k or\nDataFrame.bottom_k contexts:\n\nflights.top_k(k = 4, by = \"arr_delay\")\nflights.bottom_k(k = 4, by = \"arr_delay\")\n\n\nshape: (4, 19)\n\n\n\nyear\nmonth\nday\ndep_time\nsched_dep_time\ndep_delay\narr_time\nsched_arr_time\narr_delay\ncarrier\nflight\ntailnum\norigin\ndest\nair_time\ndistance\nhour\nminute\ntime_hour\n\n\ni64\ni64\ni64\nf64\ni64\nf64\nf64\ni64\nf64\nstr\ni64\nstr\nstr\nstr\nf64\ni64\ni64\ni64\ndatetime[μs]\n\n\n\n\n2013\n5\n7\n1715.0\n1729\n-14.0\n1944.0\n2110\n-86.0\n\"VX\"\n193\n\"N843VA\"\n\"EWR\"\n\"SFO\"\n315.0\n2565\n17\n29\n2013-05-07 21:00:00\n\n\n2013\n5\n20\n719.0\n735\n-16.0\n951.0\n1110\n-79.0\n\"VX\"\n11\n\"N840VA\"\n\"JFK\"\n\"SFO\"\n316.0\n2586\n7\n35\n2013-05-20 11:00:00\n\n\n2013\n5\n2\n1947.0\n1949\n-2.0\n2209.0\n2324\n-75.0\n\"UA\"\n612\n\"N851UA\"\n\"EWR\"\n\"LAX\"\n300.0\n2454\n19\n49\n2013-05-02 23:00:00\n\n\n2013\n5\n6\n1826.0\n1830\n-4.0\n2045.0\n2200\n-75.0\n\"AA\"\n269\n\"N3KCAA\"\n\"JFK\"\n\"SEA\"\n289.0\n2422\n18\n30\n2013-05-06 22:00:00\n\n\n\n\n\n\n\n\n3.4.4\nGrouping by multiple variables\nYou can create groups using more than one variable. For example, we\ncould make a group for each date:\n\ndaily = (\n    flights\n    .group_by([\"year\", \"month\", \"day\"])\n)\n\ndaily.max()\n\n\nshape: (365, 19)\n\n\n\nyear\nmonth\nday\ndep_time\nsched_dep_time\ndep_delay\narr_time\nsched_arr_time\narr_delay\ncarrier\nflight\ntailnum\norigin\ndest\nair_time\ndistance\nhour\nminute\ntime_hour\n\n\ni64\ni64\ni64\nf64\ni64\nf64\nf64\ni64\nf64\nstr\ni64\nstr\nstr\nstr\nf64\ni64\ni64\ni64\ndatetime[μs]\n\n\n\n\n2013\n4\n26\n2358.0\n2359\n275.0\n2358.0\n2359\n252.0\n\"YV\"\n5793\n\"N993DL\"\n\"LGA\"\n\"XNA\"\n614.0\n4983\n23\n59\n2013-04-27 03:00:00\n\n\n2013\n5\n18\n2356.0\n2359\n369.0\n2359.0\n2358\n362.0\n\"WN\"\n5769\n\"N9EAMQ\"\n\"LGA\"\n\"TPA\"\n618.0\n4983\n23\n59\n2013-05-19 03:00:00\n\n\n2013\n6\n30\n2359.0\n2359\n437.0\n2400.0\n2359\n469.0\n\"YV\"\n6177\n\"N998AT\"\n\"LGA\"\n\"XNA\"\n601.0\n4983\n23\n59\n2013-07-01 03:00:00\n\n\n2013\n9\n13\n2352.0\n2359\n245.0\n2359.0\n2359\n236.0\n\"YV\"\n6177\n\"N9EAMQ\"\n\"LGA\"\n\"XNA\"\n605.0\n4983\n23\n59\n2013-09-14 03:00:00\n\n\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n\n\n2013\n6\n9\n2356.0\n2359\n246.0\n2359.0\n2359\n239.0\n\"YV\"\n6177\n\"N9EAMQ\"\n\"LGA\"\n\"XNA\"\n617.0\n4983\n23\n59\n2013-06-10 03:00:00\n\n\n2013\n10\n14\n2347.0\n2359\n702.0\n2356.0\n2359\n688.0\n\"YV\"\n6181\n\"N994DL\"\n\"LGA\"\n\"XNA\"\n631.0\n4983\n23\n59\n2013-10-15 03:00:00\n\n\n2013\n10\n2\n2341.0\n2359\n306.0\n2400.0\n2359\n272.0\n\"YV\"\n6181\n\"N9EAMQ\"\n\"LGA\"\n\"XNA\"\n623.0\n4983\n23\n59\n2013-10-03 03:00:00\n\n\n2013\n1\n23\n2358.0\n2359\n478.0\n2359.0\n2359\n486.0\n\"YV\"\n6055\n\"N989DL\"\n\"LGA\"\n\"XNA\"\n653.0\n4983\n23\n59\n2013-01-24 04:00:00\n\n\n\n\n\n\nGroupBy methods return a DataFrame, so\nthere is no need to explicitly “un-group” your dataset.\n\n\n\n3.5\nSummary\nIn this chapter, you’ve learned the tools that Polars provides for\nworking with data frames. The tools are roughly grouped into three\ncategories: those that manipulate the rows (like\nDataFrame.filter() and DataFrame.sort()) those\nthat manipulate the columns (like DataFrame.select() and\nDataFrame.with_columns()) and those that manipulate groups\n(like DataFrame.group_by() and GroupBy.agg()).\nIn this chapter, we’ve focused on these “whole data frame” tools, but\nyou haven’t yet learned much about what you can do with the individual\nvariable. We’ll return to that in a later module in the course, where\neach section provides tools for a specific type of variable.",
    "crumbs": [
      "Learning Modules",
      "05 | Introduction to Data Science"
    ]
  },
  {
    "objectID": "learning-modules/05-intro-to-data-science.html#data-tidying",
    "href": "learning-modules/05-intro-to-data-science.html#data-tidying",
    "title": "05 | Introduction to Data Science",
    "section": "4 Data\ntidying",
    "text": "4 Data\ntidying\nIn this section, you will learn a consistent way to organize your\ndata in Python using a system called tidy data. Getting\nyour data into this format requires some work up front, but that work\npays off in the long term. Once you have tidy data, you will spend much\nless time munging data from one representation to another, allowing you\nto spend more time on the data questions you care about.\nYou’ll first learn the definition of tidy data and see it applied to\na simple toy dataset. Then we’ll dive into the primary tool you’ll use\nfor tidying data: pivoting. Pivoting allows you to change the form of\nyour data without changing any of the values.\n\nimport polars as pl\nimport polars.selectors as cs\nimport plotly.express as px\n\n\n4.1\nTidy data\nYou can represent the same underlying data in multiple ways. The\nexample below shows the same data organized in three different ways.\nEach dataset shows the same values of four variables:\ncountry, year, population, and\nnumber of documented cases of TB (tuberculosis), but each\ndataset organizes the values in a different way.\n\ntable1\n\n\nshape: (6, 4)\n\n\n\ncountry\nyear\ncases\npopulation\n\n\nstr\ni64\ni64\ni64\n\n\n\n\n\"Afghanistan\"\n1999\n745\n19987071\n\n\n\"Afghanistan\"\n2000\n2666\n20595360\n\n\n\"Brazil\"\n1999\n37737\n172006362\n\n\n\"Brazil\"\n2000\n80488\n174504898\n\n\n\"China\"\n1999\n212258\n1272915272\n\n\n\"China\"\n2000\n213766\n1280428583\n\n\n\n\n\n\n\ntable2\n\n\nshape: (12, 4)\n\n\n\ncountry\nyear\ntype\ncount\n\n\nstr\ni64\nstr\ni64\n\n\n\n\n\"Afghanistan\"\n1999\n\"cases\"\n745\n\n\n\"Afghanistan\"\n1999\n\"population\"\n19987071\n\n\n\"Afghanistan\"\n2000\n\"cases\"\n2666\n\n\n\"Afghanistan\"\n2000\n\"population\"\n20595360\n\n\n…\n…\n…\n…\n\n\n\"China\"\n1999\n\"cases\"\n212258\n\n\n\"China\"\n1999\n\"population\"\n1272915272\n\n\n\"China\"\n2000\n\"cases\"\n213766\n\n\n\"China\"\n2000\n\"population\"\n1280428583\n\n\n\n\n\n\n\ntable3\n\n\nshape: (6, 3)\n\n\n\ncountry\nyear\nrate\n\n\nstr\ni64\nstr\n\n\n\n\n\"Afghanistan\"\n1999\n\"745/19987071\"\n\n\n\"Afghanistan\"\n2000\n\"2666/20595360\"\n\n\n\"Brazil\"\n1999\n\"37737/172006362\"\n\n\n\"Brazil\"\n2000\n\"80488/174504898\"\n\n\n\"China\"\n1999\n\"212258/1272915272\"\n\n\n\"China\"\n2000\n\"213766/1280428583\"\n\n\n\n\n\n\nThese are all representations of the same underlying data, but they\nare not equally easy to use. One of them, table1, will be\nmuch easier to work with Polars & Plotly because it’s\ntidy.\nThere are three interrelated rules that make a dataset tidy:\n\nEach variable is a column; each column is a variable.\nEach observation is a row; each row is an observation.\nEach value is a cell; each cell is a single value.\n\n\n\n\nThe following three rules make a dataset tidy: variables are\ncolumns, observations are rows, and values are cells.\n\n\nWhy ensure that your data is tidy? There are two main advantages:\n\nThere’s a general advantage to picking one consistent way of\nstoring data. If you have a consistent data structure, it’s easier to\nlearn the tools that work with it because they have an underlying\nuniformity.\nThere’s a specific advantage to placing variables in columns\nbecause it allows Polar’s vectorized nature to shine. Plotly also works\nby default with tidy data formats, and requires (a little) workaround\nfor wide formats.\n\nHere are some examples of how Polars & Plotly work with tidy\ndata:\n\n# Compute rate per 10,000\ntable1.with_columns(\n    rate = pl.col(\"cases\") / pl.col(\"population\") * 1000\n)\n\n\nshape: (6, 5)\n\n\n\ncountry\nyear\ncases\npopulation\nrate\n\n\nstr\ni64\ni64\ni64\nf64\n\n\n\n\n\"Afghanistan\"\n1999\n745\n19987071\n0.037274\n\n\n\"Afghanistan\"\n2000\n2666\n20595360\n0.129447\n\n\n\"Brazil\"\n1999\n37737\n172006362\n0.219393\n\n\n\"Brazil\"\n2000\n80488\n174504898\n0.461236\n\n\n\"China\"\n1999\n212258\n1272915272\n0.16675\n\n\n\"China\"\n2000\n213766\n1280428583\n0.166949\n\n\n\n\n\n\n\n# Compute total cases per year\ntable1.group_by(\"year\").agg(total_cases = pl.col(\"cases\").sum())\n\n\nshape: (2, 2)\n\n\n\nyear\ntotal_cases\n\n\ni64\ni64\n\n\n\n\n1999\n250740\n\n\n2000\n296920\n\n\n\n\n\n\n\n# Visualize changes over time\n\ntable1_datefix = table1.with_columns(\n    date = (pl.col(\"year\").cast(pl.String) + \"-01-01\").str.to_date()\n)\n\npx.line(\n    table1_datefix,\n    x=\"date\",\n    y=\"cases\",\n    color=\"country\",\n    symbol=\"country\",\n    title=\"Cases by Year and Country\",\n)\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nWhile we are covering the basics of tidy data, I highly recommend\nreading Tidy\nData by Hadley Wickham. It’s a short paper on the principles of\nworking with tidy data and it’s benefits.\n\n\n\n\n4.2\nLengthening data\nThe principles of tidy data might seem so obvious that you wonder if\nyou’ll ever encounter a dataset that isn’t tidy. Unfortunately, however,\nmost real data is untidy. There are two main reasons:\n\nData is often organized to facilitate some goal other than\nanalysis. For example, it’s common for data to be structured to make\ndata entry, not analysis, easy.\nMost people aren’t familiar with the principles of tidy data, and\nit’s hard to derive them yourself unless you spend a lot of time working\nwith data.\n\nThis means that most real analyses will require at least a little\ntidying. You’ll begin by figuring out what the underlying variables and\nobservations are. Sometimes this is easy; other times you’ll need to\nconsult with the people who originally generated the data. Next, you’ll\npivot your data into a tidy form, with variables in the\ncolumns and observations in the rows.\nPolars provides two methods for pivoting data:\nDataFrame.pivot() and DataFrame.unpivot().\nWe’ll first start with DataFrame.unpivot() because it’s the\nmost common case. Let’s dive into some examples.\n\n4.2.1\nData in column names\nThe billboard dataset records the billboard rank of\nsongs in the year 2000:\n\nbillboard\n\n\nshape: (317, 79)\n\n\n\nartist\ntrack\ndate.entered\nwk1\nwk2\nwk3\nwk4\nwk5\nwk6\nwk7\nwk8\nwk9\nwk10\nwk11\nwk12\nwk13\nwk14\nwk15\nwk16\nwk17\nwk18\nwk19\nwk20\nwk21\nwk22\nwk23\nwk24\nwk25\nwk26\nwk27\nwk28\nwk29\nwk30\nwk31\nwk32\nwk33\nwk34\n…\nwk40\nwk41\nwk42\nwk43\nwk44\nwk45\nwk46\nwk47\nwk48\nwk49\nwk50\nwk51\nwk52\nwk53\nwk54\nwk55\nwk56\nwk57\nwk58\nwk59\nwk60\nwk61\nwk62\nwk63\nwk64\nwk65\nwk66\nwk67\nwk68\nwk69\nwk70\nwk71\nwk72\nwk73\nwk74\nwk75\nwk76\n\n\nstr\nstr\ndate\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\n…\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\ni64\nstr\nstr\nstr\nstr\nstr\nstr\nstr\nstr\nstr\nstr\nstr\n\n\n\n\n\"2 Pac\"\n\"Baby Don't Cry (Keep...\"\n2000-02-26\n87\n82\n72\n77\n87\n94\n99\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\n…\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\n\n\n\"2Ge+her\"\n\"The Hardest Part Of ...\"\n2000-09-02\n91\n87\n92\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\n…\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\n\n\n\"3 Doors Down\"\n\"Kryptonite\"\n2000-04-08\n81\n70\n68\n67\n66\n57\n54\n53\n51\n51\n51\n51\n47\n44\n38\n28\n22\n18\n18\n14\n12\n7\n6\n6\n6\n5\n5\n4\n4\n4\n4\n3\n3\n3\n…\n15\n14\n13\n14\n16\n17\n21\n22\n24\n28\n33\n42\n42\n49\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\n\n\n\"3 Doors Down\"\n\"Loser\"\n2000-10-21\n76\n76\n72\n69\n67\n65\n55\n59\n62\n61\n61\n59\n61\n66\n72\n76\n75\n67\n73\n70\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\n…\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\n\n\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n…\n\n\n\"Yearwood, Trisha\"\n\"Real Live Woman\"\n2000-04-01\n85\n83\n83\n82\n81\n91\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\n…\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\n\n\n\"Ying Yang Twins\"\n\"Whistle While You Tw...\"\n2000-03-18\n95\n94\n91\n85\n84\n78\n74\n78\n85\n89\n97\n96\n99\n99\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\n…\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\n\n\n\"Zombie Nation\"\n\"Kernkraft 400\"\n2000-09-02\n99\n99\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\n…\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\n\n\n\"matchbox twenty\"\n\"Bent\"\n2000-04-29\n60\n37\n29\n24\n22\n21\n18\n16\n13\n12\n8\n6\n1\n2\n3\n2\n2\n3\n4\n5\n4\n4\n6\n9\n12\n13\n19\n20\n20\n24\n29\n28\n27\n30\n…\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\nnull\n\n\n\n\n\n\nIn this dataset, each observation is a song. The first three columns\n(artist, track, and date.entered)\nare variables that describe the song. Then we have 76 columns,\nwk1-wk76, that describe the rank of the song\nin each week. Here, the column names are one variable (the\nweek) and the cell values are another (the\nrank).\nTo tidy this data, we’ll use DataFrame.unpivot():\n\nbillboard.unpivot(\n    index=[\"artist\", \"track\", \"date.entered\"],\n    variable_name=\"week\",\n    value_name=\"rank\"\n)\n\n\nshape: (24_092, 5)\n\n\n\nartist\ntrack\ndate.entered\nweek\nrank\n\n\nstr\nstr\ndate\nstr\nstr\n\n\n\n\n\"2 Pac\"\n\"Baby Don't Cry (Keep...\"\n2000-02-26\n\"wk1\"\n\"87\"\n\n\n\"2Ge+her\"\n\"The Hardest Part Of ...\"\n2000-09-02\n\"wk1\"\n\"91\"\n\n\n\"3 Doors Down\"\n\"Kryptonite\"\n2000-04-08\n\"wk1\"\n\"81\"\n\n\n\"3 Doors Down\"\n\"Loser\"\n2000-10-21\n\"wk1\"\n\"76\"\n\n\n…\n…\n…\n…\n…\n\n\n\"Yearwood, Trisha\"\n\"Real Live Woman\"\n2000-04-01\n\"wk76\"\nnull\n\n\n\"Ying Yang Twins\"\n\"Whistle While You Tw...\"\n2000-03-18\n\"wk76\"\nnull\n\n\n\"Zombie Nation\"\n\"Kernkraft 400\"\n2000-09-02\n\"wk76\"\nnull\n\n\n\"matchbox twenty\"\n\"Bent\"\n2000-04-29\n\"wk76\"\nnull\n\n\n\n\n\n\nThere are three key arguments:\n\nindex specifies which columns are not\npivoted, i.e. which columns are variables.\nvariable_name names the variable stored in the column\nnames, we named that variable week.\nvalue_name names the variable stored in the cell\nvalues, we named that variable rank.\n\nNow let’s turn our attention to the resulting, longer data frame.\nWhat happens if a song is in the top 100 for less than 76 weeks? Take 2\nPack’s “Baby Don’t Cry”, for example:\n\nbillboard.unpivot(\n    index=[\"artist\", \"track\", \"date.entered\"],\n    variable_name=\"week\",\n    value_name=\"rank\"\n).filter(\n    pl.col(\"artist\") == \"2 Pac\", # using commas is another way to chain multiple ANDs\n    pl.col(\"track\").str.starts_with(\"Baby Don't Cry\")\n)\n\n\nshape: (76, 5)\n\n\n\nartist\ntrack\ndate.entered\nweek\nrank\n\n\nstr\nstr\ndate\nstr\nstr\n\n\n\n\n\"2 Pac\"\n\"Baby Don't Cry (Keep...\"\n2000-02-26\n\"wk1\"\n\"87\"\n\n\n\"2 Pac\"\n\"Baby Don't Cry (Keep...\"\n2000-02-26\n\"wk2\"\n\"82\"\n\n\n\"2 Pac\"\n\"Baby Don't Cry (Keep...\"\n2000-02-26\n\"wk3\"\n\"72\"\n\n\n\"2 Pac\"\n\"Baby Don't Cry (Keep...\"\n2000-02-26\n\"wk4\"\n\"77\"\n\n\n…\n…\n…\n…\n…\n\n\n\"2 Pac\"\n\"Baby Don't Cry (Keep...\"\n2000-02-26\n\"wk73\"\nnull\n\n\n\"2 Pac\"\n\"Baby Don't Cry (Keep...\"\n2000-02-26\n\"wk74\"\nnull\n\n\n\"2 Pac\"\n\"Baby Don't Cry (Keep...\"\n2000-02-26\n\"wk75\"\nnull\n\n\n\"2 Pac\"\n\"Baby Don't Cry (Keep...\"\n2000-02-26\n\"wk76\"\nnull\n\n\n\n\n\n\nThe null in the bottom of the table suggests that this\nsong wasn’t ranked in (at least) weeks 74-76. These nulls\ndon’t really represent unknown observations; they were forced to exist\nby the structure of the dataset, so we can safely filter them out:\n\nbillboard.unpivot(\n    index=[\"artist\", \"track\", \"date.entered\"],\n    variable_name=\"week\",\n    value_name=\"rank\"\n).drop_nulls(\n    # no arguments will drop any row with `null`\n)\n\n\nshape: (5_307, 5)\n\n\n\nartist\ntrack\ndate.entered\nweek\nrank\n\n\nstr\nstr\ndate\nstr\nstr\n\n\n\n\n\"2 Pac\"\n\"Baby Don't Cry (Keep...\"\n2000-02-26\n\"wk1\"\n\"87\"\n\n\n\"2Ge+her\"\n\"The Hardest Part Of ...\"\n2000-09-02\n\"wk1\"\n\"91\"\n\n\n\"3 Doors Down\"\n\"Kryptonite\"\n2000-04-08\n\"wk1\"\n\"81\"\n\n\n\"3 Doors Down\"\n\"Loser\"\n2000-10-21\n\"wk1\"\n\"76\"\n\n\n…\n…\n…\n…\n…\n\n\n\"Lonestar\"\n\"Amazed\"\n1999-06-05\n\"wk63\"\n\"45\"\n\n\n\"Creed\"\n\"Higher\"\n1999-09-11\n\"wk64\"\n\"50\"\n\n\n\"Lonestar\"\n\"Amazed\"\n1999-06-05\n\"wk64\"\n\"50\"\n\n\n\"Creed\"\n\"Higher\"\n1999-09-11\n\"wk65\"\n\"49\"\n\n\n\n\n\n\nThe number of rows is now much lower, indicating that many rows with\nnulls were dropped.\nYou might also wonder what happens if a song is in the top 100 for\nmore than 76 weeks? We can’t tell from this data, but you might guess\nthat additional columns wk77, wk78,\n... would be added to the dataset.\nThis data is now tidy, but we could make future computation a bit\neasier by converting values of week and rank\nfrom character strings to numbers using\nDataFrame.with_columns().\n\nbillboard_longer = (\n    billboard\n    .unpivot(\n        index=[\"artist\", \"track\", \"date.entered\"],\n        variable_name=\"week\",\n        value_name=\"rank\"\n    ).drop_nulls(\n\n    ).with_columns(\n        pl.col(\"week\").str.extract(r\"(\\d+)\").str.to_integer(),\n        pl.col(\"rank\").str.to_integer()\n    )\n)\n\nbillboard_longer\n\n\nshape: (5_307, 5)\n\n\n\nartist\ntrack\ndate.entered\nweek\nrank\n\n\nstr\nstr\ndate\ni64\ni64\n\n\n\n\n\"2 Pac\"\n\"Baby Don't Cry (Keep...\"\n2000-02-26\n1\n87\n\n\n\"2Ge+her\"\n\"The Hardest Part Of ...\"\n2000-09-02\n1\n91\n\n\n\"3 Doors Down\"\n\"Kryptonite\"\n2000-04-08\n1\n81\n\n\n\"3 Doors Down\"\n\"Loser\"\n2000-10-21\n1\n76\n\n\n…\n…\n…\n…\n…\n\n\n\"Lonestar\"\n\"Amazed\"\n1999-06-05\n63\n45\n\n\n\"Creed\"\n\"Higher\"\n1999-09-11\n64\n50\n\n\n\"Lonestar\"\n\"Amazed\"\n1999-06-05\n64\n50\n\n\n\"Creed\"\n\"Higher\"\n1999-09-11\n65\n49\n\n\n\n\n\n\nNow that we have all the week numbers in one variable and all the\nrank values in another, we’re in a good position to visualize how song\nranks vary over time.\n\npx.line(\n    billboard_longer, x=\"week\", y=\"rank\", line_group=\"track\"\n).update_traces( # we'll learn more about these extra methods in a later module\n    opacity=0.25\n).update_yaxes(\n    autorange=\"reversed\"\n)\n\n\n\n\nWe can see that very few songs stay in the top 100 for more than 20\nweeks.\n\n\n4.2.2\nHow does pivoting work?\nNow that you’ve seen how we can use pivoting to reshape our data,\nlet’s take a little time to gain some intuition about what pivoting does\nto the data. Let’s start with a very simple dataset to make it easier to\nsee what’s happening. Suppose we have three patients with\nids A, B, and C, and we take two blood pressure\nmeasurements on each patient.\n\ndf = pl.from_dict({\n    \"id\":  [\"A\", \"B\", \"C\"],\n    \"bp1\": [100, 140, 120],\n    \"bp2\": [120, 114, 125] \n})\n\ndf\n\n\nshape: (3, 3)\n\n\n\nid\nbp1\nbp2\n\n\nstr\ni64\ni64\n\n\n\n\n\"A\"\n100\n120\n\n\n\"B\"\n140\n114\n\n\n\"C\"\n120\n125\n\n\n\n\n\n\nWe want our new dataset to have three variables: id\n(already exists), measurement (the column names), and\nvalue (the cell values). To achieve this, we need to pivot\ndf longer:\n\ndf.unpivot(\n    index = \"id\",\n    variable_name=\"measurement\",\n    value_name=\"value\"\n).sort(\n    [\"id\", \"measurement\", \"value\"]\n)\n\n\nshape: (6, 3)\n\n\n\nid\nmeasurement\nvalue\n\n\nstr\nstr\ni64\n\n\n\n\n\"A\"\n\"bp1\"\n100\n\n\n\"A\"\n\"bp2\"\n120\n\n\n\"B\"\n\"bp1\"\n140\n\n\n\"B\"\n\"bp2\"\n114\n\n\n\"C\"\n\"bp1\"\n120\n\n\n\"C\"\n\"bp2\"\n125\n\n\n\n\n\n\nHow does the reshaping work? It’s easier to see if we think about it\ncolumn by column. As shown below, the values in a column that was\nalready a variable in the original dataset (id) need to be\nrepeated, once for each column that is pivoted.\n\n\n\nColumns that are already variables need to be repeated, once\nfor each column that is pivoted.\n\n\nThe column names become values in a new variable, whose name is\ndefined by variable_name, as shown below. THey need to be\nrepeated once for each row in the original dataset.\n\n\n\nThe column names of pivoted columns become values in a new\ncolumn. The values need to be repeated once for each row of the original\ndataset.\n\n\nThe cell values also become values in a new variable, with a name\ndefined by values_name. They are unwound row by row, as\nshown below.\n\n\n\nThe number of values is preserved (not repeated), but\nunwound row-by-row.\n\n\n\n\n4.2.3\nMore variables in column names\nA more challenging situation occurs when you have multiple pieces of\ninformation crammed into the column names, and you would like to store\nthese in separate new variables. For example, take the who\ndataset, the source of table1 and friends you saw\nabove:\n\nwho2.glimpse()\n\nRows: 7240\nColumns: 58\n$ country    &lt;str&gt; 'Afghanistan', 'Afghanistan', 'Afghanistan', 'Afghanistan', 'Afghanistan', 'Afghanistan', 'Afghanistan', 'Afghanistan', 'Afghanistan', 'Afghanistan'\n$ year       &lt;i64&gt; 1980, 1981, 1982, 1983, 1984, 1985, 1986, 1987, 1988, 1989\n$ sp_m_014   &lt;i64&gt; None, None, None, None, None, None, None, None, None, None\n$ sp_m_1524  &lt;i64&gt; None, None, None, None, None, None, None, None, None, None\n$ sp_m_2534  &lt;i64&gt; None, None, None, None, None, None, None, None, None, None\n$ sp_m_3544  &lt;i64&gt; None, None, None, None, None, None, None, None, None, None\n$ sp_m_4554  &lt;i64&gt; None, None, None, None, None, None, None, None, None, None\n$ sp_m_5564  &lt;i64&gt; None, None, None, None, None, None, None, None, None, None\n$ sp_m_65    &lt;i64&gt; None, None, None, None, None, None, None, None, None, None\n$ sp_f_014   &lt;i64&gt; None, None, None, None, None, None, None, None, None, None\n$ sp_f_1524  &lt;i64&gt; None, None, None, None, None, None, None, None, None, None\n$ sp_f_2534  &lt;i64&gt; None, None, None, None, None, None, None, None, None, None\n$ sp_f_3544  &lt;i64&gt; None, None, None, None, None, None, None, None, None, None\n$ sp_f_4554  &lt;i64&gt; None, None, None, None, None, None, None, None, None, None\n$ sp_f_5564  &lt;i64&gt; None, None, None, None, None, None, None, None, None, None\n$ sp_f_65    &lt;i64&gt; None, None, None, None, None, None, None, None, None, None\n$ sn_m_014   &lt;i64&gt; None, None, None, None, None, None, None, None, None, None\n$ sn_m_1524  &lt;i64&gt; None, None, None, None, None, None, None, None, None, None\n$ sn_m_2534  &lt;i64&gt; None, None, None, None, None, None, None, None, None, None\n$ sn_m_3544  &lt;i64&gt; None, None, None, None, None, None, None, None, None, None\n$ sn_m_4554  &lt;i64&gt; None, None, None, None, None, None, None, None, None, None\n$ sn_m_5564  &lt;i64&gt; None, None, None, None, None, None, None, None, None, None\n$ sn_m_65    &lt;i64&gt; None, None, None, None, None, None, None, None, None, None\n$ sn_f_014   &lt;i64&gt; None, None, None, None, None, None, None, None, None, None\n$ sn_f_1524  &lt;i64&gt; None, None, None, None, None, None, None, None, None, None\n$ sn_f_2534  &lt;i64&gt; None, None, None, None, None, None, None, None, None, None\n$ sn_f_3544  &lt;i64&gt; None, None, None, None, None, None, None, None, None, None\n$ sn_f_4554  &lt;i64&gt; None, None, None, None, None, None, None, None, None, None\n$ sn_f_5564  &lt;i64&gt; None, None, None, None, None, None, None, None, None, None\n$ sn_f_65    &lt;i64&gt; None, None, None, None, None, None, None, None, None, None\n$ ep_m_014   &lt;i64&gt; None, None, None, None, None, None, None, None, None, None\n$ ep_m_1524  &lt;i64&gt; None, None, None, None, None, None, None, None, None, None\n$ ep_m_2534  &lt;i64&gt; None, None, None, None, None, None, None, None, None, None\n$ ep_m_3544  &lt;i64&gt; None, None, None, None, None, None, None, None, None, None\n$ ep_m_4554  &lt;i64&gt; None, None, None, None, None, None, None, None, None, None\n$ ep_m_5564  &lt;i64&gt; None, None, None, None, None, None, None, None, None, None\n$ ep_m_65    &lt;i64&gt; None, None, None, None, None, None, None, None, None, None\n$ ep_f_014   &lt;i64&gt; None, None, None, None, None, None, None, None, None, None\n$ ep_f_1524  &lt;i64&gt; None, None, None, None, None, None, None, None, None, None\n$ ep_f_2534  &lt;i64&gt; None, None, None, None, None, None, None, None, None, None\n$ ep_f_3544  &lt;i64&gt; None, None, None, None, None, None, None, None, None, None\n$ ep_f_4554  &lt;i64&gt; None, None, None, None, None, None, None, None, None, None\n$ ep_f_5564  &lt;i64&gt; None, None, None, None, None, None, None, None, None, None\n$ ep_f_65    &lt;i64&gt; None, None, None, None, None, None, None, None, None, None\n$ rel_m_014  &lt;i64&gt; None, None, None, None, None, None, None, None, None, None\n$ rel_m_1524 &lt;i64&gt; None, None, None, None, None, None, None, None, None, None\n$ rel_m_2534 &lt;i64&gt; None, None, None, None, None, None, None, None, None, None\n$ rel_m_3544 &lt;i64&gt; None, None, None, None, None, None, None, None, None, None\n$ rel_m_4554 &lt;i64&gt; None, None, None, None, None, None, None, None, None, None\n$ rel_m_5564 &lt;i64&gt; None, None, None, None, None, None, None, None, None, None\n$ rel_m_65   &lt;i64&gt; None, None, None, None, None, None, None, None, None, None\n$ rel_f_014  &lt;i64&gt; None, None, None, None, None, None, None, None, None, None\n$ rel_f_1524 &lt;i64&gt; None, None, None, None, None, None, None, None, None, None\n$ rel_f_2534 &lt;i64&gt; None, None, None, None, None, None, None, None, None, None\n$ rel_f_3544 &lt;i64&gt; None, None, None, None, None, None, None, None, None, None\n$ rel_f_4554 &lt;i64&gt; None, None, None, None, None, None, None, None, None, None\n$ rel_f_5564 &lt;i64&gt; None, None, None, None, None, None, None, None, None, None\n$ rel_f_65   &lt;i64&gt; None, None, None, None, None, None, None, None, None, None\n\n\n\nThis dataset, collected by the World Health Organization, records\ninformation about tuberculosis diagnoses. There are two columns that are\nalready variables and are easy to interpret: country and\nyear. They are followed by 56 columns like\nsp_m_014, ep_m_4554, and\nrel_m_3544. If you stare at these columns for long enough,\nyou’ll notice there’s a pattern. Each column name is made up of three\npieces separated by _. The first piece,\nsp/rel/ep, describes the method\nused for the diagnosis, the second piece, m/f\nis the gender (coded as a binary variable in this dataset), and the\nthird piece,\n014/1524/2534/3544/4554/5564/65\nis the age range (014 represents 0-14, for example).\nSo in this case, we have six pieces of information recorded in\nwho2: the country and the year (already columns); the\nmethod of diagnosis, the gender category, and the age range category\n(contained in the other column names); and the count of patients in that\ncategory (cell values).\nTo organize these six pieces of information in six separate columns,\nfirst we use DataFrame.unpivot() like before, then we have\nto do some data wrangling using list\nexpressions to split the information from the column names into\nseparate columns:\n\nUnpivot:\n\n\nstep1 = who2.unpivot(\n    index=[\"country\", \"year\"],\n    variable_name=\"key\",\n    value_name=\"count\"\n)\n\nstep1\n\n\nshape: (405_440, 4)\n\n\n\ncountry\nyear\nkey\ncount\n\n\nstr\ni64\nstr\ni64\n\n\n\n\n\"Afghanistan\"\n1980\n\"sp_m_014\"\nnull\n\n\n\"Afghanistan\"\n1981\n\"sp_m_014\"\nnull\n\n\n\"Afghanistan\"\n1982\n\"sp_m_014\"\nnull\n\n\n\"Afghanistan\"\n1983\n\"sp_m_014\"\nnull\n\n\n…\n…\n…\n…\n\n\n\"Zimbabwe\"\n2010\n\"rel_f_65\"\nnull\n\n\n\"Zimbabwe\"\n2011\n\"rel_f_65\"\nnull\n\n\n\"Zimbabwe\"\n2012\n\"rel_f_65\"\nnull\n\n\n\"Zimbabwe\"\n2013\n\"rel_f_65\"\n725\n\n\n\n\n\n\n\nSplit the key column into diagnosis,\ngender, and age columns:\n\n\nstep2 = step1.with_columns(\n    pl.col(\"key\").str.split(\"_\")\n)\n\nstep2\n\n\nshape: (405_440, 4)\n\n\n\ncountry\nyear\nkey\ncount\n\n\nstr\ni64\nlist[str]\ni64\n\n\n\n\n\"Afghanistan\"\n1980\n[\"sp\", \"m\", \"014\"]\nnull\n\n\n\"Afghanistan\"\n1981\n[\"sp\", \"m\", \"014\"]\nnull\n\n\n\"Afghanistan\"\n1982\n[\"sp\", \"m\", \"014\"]\nnull\n\n\n\"Afghanistan\"\n1983\n[\"sp\", \"m\", \"014\"]\nnull\n\n\n…\n…\n…\n…\n\n\n\"Zimbabwe\"\n2010\n[\"rel\", \"f\", \"65\"]\nnull\n\n\n\"Zimbabwe\"\n2011\n[\"rel\", \"f\", \"65\"]\nnull\n\n\n\"Zimbabwe\"\n2012\n[\"rel\", \"f\", \"65\"]\nnull\n\n\n\"Zimbabwe\"\n2013\n[\"rel\", \"f\", \"65\"]\n725\n\n\n\n\n\n\n\nExtract each list element into a new column:\n\n\nstep3 = step2.select(\n    pl.col(\"country\"),\n    pl.col(\"year\"),\n    pl.col(\"key\").list.get(0).alias(\"diagnosis\"), # Polars also uses 0-indexing\n    pl.col(\"key\").list.get(1).alias(\"gender\"),\n    pl.col(\"key\").list.get(2).alias(\"age\"),\n    pl.col(\"count\")\n)\n\nstep3\n\n\nshape: (405_440, 6)\n\n\n\ncountry\nyear\ndiagnosis\ngender\nage\ncount\n\n\nstr\ni64\nstr\nstr\nstr\ni64\n\n\n\n\n\"Afghanistan\"\n1980\n\"sp\"\n\"m\"\n\"014\"\nnull\n\n\n\"Afghanistan\"\n1981\n\"sp\"\n\"m\"\n\"014\"\nnull\n\n\n\"Afghanistan\"\n1982\n\"sp\"\n\"m\"\n\"014\"\nnull\n\n\n\"Afghanistan\"\n1983\n\"sp\"\n\"m\"\n\"014\"\nnull\n\n\n…\n…\n…\n…\n…\n…\n\n\n\"Zimbabwe\"\n2010\n\"rel\"\n\"f\"\n\"65\"\nnull\n\n\n\"Zimbabwe\"\n2011\n\"rel\"\n\"f\"\n\"65\"\nnull\n\n\n\"Zimbabwe\"\n2012\n\"rel\"\n\"f\"\n\"65\"\nnull\n\n\n\"Zimbabwe\"\n2013\n\"rel\"\n\"f\"\n\"65\"\n725\n\n\n\n\n\n\nAll together:\n\n(\n    who2.unpivot(\n        index=[\"country\", \"year\"], variable_name=\"key\", value_name=\"count\"\n    )\n    .with_columns(\n        pl.col(\"key\").str.split(\"_\")\n    )\n    .select(\n        pl.col(\"country\"),\n        pl.col(\"year\"),\n        pl.col(\"key\").list.get(0).alias(\"diagnosis\"),\n        pl.col(\"key\").list.get(1).alias(\"gender\"),\n        pl.col(\"key\").list.get(2).alias(\"age\"),\n        pl.col(\"count\")\n    )\n)\n\nWhile the above steps break down the process to understand easier,\nhere is a more concise, albeit more advanced, way to achieve the same\nresults:\n\n(\n    who2.unpivot(\n        index=[\"country\", \"year\"], \n        variable_name=\"key\", \n        value_name=\"count\"\n    )\n    .with_columns(\n        pl.col(\"key\")\n        .str.split(\"_\")\n        .list.to_struct(fields=[\"diagnosis\", \"gender\", \"age\"])\n    )\n    .unnest(\"key\")\n)\n\n\nshape: (405_440, 6)\n\n\n\ncountry\nyear\ndiagnosis\ngender\nage\ncount\n\n\nstr\ni64\nstr\nstr\nstr\ni64\n\n\n\n\n\"Afghanistan\"\n1980\n\"sp\"\n\"m\"\n\"014\"\nnull\n\n\n\"Afghanistan\"\n1981\n\"sp\"\n\"m\"\n\"014\"\nnull\n\n\n\"Afghanistan\"\n1982\n\"sp\"\n\"m\"\n\"014\"\nnull\n\n\n\"Afghanistan\"\n1983\n\"sp\"\n\"m\"\n\"014\"\nnull\n\n\n…\n…\n…\n…\n…\n…\n\n\n\"Zimbabwe\"\n2010\n\"rel\"\n\"f\"\n\"65\"\nnull\n\n\n\"Zimbabwe\"\n2011\n\"rel\"\n\"f\"\n\"65\"\nnull\n\n\n\"Zimbabwe\"\n2012\n\"rel\"\n\"f\"\n\"65\"\nnull\n\n\n\"Zimbabwe\"\n2013\n\"rel\"\n\"f\"\n\"65\"\n725\n\n\n\n\n\n\nConceptually, this is only a minor variation on the simpler case\nyou’ve already seen. The figure below shows the basic idea: now, instead\nof the column names pivoting into a single column, they pivot into\nmultiple columns.\n\n\n\nPivoting columns with multiple pieces of information in the\nnames means that each column name now fills in values in multiple output\ncolumns.\n\n\n\n\n\n4.3\nWidening data\nSo far we’ve used DataFrame.unpivot() to solve the\ncommon class of problems where values have ended up in column names.\nNext we’ll pivot (HA HA) to DataFrame.pivot(), which makes\ndatasets wider by increasing columns and reducing rows\nand helps when one observation is spread across multiple rows. This\nseems to arise less commonly in the wild, but it does seem to crop up a\nlot when dealing with governmental data.\nWe’ll start by looking at cms_patient_experience, a\ndataset from the Centers of Medicare and Medicaid services that collects\ndata about patient experiences:\n\ncms_patient_experience\n\n\nshape: (500, 5)\n\n\n\norg_pac_id\norg_nm\nmeasure_cd\nmeasure_title\nprf_rate\n\n\nstr\nstr\nstr\nstr\ni64\n\n\n\n\n\"0446157747\"\n\"USC CARE MEDICAL GROUP INC\"\n\"CAHPS_GRP_1\"\n\"CAHPS for MIPS SSM: Getting Ti…\n63\n\n\n\"0446157747\"\n\"USC CARE MEDICAL GROUP INC\"\n\"CAHPS_GRP_2\"\n\"CAHPS for MIPS SSM: How Well P…\n87\n\n\n\"0446157747\"\n\"USC CARE MEDICAL GROUP INC\"\n\"CAHPS_GRP_3\"\n\"CAHPS for MIPS SSM: Patient's …\n86\n\n\n\"0446157747\"\n\"USC CARE MEDICAL GROUP INC\"\n\"CAHPS_GRP_5\"\n\"CAHPS for MIPS SSM: Health Pro…\n57\n\n\n…\n…\n…\n…\n…\n\n\n\"9931011434\"\n\"PATIENT FIRST RICHMOND MEDICAL…\n\"CAHPS_GRP_2\"\n\"CAHPS for MIPS SSM: How Well P…\nnull\n\n\n\"9931011434\"\n\"PATIENT FIRST RICHMOND MEDICAL…\n\"CAHPS_GRP_3\"\n\"CAHPS for MIPS SSM: Patient's …\nnull\n\n\n\"9931011434\"\n\"PATIENT FIRST RICHMOND MEDICAL…\n\"CAHPS_GRP_5\"\n\"CAHPS for MIPS SSM: Health Pro…\n45\n\n\n\"9931011434\"\n\"PATIENT FIRST RICHMOND MEDICAL…\n\"CAHPS_GRP_12\"\n\"CAHPS for MIPS SSM: Stewardshi…\n19\n\n\n\n\n\n\nThe core unit being studied is an organization, but each organization\nis spread across six rows, with one row for each measurement taken in\nthe survey organization. We can see the complete set of values for\nmeasure_cd and measure_title by using\nDataFrame.unique().select():\n\ncols = [\"measure_cd\", \"measure_title\"]\n\ncms_patient_experience.unique(subset=cols).select(cols).sort(cols)\n\n\nshape: (6, 2)\n\n\n\nmeasure_cd\nmeasure_title\n\n\nstr\nstr\n\n\n\n\n\"CAHPS_GRP_1\"\n\"CAHPS for MIPS SSM: Getting Ti…\n\n\n\"CAHPS_GRP_12\"\n\"CAHPS for MIPS SSM: Stewardshi…\n\n\n\"CAHPS_GRP_2\"\n\"CAHPS for MIPS SSM: How Well P…\n\n\n\"CAHPS_GRP_3\"\n\"CAHPS for MIPS SSM: Patient's …\n\n\n\"CAHPS_GRP_5\"\n\"CAHPS for MIPS SSM: Health Pro…\n\n\n\"CAHPS_GRP_8\"\n\"CAHPS for MIPS SSM: Courteous …\n\n\n\n\n\n\nNeither of these columns will make particularly great variable names:\nmeasure_cd doesn’t hint at the meaning of the variable and\nmeasure_title is a long sentence containing spaces. We’ll\nuse measure_cd as the source for our new column names for\nnow, but in a real analysis you might want to create your own variable\nnames that are both short and meaningful.\nDataFrame.pivot() has a similar, but different,\ninterface than DataFrame.unpivot(): you still select the\nindex columns (the columns that remain), but now you select\nwhich column the values will come from, and which column\nthe names come from (on).\n\ncms_patient_experience.pivot(\n    index=[\"org_pac_id\", \"org_nm\"],\n    on=[\"measure_cd\"], # Notice we don't use `measure_title`\n    values=\"prf_rate\"\n)\n\n\nshape: (95, 8)\n\n\n\norg_pac_id\norg_nm\nCAHPS_GRP_1\nCAHPS_GRP_2\nCAHPS_GRP_3\nCAHPS_GRP_5\nCAHPS_GRP_8\nCAHPS_GRP_12\n\n\nstr\nstr\ni64\ni64\ni64\ni64\ni64\ni64\n\n\n\n\n\"0446157747\"\n\"USC CARE MEDICAL GROUP INC\"\n63\n87\n86\n57\n85\n24\n\n\n\"0446162697\"\n\"ASSOCIATION OF UNIVERSITY PHYS…\n59\n85\n83\n63\n88\n22\n\n\n\"0547164295\"\n\"BEAVER MEDICAL GROUP PC\"\n49\nnull\n75\n44\n73\n12\n\n\n\"0749333730\"\n\"CAPE PHYSICIANS ASSOCIATES PA\"\n67\n84\n85\n65\n82\n24\n\n\n…\n…\n…\n…\n…\n…\n…\n…\n\n\n\"9830008770\"\n\"WASHINGTON UNIVERSITY\"\n65\nnull\nnull\n61\nnull\n28\n\n\n\"9830093640\"\n\"COOPERATIVE HEALTHCARE SERVICE…\n65\n87\n78\n52\nnull\n25\n\n\n\"9830094515\"\n\"SUTTER VALLEY MEDICAL FOUNDATI…\n60\nnull\n88\n55\nnull\n24\n\n\n\"9931011434\"\n\"PATIENT FIRST RICHMOND MEDICAL…\n80\nnull\nnull\n45\nnull\n19\n\n\n\n\n\n\n\n4.3.1\nHow does DataFrame.pivot() work?\nTo understand how DataFrame.pivot() works, let’s again\nstart with a very simple dataset. This time we have two patients with\nids A and B, we have three blood pressure measurements on\npatient A and two on patient B:\n\ndf = pl.from_dict({\n    \"id\": [\"A\", \"B\", \"B\", \"A\", \"A\"],\n    \"measurement\": [\"bp1\", \"bp1\", \"bp2\", \"bp2\", \"bp3\"],\n    \"value\": [100, 140, 115, 120, 105]\n})\n\nWe’ll take the values from the value column and the\nnames from the measurement column:\n\ndf.pivot(on=\"measurement\", values=\"value\") # unused cols get put in `index`\n\n\nshape: (2, 4)\n\n\n\nid\nbp1\nbp2\nbp3\n\n\nstr\ni64\ni64\ni64\n\n\n\n\n\"A\"\n100\n120\n105\n\n\n\"B\"\n140\n115\nnull\n\n\n\n\n\n\nTo begin the process, DataFrame.pivot() needs to first\nfigure out what will go in the rows and columns. The new column names\nwill be the unique values of measurement.\n\ndf.select(\"measurement\").unique()\n\n\nshape: (3, 1)\n\n\n\nmeasurement\n\n\nstr\n\n\n\n\n\"bp1\"\n\n\n\"bp3\"\n\n\n\"bp2\"\n\n\n\n\n\n\nBy default, the rows in the output are determined by all the\nvariables that aren’t going into the new names or values. These are\ncalled the index columns. Here there is only one column,\nbut in general there can be any number.\n\ndf.select(pl.exclude(\"measurement\", \"value\")).unique()\n\n\nshape: (2, 1)\n\n\n\nid\n\n\nstr\n\n\n\n\n\"A\"\n\n\n\"B\"\n\n\n\n\n\n\nDataFrame.pivot() then combines these results to\ngenerate an empty data frame:\n\ndf.select(pl.exclude(\"measurement\", \"value\")).unique().with_columns(\n    x=pl.lit(None), y=pl.lit(None), z=pl.lit(None)\n)\n\n\nshape: (2, 4)\n\n\n\nid\nx\ny\nz\n\n\nstr\nnull\nnull\nnull\n\n\n\n\n\"A\"\nnull\nnull\nnull\n\n\n\"B\"\nnull\nnull\nnull\n\n\n\n\n\n\nIt then fills in all the missing values using the data in the input.\nIn this case, not every cell in the output has a corresponding value in\nthe input as there’s no third blood pressure measurement for patient B,\nso that cell remains missing.\n\n\n4.3.2\nData and variable names in the column headers\nWe will now see an example where we need to unpivot and pivot in the\nsame set of steps to tidy our data. This step up in complexity is when\nthe column names include a mix of variable values and variable names.\nFor example, take the household dataset:\n\nhousehold = pl.from_dict({\n    \"family\": [1, 2, 3, 4, 5],\n    \"dob_child1\": [\"1998-11-26\", \"1996-06-22\", \"2002-07-11\", \"2004-10-10\", \"2000-12-05\"],\n    \"dob_child2\": [\"2000-01-29\", None, \"2004-04-05\", \"2009-08-27\", \"2005-02-28\"],\n    \"name_child1\": [\"Susan\", \"Mark\", \"Sam\", \"Craig\", \"Parker\"],\n    \"name_child2\": [\"Jose\", None, \"Seth\", \"Khai\", \"Gracie\"]\n}).with_columns(\n    cs.starts_with(\"dob\").str.to_date()\n)\n\nhousehold\n\n\nshape: (5, 5)\n\n\n\nfamily\ndob_child1\ndob_child2\nname_child1\nname_child2\n\n\ni64\ndate\ndate\nstr\nstr\n\n\n\n\n1\n1998-11-26\n2000-01-29\n\"Susan\"\n\"Jose\"\n\n\n2\n1996-06-22\nnull\n\"Mark\"\nnull\n\n\n3\n2002-07-11\n2004-04-05\n\"Sam\"\n\"Seth\"\n\n\n4\n2004-10-10\n2009-08-27\n\"Craig\"\n\"Khai\"\n\n\n5\n2000-12-05\n2005-02-28\n\"Parker\"\n\"Gracie\"\n\n\n\n\n\n\nThis dataset contains data about five families, with the names and\ndates of birth of up to two children. The new challenge in this dataset\nis that the column names contain the names of two variables\n(dob, name) and the values of another\n(child, with values 1 or 2).\n\n(\n    # First, unpivot the data frame to create rows for each family-column combination\n    household.unpivot(index=\"family\")\n\n    # Extract the base column name (dob/name) and the child number\n    .with_columns(\n        pl.col(\"variable\")\n        .str.split(\"_\")\n        .list.to_struct(fields=[\"base_col\", \"child\"])\n    )\n    .unnest(\"variable\")\n\n    # Pivot the data to create separate columns for each base_col (dob, name)\n    .pivot(index=[\"family\", \"child\"], on=\"base_col\", values=\"value\")\n\n    # Filter out rows with null values\n    .drop_nulls()\n\n    # Clean up results\n    .sort([\"family\", \"child\"])\n    .with_columns(pl.col(\"dob\").str.to_date())\n)\n\n\nshape: (9, 4)\n\n\n\nfamily\nchild\ndob\nname\n\n\ni64\nstr\ndate\nstr\n\n\n\n\n1\n\"child1\"\n1998-11-26\n\"Susan\"\n\n\n1\n\"child2\"\n2000-01-29\n\"Jose\"\n\n\n2\n\"child1\"\n1996-06-22\n\"Mark\"\n\n\n3\n\"child1\"\n2002-07-11\n\"Sam\"\n\n\n…\n…\n…\n…\n\n\n4\n\"child1\"\n2004-10-10\n\"Craig\"\n\n\n4\n\"child2\"\n2009-08-27\n\"Khai\"\n\n\n5\n\"child1\"\n2000-12-05\n\"Parker\"\n\n\n5\n\"child2\"\n2005-02-28\n\"Gracie\"\n\n\n\n\n\n\nWe use DataFrame.drop_nulls() since the shape of the\ninput forces the creation of explicit missing variables (e.g., for\nfamilies that only have one child).\n\n\n\n4.4\nSummary\nIn this section, you learned about tidy data: data that has variables\nin columns and observations in rows. Tidy data makes working in the\nPolars easier, because it’s a consistent structure understood by most\nfunctions, the main challenge is transforming the data from whatever\nstructure you receive it in to a tidy format. To that end, you learned\nabout DataFrame.unpivot() and\nDataFrame.pivot() which allow you to tidy up many untidy\ndatasets.\nAnother challenge is that, for a given dataset, it can be impossible\nto label the longer or the wider version as the “tidy” one. This is\npartly a reflection of our definition of tidy data, where we said tidy\ndata has one variable in each column, but we didn’t actually define what\na variable is (and it’s surprisingly hard to do so). It’s totally fine\nto be pragmatic and to say a variable is whatever makes your analysis\neasiest. So if you’re stuck figuring out how to do some computation,\nconsider switching up the organization of your data; don’t be afraid to\nuntidy, transform, and re-tidy as needed!",
    "crumbs": [
      "Learning Modules",
      "05 | Introduction to Data Science"
    ]
  },
  {
    "objectID": "learning-modules/05-intro-to-data-science.html#data-import-export",
    "href": "learning-modules/05-intro-to-data-science.html#data-import-export",
    "title": "05 | Introduction to Data Science",
    "section": "5 Data\nimport & export",
    "text": "5 Data\nimport & export\nWorking with data provided by Python packages is a great way to learn\ndata science tools, but at some point, you’ll want to apply what you’ve\nlearned to your own data. In this section, you’ll learn the basics of\nreading data files into Python and how to export them for others (or\nyourself in the future) to use.\nSpecifically, this chapter will focus on reading plain-text\nrectangular files. We’ll start with practical advice for handling\nfeatures like column names, types, and missing data. You will then learn\nabout reading data from multiple files at once and writing data from\nPython to a file. Finally, you’ll learn how to handcraft data frames in\nPython, and export them with Polars functions.\n\nimport polars as pl\nimport io # we'll use this to \"create\" CSVs within Python examples\n\n\n5.1\nReading data from a file\nTo begin, we’ll focus on the most common rectangular data file type:\nCSV, which is short for comma-separated values. Here is what a simple\nCSV file looks like. The first row, commonly called the header row,\ngives the column names, and the following six rows provide the data. The\ncolumns are separated, aka delimited, by commas.\nStudent ID,Full Name,favourite.food,mealPlan,AGE\n1,Sunil Huffmann,Strawberry yoghurt,Lunch only,4\n2,Barclay Lynn,French fries,Lunch only,5\n3,Jayendra Lyne,N/A,Breakfast and lunch,7\n4,Leon Rossini,Anchovies,Lunch only,\n5,Chidiegwu Dunkel,Pizza,Breakfast and lunch,five\n6,Güvenç Attila,Ice cream,Lunch only,6\nThe following table shows a representation of the same data as a\ntable:\n\n\n\n\n\n\n\n\n\n\nStudent ID\nFull Name\nfavourite.food\nmealPlan\nAGE\n\n\n\n\n1\nSunil Huffmann\nStrawberry yoghurt\nLunch only\n4\n\n\n2\nBarclay Lynn\nFrench fries\nLunch only\n5\n\n\n3\nJayendra Lyne\nN/A\nBreakfast and lunch\n7\n\n\n4\nLeon Rossini\nAnchovies\nLunch only\nNULL\n\n\n5\nChidiegwu Dunkel\nPizza\nBreakfast and lunch\nfive\n\n\n6\nGuvenc Attila\nIce cream\nLunch only\n6\n\n\n\nWe can read this file into Python using pl.read_csv().\nThe first argument is the most important: the path to the file. You can\nthink about the path as the address of the file: the file is called\nstudents.csv and it lives in the data\nfolder.\n\nstudents = pl.read_csv(\"data/students.csv\")\n\nThe code above will work if you have the students.csv file in a data\nfolder in your project. You can also read it directly from a URL:\nstudents = pl.read_csv(\"https://raw.githubusercontent.com/hadley/r4ds/main/data/students.csv\")\nWhen you run pl.read_csv(), Polars will scan the file\nand automatically infer column types based on the data it contains.\nPolars doesn’t print a detailed message about column specifications by\ndefault, but you can examine the schema to see the inferred types:\n\nstudents.schema.to_frame()\n\n\nshape: (0, 5)\n\n\n\nStudent ID\nFull Name\nfavourite.food\nmealPlan\nAGE\n\n\ni64\nstr\nstr\nstr\nstr\n\n\n\n\n\n\n\n\n\n5.1.1\nPractical advice\nOnce you read data in, the first step usually involves transforming\nit in some way to make it easier to work with in the rest of your\nanalysis. Let’s take another look at the students data with that in\nmind.\n\nstudents\n\n\nshape: (6, 5)\n\n\n\nStudent ID\nFull Name\nfavourite.food\nmealPlan\nAGE\n\n\ni64\nstr\nstr\nstr\nstr\n\n\n\n\n1\n\"Sunil Huffmann\"\n\"Strawberry yoghurt\"\n\"Lunch only\"\n\"4\"\n\n\n2\n\"Barclay Lynn\"\n\"French fries\"\n\"Lunch only\"\n\"5\"\n\n\n3\n\"Jayendra Lyne\"\n\"N/A\"\n\"Breakfast and lunch\"\n\"7\"\n\n\n4\n\"Leon Rossini\"\n\"Anchovies\"\n\"Lunch only\"\nnull\n\n\n5\n\"Chidiegwu Dunkel\"\n\"Pizza\"\n\"Breakfast and lunch\"\n\"five\"\n\n\n6\n\"Güvenç Attila\"\n\"Ice cream\"\n\"Lunch only\"\n\"6\"\n\n\n\n\n\n\nIn the favourite.food column, there’s an entry “N/A”\nthat should be interpreted as a real None that Python will\nrecognize as “not available”. This is something we can address using the\nnull_values argument. By default, Polars only recognizes\nempty strings and the string “null” (case-insensitive) as missing\nvalues.\n\nstudents = pl.read_csv(\n    \"data/students.csv\", \n    null_values=[\"N/A\", \"\"]\n)\n\nstudents\n\n\nshape: (6, 5)\n\n\n\nStudent ID\nFull Name\nfavourite.food\nmealPlan\nAGE\n\n\ni64\nstr\nstr\nstr\nstr\n\n\n\n\n1\n\"Sunil Huffmann\"\n\"Strawberry yoghurt\"\n\"Lunch only\"\n\"4\"\n\n\n2\n\"Barclay Lynn\"\n\"French fries\"\n\"Lunch only\"\n\"5\"\n\n\n3\n\"Jayendra Lyne\"\nnull\n\"Breakfast and lunch\"\n\"7\"\n\n\n4\n\"Leon Rossini\"\n\"Anchovies\"\n\"Lunch only\"\nnull\n\n\n5\n\"Chidiegwu Dunkel\"\n\"Pizza\"\n\"Breakfast and lunch\"\n\"five\"\n\n\n6\n\"Güvenç Attila\"\n\"Ice cream\"\n\"Lunch only\"\n\"6\"\n\n\n\n\n\n\nYou might also notice that Student ID and\nFull Name columns contain spaces, which can make them\nawkward to work with in code. In Polars, you can refer to these columns\nusing either bracket notation or with the . accessor, but\nthe latter won’t work with spaces or special characters:\n\n# Works with spaces\nfirst_student_name = students[\"Full Name\"][0]\nprint(first_student_name)\n\n# Won't work with spaces\nfirst_student_name = students.Full Name[0]  # Syntax error!\n\n\n  Cell In[98], line 6\n    first_student_name = students.Full Name[0]  # Syntax error!\n                                       ^\nSyntaxError: invalid syntax\n\n\n\n\nIt’s often a good idea to rename these columns to follow Python\nnaming conventions. Here’s how you can rename specific columns:\n\nstudents = students.rename({\n    \"Student ID\": \"student_id\",\n    \"Full Name\": \"full_name\"\n})\n\nstudents\n\n\nshape: (6, 5)\n\n\n\nstudent_id\nfull_name\nfavourite.food\nmealPlan\nAGE\n\n\ni64\nstr\nstr\nstr\nstr\n\n\n\n\n1\n\"Sunil Huffmann\"\n\"Strawberry yoghurt\"\n\"Lunch only\"\n\"4\"\n\n\n2\n\"Barclay Lynn\"\n\"French fries\"\n\"Lunch only\"\n\"5\"\n\n\n3\n\"Jayendra Lyne\"\nnull\n\"Breakfast and lunch\"\n\"7\"\n\n\n4\n\"Leon Rossini\"\n\"Anchovies\"\n\"Lunch only\"\nnull\n\n\n5\n\"Chidiegwu Dunkel\"\n\"Pizza\"\n\"Breakfast and lunch\"\n\"five\"\n\n\n6\n\"Güvenç Attila\"\n\"Ice cream\"\n\"Lunch only\"\n\"6\"\n\n\n\n\n\n\nAn alternative approach is to use a function to clean all column\nnames at once. Polars doesn’t have a built-in function for this, but we\ncan use a special shortcut called a lambda function to do this in one\nline. Think of a lambda function as a mini-function that you can write\ndirectly where you need it, without having to define it separately. It’s\nlike giving Polars quick instructions on how to transform each column\nname.\n\nstudents = (\n    students.rename(\n        lambda col_name: col_name.lower().replace(\" \", \"_\").replace(\".\", \"_\")\n    )\n)\n\nWith this code, we are telling Polars to take each column\nname (not the values of the columns), call it col,\nand do these three things to it:\n\nConvert it to lowercase\nReplace any spaces with underscores\nReplace any periods with underscores\n\nNote that these are the string methods we learned earlier in this\ncourse, not functions that come from Polars. col_name has\nthe type str.\nLike in for loops, it doesn’t matter what the looping\n(or lambda) variable is called. I just called it col_name\nbecause that is what we are effecting. I could’ve also called\nit x and it would work the same:\nstudents = (\n    students.rename(\n        lambda x: x.lower().replace(\" \", \"_\").replace(\".\", \"_\")\n    )\n)\nIf you wanted to use a regular function, you could do something like\nthis:\ndef clean_col_name(col_name):\n    return col_name.lower().replace(\" \", \"_\").replace(\".\", \"_\")\n\nstudents = students.rename(clean_column_name) \n# Note: no parentheses here, we're passing the function itself\nWhen would you want to use a named/user-defined function over a\nlambda function? It comes down to how many times you would repeat the\nsteps. If you are working with only one data frame, a lambda function\nmight be quicker to write, but if you are going to clean multiple data\nframes in the same script, creating a named function to use over again\nwould be the better method.\n\n\n\n\n\n\nNote\n\n\n\nYou can use this code snippet to help you with your labs and tests.\nYou don’t need to fully understand lambda functions for this course, but\nyou can think of this specific pattern as a helpful ‘recipe’ for\ncleaning column names in one step while keeping your code clean and\nreadable. If you ever need to customize how column names are cleaned,\nyou can just adjust what happens inside the lambda function. The Polars\ndocumentation\nfor DataFrame.rename() has another example using lambda\nfunctions to rename columns.\n\n\nAnother common task after reading in data is to consider variable\ntypes. For example, meal_plan is a categorical variable\nwith a known set of possible values, which in Python should be\nrepresented as a category:\n\nstudents = students.with_columns(\n    pl.col(\"mealplan\").cast(pl.Categorical)\n)\nstudents\n\n\nshape: (6, 5)\n\n\n\nstudent_id\nfull_name\nfavourite_food\nmealplan\nage\n\n\ni64\nstr\nstr\ncat\nstr\n\n\n\n\n1\n\"Sunil Huffmann\"\n\"Strawberry yoghurt\"\n\"Lunch only\"\n\"4\"\n\n\n2\n\"Barclay Lynn\"\n\"French fries\"\n\"Lunch only\"\n\"5\"\n\n\n3\n\"Jayendra Lyne\"\nnull\n\"Breakfast and lunch\"\n\"7\"\n\n\n4\n\"Leon Rossini\"\n\"Anchovies\"\n\"Lunch only\"\nnull\n\n\n5\n\"Chidiegwu Dunkel\"\n\"Pizza\"\n\"Breakfast and lunch\"\n\"five\"\n\n\n6\n\"Güvenç Attila\"\n\"Ice cream\"\n\"Lunch only\"\n\"6\"\n\n\n\n\n\n\nBefore you analyze this dataset, you’ll probably want to fix the age\ncolumn. Currently, age contains mixed types because one\nobservation is typed out as “five” instead of the number 5:\n\nstudents = students.with_columns(\n    age=pl.when(pl.col(\"age\") == \"five\")\n    .then(pl.lit(5))\n    .otherwise(pl.col(\"age\").cast(pl.Int64, strict=False))\n) # This is conceptually very similar to Python's built in if-elif-else\n\nstudents\n\n\nshape: (6, 5)\n\n\n\nstudent_id\nfull_name\nfavourite_food\nmealplan\nage\n\n\ni64\nstr\nstr\ncat\ni64\n\n\n\n\n1\n\"Sunil Huffmann\"\n\"Strawberry yoghurt\"\n\"Lunch only\"\n4\n\n\n2\n\"Barclay Lynn\"\n\"French fries\"\n\"Lunch only\"\n5\n\n\n3\n\"Jayendra Lyne\"\nnull\n\"Breakfast and lunch\"\n7\n\n\n4\n\"Leon Rossini\"\n\"Anchovies\"\n\"Lunch only\"\nnull\n\n\n5\n\"Chidiegwu Dunkel\"\n\"Pizza\"\n\"Breakfast and lunch\"\n5\n\n\n6\n\"Güvenç Attila\"\n\"Ice cream\"\n\"Lunch only\"\n6\n\n\n\n\n\n\nThe Polars code above uses a conditional expression with\nwhen(), then(), and otherwise()\nto handle the special case, then attempts to cast the column to a\nfloating-point number. The strict=False parameter tells\nPolars to convert values that can be parsed as numbers and set the rest\nto None.\n\n\n5.1.2\nOther arguments\nUsually, pl.read_csv() uses the first line of the data\nfor the column names, which is a very common convention. But it’s not\nuncommon for a few lines of metadata to be included at the top of the\nfile. You can use skip_rows to skip the first n lines:\n\ncsv_data = \"\"\"The first line of metadata\nThe second line of metadata\nx,y,z \n1,2,3\"\"\"\n\npl.read_csv(io.StringIO(csv_data), skip_rows=2)\n\n\nshape: (1, 3)\n\n\n\nx\ny\nz\n\n\ni64\ni64\ni64\n\n\n\n\n1\n2\n3\n\n\n\n\n\n\nIn other cases, the data might not have column names. You can use\nhas_header=False to tell Polars not to treat the first row\nas headings:\n\ncsv_data = \"\"\"1,2,3\n4,5,6\"\"\"\n\npl.read_csv(io.StringIO(csv_data), has_header=False)\n\n\nshape: (2, 3)\n\n\n\ncolumn_1\ncolumn_2\ncolumn_3\n\n\ni64\ni64\ni64\n\n\n\n\n1\n2\n3\n\n\n4\n5\n6\n\n\n\n\n\n\nBy default, Polars will name the columns “column_1”, “column_2”, etc.\nYou can provide your own column names with the new_columns\nparameter:\n\ncsv_data = \"\"\"1,2,3\n4,5,6\"\"\"\n\npl.read_csv(\n    io.StringIO(csv_data), \n    has_header=False,\n    new_columns=[\"x\", \"y\", \"z\"]\n)\n\n\nshape: (2, 3)\n\n\n\nx\ny\nz\n\n\ni64\ni64\ni64\n\n\n\n\n1\n2\n3\n\n\n4\n5\n6\n\n\n\n\n\n\nThese arguments are all you need to know to read the majority of CSV\nfiles that you’ll encounter in practice. (For the rest, you’ll need to\ncarefully inspect your .csv file and read the documentation for\npl.read_csv()’s many other arguments.)\n\n\n5.1.3\nOther file types\nOnce you’ve mastered read_csv(), using Polars’ other\nfunctions is straightforward; it’s just a matter of knowing which\nfunction to reach for:\n\nread_csv() reads comma-separated files.\nread_csv() can also read semicolon-separated files by\nsetting separator=\";\".\nread_csv() can read tab-delimited files by setting\nseparator=\"\\t\", or you can use the alias\nread_tsv().\nread_csv() can read files with any delimiter by setting\nthe separator parameter.\nread_ndjson() reads newline-delimited JSON files.\nread_parquet() reads Apache Parquet files, a columnar\nstorage format that is typically faster and more space-efficient than\nCSV.\nread_ipc() or read_arrow() reads Arrow IPC\nfiles, which provide high-performance interoperability between different\nsystems.\nread_excel() reads Excel files (learn more about the\ndifferent Excel features here).\nread_avro() reads Avro files.\n\n\n\n\n5.2\nControlling column types\nA CSV file doesn’t contain any information about the type of each\nvariable (i.e., whether it’s a boolean, number, string, etc.), so Polars\nwill try to guess the type. This section describes how the guessing\nprocess works, how to resolve some common problems that cause it to\nfail, and how to supply the column types yourself.\n\n5.2.1\nGuessing types\nPolars uses a heuristic to figure out the column types. By default,\nit samples a certain number of rows from the file and tries to infer the\ntype based on the values it sees. You can control this with the\ninfer_schema_length parameter.\nThe type inference generally follows these rules: - If values are\n“true” or “false” (case-insensitive), it’s a boolean. - If values are\nall integers, it’s an integer type. - If values have decimals but are\nall numeric, it’s a floating-point type. - If values match a date or\ndatetime pattern, it’s a date or datetime type. - Otherwise, it’s a\nstring type.\nYou can see that behavior with a simple example:\n\ncsv_data = \"\"\"logical,numeric,date,string\nTRUE,1,2021-01-15,abc\nfalse,4.5,2021-02-15,def\nT,Inf,2021-02-16,ghi\"\"\"\n\npl.read_csv(io.StringIO(csv_data))\n\n\nshape: (3, 4)\n\n\n\nlogical\nnumeric\ndate\nstring\n\n\nstr\nstr\nstr\nstr\n\n\n\n\n\"TRUE\"\n\"1\"\n\"2021-01-15\"\n\"abc\"\n\n\n\"false\"\n\"4.5\"\n\"2021-02-15\"\n\"def\"\n\n\n\"T\"\n\"Inf\"\n\"2021-02-16\"\n\"ghi\"\n\n\n\n\n\n\nThis heuristic works well if you have a clean dataset, but in real\nlife, you’ll encounter a variety of challenges that require special\nhandling.\n\n\n5.2.2\nMissing values, column types, and problems\nThe most common way column detection fails is that a column contains\nunexpected values, and you get a string column instead of a more\nspecific type. One of the most common causes is a missing value recorded\nusing something other than the None that Polars\nexpects.\nTake this simple 1-column CSV file as an example:\n\nsimple_csv = \"\"\"x\n10\n.\n20\n30\"\"\"\n\n# Read without specifying null values\npl.read_csv(io.StringIO(simple_csv))\n\n\nshape: (4, 1)\n\n\n\nx\n\n\nstr\n\n\n\n\n\"10\"\n\n\n\".\"\n\n\n\"20\"\n\n\n\"30\"\n\n\n\n\n\n\nIf we read it without any additional arguments, x\nbecomes a string column. In this very small example, you can easily see\nthe missing value .. But what if you have thousands of rows\nwith only a few missing values represented by .s scattered\nthroughout?\nIn Polars, you can specify the column type and tell it what values\nshould be treated as null:\n\npl.read_csv(\n    io.StringIO(simple_csv),\n    schema_overrides={\"x\": pl.Int64},\n    null_values=[\".\"],\n)\n\n\nshape: (4, 1)\n\n\n\nx\n\n\ni64\n\n\n\n\n10\n\n\nnull\n\n\n20\n\n\n30\n\n\n\n\n\n\n\n\n5.2.3\nColumn types\nPolars provides many data types that you can specify:\n\npl.Boolean: For logical values (True/False)\npl.Int8, pl.Int16, pl.Int32,\npl.Int64: For integers of different sizes\npl.UInt8, pl.UInt16,\npl.UInt32, pl.UInt64: For unsigned integers\n(positive only)\npl.Float32, pl.Float64: For floating-point\nnumbers\npl.Decimal: For precise decimal arithmetic\npl.Utf8: For string data\npl.Categorical: For categorical (factor) data\npl.Date, pl.Time,\npl.Datetime: For date and time data\npl.Object: For Python objects that don’t fit the other\ntypes\npl.Binary: For binary data\npl.Struct: For nested data structures\n\nYou can specify column types in two ways:\n\nUsing the schema or schema_overrides\nparameter when reading data\nUsing cast() to convert columns after reading\n\n\n# Specify types when reading\ncsv_data = \"\"\"x,y,z\n1,2,3\"\"\"\n\ndf = pl.read_csv(\n    io.StringIO(csv_data),\n    schema_overrides={\n        \"x\": pl.Int32,\n        \"y\": pl.Float64,\n        \"z\": pl.Utf8\n    }\n)\nprint(df.schema)\n\n# Or convert after reading\ndf = pl.read_csv(io.StringIO(csv_data))\ndf = df.with_columns([\n    pl.col(\"x\").cast(pl.Int32),\n    pl.col(\"y\").cast(pl.Float64),\n    pl.col(\"z\").cast(pl.Utf8)\n])\nprint(df.schema)\n\nSchema({'x': Int32, 'y': Float64, 'z': String})\nSchema({'x': Int32, 'y': Float64, 'z': String})\n\n\nYou can also specify a schema for all columns at once:\n\nschema = {\"x\": pl.Int32, \"y\": pl.Float64, \"z\": pl.Utf8}\ndf = pl.read_csv(io.StringIO(csv_data), schema=schema)\nprint(df.schema)\n\nSchema({'x': Int32, 'y': Float64, 'z': String})\n\n\nIf you want to select only specific columns when reading a file, you\ncan use the columns parameter:\n\ndf = pl.read_csv(io.StringIO(csv_data), columns=[\"x\"])\nprint(df)\n\nshape: (1, 1)\n┌─────┐\n│ x   │\n│ --- │\n│ i64 │\n╞═════╡\n│ 1   │\n└─────┘\n\n\n\n\n\n5.3\nReading data from multiple files\nSometimes your data is split across multiple files instead of being\ncontained in a single file. For example, you might have sales data for\nmultiple months, with each month’s data in a separate file:\n01-sales.csv for January, 02-sales.csv for\nFebruary, and 03-sales.csv for March.\nWith Polars, you can read these files one by one and then concatenate\nthem:\n# List of sales files\nsales_files = [\n    \"data/01-sales.csv\",\n    \"data/02-sales.csv\",\n    \"data/03-sales.csv\"\n]\n\n# Read and concatenate via list comprehension\ndfs = [pl.read_csv(file).with_columns(pl.lit(os.path.basename(file)).alias(\"file\")) \n       for file in sales_files]\nsales = pl.concat(dfs)\nprint(sales)\n\n\n\n\n\n\nTip\n\n\n\nThis method uses something called List Comprehension, which you can\nlearn more about here.\n\n\nYou can download these files from the URLs mentioned in the original\nchapter, or read them directly:\nsales_files = [\n    \"https://pos.it/r4ds-01-sales\",\n    \"https://pos.it/r4ds-02-sales\",\n    \"https://pos.it/r4ds-03-sales\"\n]\n\ndfs = [pl.read_csv(file).with_columns(pl.lit(file).alias(\"file\")) \n       for file in sales_files]\nsales = pl.concat(dfs)\nprint(sales)\nIf you have many files you want to read in, you can use the\nglob module to find the files by matching a pattern:\nimport glob\n\nsales_files = glob.glob(\"data/*-sales.csv\")\nsales_files\n\n\n5.4\nWriting to a file\nPolars provides several functions for writing data to disk. The most\ncommon are write_csv() and write_parquet().\nThe most important arguments to these functions are the\nDataFrame to save and the file path where you want to save\nit.\nstudents.write_csv(\"students.csv\")\nNow let’s read that CSV file back in. Note that the variable type\ninformation you set up is lost when you save to CSV because you’re\nstarting over with reading from a plain text file. This makes CSVs\nsomewhat unreliable for caching interim results—you need to recreate the\ncolumn specification every time you load in. There are two better\nalternatives:\n1.Parquet\nfiles maintain the column types and are generally faster and more\nspace-efficient:\nstudents.write_parquet(\"students.parquet\")\nparquet_students = pl.read_parquet(\"students.parquet\")\n\nFor Python-specific caching, you can use the pickle\nformat through libraries like joblib:\n\nimport joblib\n\njoblib.dump(students, \"students.joblib\")\njoblib_students = joblib.load(\"students.joblib\")\nprint(joblib_students)\nParquet is usually preferable because it’s cross-language compatible,\nmore efficient, and maintains your data types.\n\n\n5.5\nData entry\nSometimes you’ll need to assemble a DataFrame “by hand”\nwith a little data entry in your Python script. Polars provides a simple\nway to create data frames from dictionaries where each key is a column\nname and each value is a list of values:\n\ndf = pl.DataFrame({\n    \"x\": [1, 2, 5],\n    \"y\": [\"h\", \"m\", \"g\"],\n    \"z\": [0.08, 0.83, 0.60]\n})\n\ndf\n\n\nshape: (3, 3)\n\n\n\nx\ny\nz\n\n\ni64\nstr\nf64\n\n\n\n\n1\n\"h\"\n0.08\n\n\n2\n\"m\"\n0.83\n\n\n5\n\"g\"\n0.6\n\n\n\n\n\n\nYou can also create a data frame from a list of dictionaries, where\neach dictionary represents a row:\n\ndf = pl.DataFrame([\n    {\"x\": 1, \"y\": \"h\", \"z\": 0.08},\n    {\"x\": 2, \"y\": \"m\", \"z\": 0.83},\n    {\"x\": 5, \"y\": \"g\", \"z\": 0.60}\n])\n\ndf\n\n\nshape: (3, 3)\n\n\n\nx\ny\nz\n\n\ni64\nstr\nf64\n\n\n\n\n1\n\"h\"\n0.08\n\n\n2\n\"m\"\n0.83\n\n\n5\n\"g\"\n0.6\n\n\n\n\n\n\n\n\n5.6\nSummary\nIn this section, you’ve learned how to load CSV files with Polars’\npl.read_csv() and how to do your own data entry by creating\nDataFrames from dictionaries and lists. You’ve learned how CSV files\nwork, some of the problems you might encounter, and how to overcome\nthem.\nWe’ll revisit data import in various formats throughout your Python\ndata science journey, including Excel files, databases, Parquet files,\nJSON, and data from websites.\nPolars is an excellent choice for data handling, as it’s designed to\ntake advantage of modern hardware through parallel processing and memory\nefficiency. As you become more familiar with Python data science tools,\nyou’ll appreciate Polars’ performance benefits and elegant API\ndesign.",
    "crumbs": [
      "Learning Modules",
      "05 | Introduction to Data Science"
    ]
  },
  {
    "objectID": "learning-modules/05-intro-to-data-science.html#exercises",
    "href": "learning-modules/05-intro-to-data-science.html#exercises",
    "title": "05 | Introduction to Data Science",
    "section": "6\nExercises",
    "text": "6\nExercises\n\nDoes it matter what order you used\nDataFrame.filter() and DataFrame.sort() if\nyou’re using both? Why/why not? Think about the results and how much\nwork the functions would have to do.\nWhat happens if you specify the name of the same variable\nmultiple times in a DataFrame.select() call?\nUsing the penguins dataset, make a scatter plot of\nbill_depth_mm vs. bill_length_mm. That is,\nmake a scatter plot with bill_depth_mm on the y-axis and\nbill_length_mm on the x-axis. Describe the relationship\nbetween these two variables.\nFrom the flights dataset, compare\ndep_time, sched_dep_time, and\ndep_delay. How would you expect those three numbers to be\nrelated?\nIn a single pipeline for each condition, find all\nflights that meet the condition:\n\nHad an arrival delay of two or more hours\nFlew to Houston (IAH or HOU)\nWere operated by United, American, or Delta\nDeparted in summer (July, August, and September)\nArrived more than two hours late but didn’t leave late\nWere delayed by at least an hour, but made up over 30 minutes in\nflight\n\nFind the flights that are most delayed upon departure from each\ndestination.\nHow do delays vary over the course of the day? Illustrate your\nanswer with a plot.",
    "crumbs": [
      "Learning Modules",
      "05 | Introduction to Data Science"
    ]
  },
  {
    "objectID": "learning-modules/03-functions-flow-control-and-conditionals.html",
    "href": "learning-modules/03-functions-flow-control-and-conditionals.html",
    "title": "03 | Functions, Flow Control, & Conditionals",
    "section": "",
    "text": "So far, we’ve used Python’s built-in functions. In this module,\nyou’ll learn to create and run your own functions, and see how one\nfunction can call another. We’ll also introduce the for\nloop to repeat computations and the if statement to execute different\ncode based on program state. Finally, we’ll learn how to handle external\nfiles, update variables, and perform searches in strings.",
    "crumbs": [
      "Learning Modules",
      "03 | Functions, Flow Control, & Conditionals"
    ]
  },
  {
    "objectID": "learning-modules/03-functions-flow-control-and-conditionals.html#overview",
    "href": "learning-modules/03-functions-flow-control-and-conditionals.html#overview",
    "title": "03 | Functions, Flow Control, & Conditionals",
    "section": "",
    "text": "So far, we’ve used Python’s built-in functions. In this module,\nyou’ll learn to create and run your own functions, and see how one\nfunction can call another. We’ll also introduce the for\nloop to repeat computations and the if statement to execute different\ncode based on program state. Finally, we’ll learn how to handle external\nfiles, update variables, and perform searches in strings.",
    "crumbs": [
      "Learning Modules",
      "03 | Functions, Flow Control, & Conditionals"
    ]
  },
  {
    "objectID": "learning-modules/03-functions-flow-control-and-conditionals.html#defining-new-functions",
    "href": "learning-modules/03-functions-flow-control-and-conditionals.html#defining-new-functions",
    "title": "03 | Functions, Flow Control, & Conditionals",
    "section": "2\nDefining new functions",
    "text": "2\nDefining new functions\nA function definition specifies the name of a new\nfunction and the sequence of statements that run when the function is\ncalled:\n\ndef print_lyrics():\n    print(\"Almost Heaven, West Virginia\")\n    print(\"Blue Ridge Mountains, Shenandoah River\")\n\ndef is a keyword that indicates a function definition.\nThe name of this function is print_lyrics. The empty\nparentheses after the name indicate that this function doesn’t take any\narguments.\nThe first line of the function definition is the\nheader, and the rest is the body. The\nheader must end with a colon, and the body must be indented (by\nconvention, four spaces). The body of this function is two\nprint() statements, but in general, the body can include\nany number of statements.\nDefining a function creates a function object, which\nyou can display:\n\nprint_lyrics\n\n&lt;function __main__.print_lyrics()&gt;\n\n\nThe output shows that print_lyrics takes no arguments.\n__main__ is the name of the module that contains\nprint_lyrics.\nYou can call this function the same way as any other Python\nfunction:\n\nprint_lyrics()\n\nAlmost Heaven, West Virginia\nBlue Ridge Mountains, Shenandoah River",
    "crumbs": [
      "Learning Modules",
      "03 | Functions, Flow Control, & Conditionals"
    ]
  },
  {
    "objectID": "learning-modules/03-functions-flow-control-and-conditionals.html#parameters",
    "href": "learning-modules/03-functions-flow-control-and-conditionals.html#parameters",
    "title": "03 | Functions, Flow Control, & Conditionals",
    "section": "3\nParameters",
    "text": "3\nParameters\nSome of the functions we’ve seen require arguments:\nabs() takes a number, and math.pow() takes two\narguments (the base and the exponent). We can make our own:\n\ndef print_twice(string):\n    print(string)\n    print(string)\n\nThe variable in parentheses is called a parameter.\nWhen the function is called, the value of the argument is assigned to\nthe parameter. For example:\n\nprint_twice(\"Hail WV!\")\n\nHail WV!\nHail WV!\n\n\nThis has the same effect as assigning the argument to the parameter\nand then executing the body:\n\nstring = \"Hail WV!\"\nprint(string)\nprint(string)\n\nHail WV!\nHail WV!\n\n\nYou can also pass a variable as an argument:\n\nline = \"Hail WV!\"\nprint_twice(line)\n\nHail WV!\nHail WV!",
    "crumbs": [
      "Learning Modules",
      "03 | Functions, Flow Control, & Conditionals"
    ]
  },
  {
    "objectID": "learning-modules/03-functions-flow-control-and-conditionals.html#calling-functions",
    "href": "learning-modules/03-functions-flow-control-and-conditionals.html#calling-functions",
    "title": "03 | Functions, Flow Control, & Conditionals",
    "section": "4 Calling\nfunctions",
    "text": "4 Calling\nfunctions\nOnce you define a function, you can use it inside another. Here’s a\nplayful example of printing lyrics for “Turn\nDown For What” by DJ Snake & Lil Jon:\nVerse:\nFire up that loud\nAnother round of shots\n\nChorus:\nTurn down for what?\nTurn down for what?\nTurn down for what?\nTurn down for what?\nTurn down for what?\n\nBuild:\nshots! shots! shots! shots!\nshots! shots! shots! shots!\nshots! shots! shots! shots!\nshots! shots! shots! shots!\nAs Lil Jon suggests, we need to buy a lot of rounds of shots. We can\nstart with a helper function:\n\ndef repeat(word, n):\n    print(word * n)\n\n\nrepeat(\"shots! \", 3)\n\nshots! shots! shots! \n\n\n\ndef print_build():\n    repeat(\"shots! \", 4)\n    repeat(\"shots! \", 4)\n    repeat(\"shots! \", 4)\n    repeat(\"shots! \", 4)\n\nprint_build()\n\nshots! shots! shots! shots! \nshots! shots! shots! shots! \nshots! shots! shots! shots! \nshots! shots! shots! shots! \n\n\nprint_build() calls repeat(), which then\ncalls print(). We could do the same with fewer functions,\nbut this illustrates how functions can work together.\nIf we want to control how many times repeat() repeats,\nwe add a parameter to print_build():\n\ndef print_build(n):\n    repeat(\"shots! \", n)\n    repeat(\"shots! \", n)\n    repeat(\"shots! \", n)\n    repeat(\"shots! \", n)\n\nThen we can call:\n\nprint_build(4)\n\nshots! shots! shots! shots! \nshots! shots! shots! shots! \nshots! shots! shots! shots! \nshots! shots! shots! shots! \n\n\nNext, let’s add verse and chorus functions:\n\ndef print_verse():\n    print(\"Fire up that loud\")\n    print(\"Another round of shots\")\n\nprint_verse()\n\nFire up that loud\nAnother round of shots\n\n\n\ndef print_chorus():\n    print(\"Turn down for what?\")\n    print(\"Turn down for what?\")\n    print(\"Turn down for what?\")\n    print(\"Turn down for what?\")\n    print(\"Turn down for what?\")\n\nprint_chorus()\n\nTurn down for what?\nTurn down for what?\nTurn down for what?\nTurn down for what?\nTurn down for what?\n\n\nNow bring it all together:\n\nprint_verse()\nprint_chorus()\nprint_verse()\nprint_chorus()\nprint_build(4)\n\nFire up that loud\nAnother round of shots\nTurn down for what?\nTurn down for what?\nTurn down for what?\nTurn down for what?\nTurn down for what?\nFire up that loud\nAnother round of shots\nTurn down for what?\nTurn down for what?\nTurn down for what?\nTurn down for what?\nTurn down for what?\nshots! shots! shots! shots! \nshots! shots! shots! shots! \nshots! shots! shots! shots! \nshots! shots! shots! shots! \n\n\nWe’re repeating some lines of code explicitly, which isn’t ideal.\nWe’ll address that soon.",
    "crumbs": [
      "Learning Modules",
      "03 | Functions, Flow Control, & Conditionals"
    ]
  },
  {
    "objectID": "learning-modules/03-functions-flow-control-and-conditionals.html#repetition",
    "href": "learning-modules/03-functions-flow-control-and-conditionals.html#repetition",
    "title": "03 | Functions, Flow Control, & Conditionals",
    "section": "5\nRepetition",
    "text": "5\nRepetition\nTo print something multiple times, you can use a for\nloop. Here’s a simple example:\n\nfor i in range(2):\n    print(i)\n\n0\n1\n\n\nrange(2) creates a sequence of two values:\n0 and 1. The loop assigns each value to\ni and then runs the body. When the sequence ends, the loop\nends.\nHere’s a loop that prints the verse twice:\n\nfor i in range(2):\n    print(\"Verse\", i)\n    print_verse(),\n    print() # adds a blank line\n\nVerse 0\nFire up that loud\nAnother round of shots\n\nVerse 1\nFire up that loud\nAnother round of shots\n\n\n\nA for loop can appear inside a function, such as this\none that prints the verse m times:\n\ndef print_m_verse(m):\n    for i in range(m):\n        print_verse()\n\nprint_m_verse(4)\n\nFire up that loud\nAnother round of shots\nFire up that loud\nAnother round of shots\nFire up that loud\nAnother round of shots\nFire up that loud\nAnother round of shots\n\n\nIn this example, we don’t use i in the body of the loop,\nbut there has to be a variable in the header anyway.",
    "crumbs": [
      "Learning Modules",
      "03 | Functions, Flow Control, & Conditionals"
    ]
  },
  {
    "objectID": "learning-modules/03-functions-flow-control-and-conditionals.html#variables-and-parameters-are-local",
    "href": "learning-modules/03-functions-flow-control-and-conditionals.html#variables-and-parameters-are-local",
    "title": "03 | Functions, Flow Control, & Conditionals",
    "section": "6\nVariables and parameters are local",
    "text": "6\nVariables and parameters are local\nA variable created inside a function is local,\nmeaning it only exists inside that function. Here’s an example:\n\ndef cat_twice(part_1, part_2):\n    cat = part_1 + part_2\n    print_twice(cat)\n\n\nline_1 = \"Country roads, \"\nline_2 = \"take me home.\"\ncat_twice(line_1, line_2)\n\nCountry roads, take me home.\nCountry roads, take me home.\n\n\nInside cat_twice(), cat is created. Outside of it,\ncat doesn’t exist:\n\nprint(cat)\n\n\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[75], line 1\n----&gt; 1 print(cat)\n\nNameError: name 'cat' is not defined\n\n\n\nParameters are also local. Outside cat_twice(),\npart_1 and part_2 don’t exist.",
    "crumbs": [
      "Learning Modules",
      "03 | Functions, Flow Control, & Conditionals"
    ]
  },
  {
    "objectID": "learning-modules/03-functions-flow-control-and-conditionals.html#tracebacks",
    "href": "learning-modules/03-functions-flow-control-and-conditionals.html#tracebacks",
    "title": "03 | Functions, Flow Control, & Conditionals",
    "section": "7\nTracebacks",
    "text": "7\nTracebacks\nWhen a runtime error occurs inside a function, Python shows a\ntraceback, listing the function that was running, the\nfunction that called it, and so on, up the “stack.” Here’s a\nprint_twice() that tries to print cat, which\nis a local variable in a different function:\n\ndef print_twice(string):\n    print(cat)              # NameError\n    print(cat)\n\n\ncat_twice(line_1, line_2)\n\n\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[77], line 1\n----&gt; 1 cat_twice(line_1, line_2)\n\nCell In[73], line 3, in cat_twice(part_1, part_2)\n      1 def cat_twice(part_1, part_2):\n      2     cat = part_1 + part_2\n----&gt; 3     print_twice(cat)\n\nCell In[76], line 2, in print_twice(string)\n      1 def print_twice(string):\n----&gt; 2     print(cat)              # NameError\n      3     print(cat)\n\nNameError: name 'cat' is not defined\n\n\n\nThe traceback shows that cat_twice() called\nprint_twice(), which caused the error.",
    "crumbs": [
      "Learning Modules",
      "03 | Functions, Flow Control, & Conditionals"
    ]
  },
  {
    "objectID": "learning-modules/03-functions-flow-control-and-conditionals.html#refactoring",
    "href": "learning-modules/03-functions-flow-control-and-conditionals.html#refactoring",
    "title": "03 | Functions, Flow Control, & Conditionals",
    "section": "8\nRefactoring",
    "text": "8\nRefactoring\nLet’s reorganize our “Turn Down for What” example to avoid repeated\ncode. This is called refactoring.\n\n# Original\ndef print_build(n):\n    repeat(\"shots! \", n)\n    repeat(\"shots! \", n)\n    repeat(\"shots! \", n)\n    repeat(\"shots! \", n)\n\n# Improved\ndef print_build(repeats, shots):\n    for i in range(repeats):\n        repeat(\"shots! \", shots)\n\nprint_build(4, 4)\n\nshots! shots! shots! shots! \nshots! shots! shots! shots! \nshots! shots! shots! shots! \nshots! shots! shots! shots! \n\n\n\n# Original\ndef print_verse():\n    print(\"Fire up that loud\")\n    print(\"Another round of shots\")\n\n# Improved\ndef print_verse(lines):\n    for i in range(lines):\n        print(\"Fire up that loud\")\n        print(\"Another round of shots\")\n\nprint_verse(4)\n\nFire up that loud\nAnother round of shots\nFire up that loud\nAnother round of shots\nFire up that loud\nAnother round of shots\nFire up that loud\nAnother round of shots\n\n\n\n# Original\ndef print_chorus():\n    print(\"Turn down for what?\")\n    print(\"Turn down for what?\")\n    print(\"Turn down for what?\")\n    print(\"Turn down for what?\")\n    print(\"Turn down for what?\")\n\n# Improved\ndef print_chorus(lines):\n    for i in range(lines):\n        print(\"Turn down for what?\")\n\nprint_chorus(6)\n\nTurn down for what?\nTurn down for what?\nTurn down for what?\nTurn down for what?\nTurn down for what?\nTurn down for what?\n\n\nPutting it all together:\n\nprint_verse(1)\nprint()\nprint_chorus(5)\nprint()\nprint_verse(1)\nprint()\nprint_chorus(5)\nprint()\nprint_verse(4)\nprint()\nprint_build(6, 4)\nprint()\nprint_chorus(5)\n\nFire up that loud\nAnother round of shots\n\nTurn down for what?\nTurn down for what?\nTurn down for what?\nTurn down for what?\nTurn down for what?\n\nFire up that loud\nAnother round of shots\n\nTurn down for what?\nTurn down for what?\nTurn down for what?\nTurn down for what?\nTurn down for what?\n\nFire up that loud\nAnother round of shots\nFire up that loud\nAnother round of shots\nFire up that loud\nAnother round of shots\nFire up that loud\nAnother round of shots\n\nshots! shots! shots! shots! \nshots! shots! shots! shots! \nshots! shots! shots! shots! \nshots! shots! shots! shots! \nshots! shots! shots! shots! \nshots! shots! shots! shots! \n\nTurn down for what?\nTurn down for what?\nTurn down for what?\nTurn down for what?\nTurn down for what?\n\n\nRefactoring improves the code’s structure without changing its\nbehavior. If we had planned the structure from the start, we might have\navoided this step, but sometimes you only see a better design after you\nstart coding.",
    "crumbs": [
      "Learning Modules",
      "03 | Functions, Flow Control, & Conditionals"
    ]
  },
  {
    "objectID": "learning-modules/03-functions-flow-control-and-conditionals.html#why-functions",
    "href": "learning-modules/03-functions-flow-control-and-conditionals.html#why-functions",
    "title": "03 | Functions, Flow Control, & Conditionals",
    "section": "9 Why\nfunctions?",
    "text": "9 Why\nfunctions?\n\nReadability: Naming groups of statements makes code\neasier to read and debug.\nReusability: Functions eliminate repetitive code.\nChanges become easier to manage.\nModularity: Breaking down a program into functions\nlets you debug parts individually.\nReuse: Well-designed functions can be used by other\nprograms.\n\nWrapping code in a function is called encapsulation.\nOne advantage is that a name serves as documentation. Another is that\ncalling a function is more concise than copying and pasting its\nbody.\nAdding parameters to a function is called\ngeneralization, because it makes the function more\ngeneral – for example, printing \"shots!\" any number of\ntimes.\nWhen a function has several numerical arguments, it’s easy to mix\nthem up. You can use keyword arguments to specify each\nargument by name:\n\ndef print_build(repeats, shots):\n    for i in range(repeats):\n        repeat(\"shots! \", shots)\n\nprint_build(repeats=8, shots=4)\nprint()\nprint_build(shots=4, repeats=8)\n\nshots! shots! shots! shots! \nshots! shots! shots! shots! \nshots! shots! shots! shots! \nshots! shots! shots! shots! \nshots! shots! shots! shots! \nshots! shots! shots! shots! \nshots! shots! shots! shots! \nshots! shots! shots! shots! \n\nshots! shots! shots! shots! \nshots! shots! shots! shots! \nshots! shots! shots! shots! \nshots! shots! shots! shots! \nshots! shots! shots! shots! \nshots! shots! shots! shots! \nshots! shots! shots! shots! \nshots! shots! shots! shots!",
    "crumbs": [
      "Learning Modules",
      "03 | Functions, Flow Control, & Conditionals"
    ]
  },
  {
    "objectID": "learning-modules/03-functions-flow-control-and-conditionals.html#docstrings",
    "href": "learning-modules/03-functions-flow-control-and-conditionals.html#docstrings",
    "title": "03 | Functions, Flow Control, & Conditionals",
    "section": "10\nDocstrings",
    "text": "10\nDocstrings\nA docstring is a string at the start of a function\nthat explains its interface:\n\ndef print_build(repeats, shots):\n    \"\"\"Prints \"shots\" for a custom amount of times and lines\n\n    repeats: number of lines of lyrics\n    shots: number of times \"shots\" is printed per line\n    \"\"\"\n    for i in range(repeats):\n        repeat(\"shots! \", shots)\n\nA good docstring explains what the function does and the effect of\neach parameter, without diving into internal details.",
    "crumbs": [
      "Learning Modules",
      "03 | Functions, Flow Control, & Conditionals"
    ]
  },
  {
    "objectID": "learning-modules/03-functions-flow-control-and-conditionals.html#if-statements",
    "href": "learning-modules/03-functions-flow-control-and-conditionals.html#if-statements",
    "title": "03 | Functions, Flow Control, & Conditionals",
    "section": "11\nif statements",
    "text": "11\nif statements\nConditional statements let you check conditions and\nchange the program’s behavior. The simplest form is the if\nstatement:\nif x &gt; 0:\n    print('x is positive')\nThe boolean expression after if is called the condition.\nIf it’s true, Python executes the indented block; otherwise, it skips\nit.\nIf you need a block that does nothing, use pass:\nif x &lt; 0:\n    pass          # TODO: need to handle negative values!",
    "crumbs": [
      "Learning Modules",
      "03 | Functions, Flow Control, & Conditionals"
    ]
  },
  {
    "objectID": "learning-modules/03-functions-flow-control-and-conditionals.html#boolean-expressions-and-logical-operators",
    "href": "learning-modules/03-functions-flow-control-and-conditionals.html#boolean-expressions-and-logical-operators",
    "title": "03 | Functions, Flow Control, & Conditionals",
    "section": "12\nBoolean expressions and logical operators",
    "text": "12\nBoolean expressions and logical operators\nA boolean expression is either True or\nFalse. For instance:\n\n5 == 5\n\nTrue\n\n\n\n5 == 7\n\nFalse\n\n\nThe double equal sign == compares two values for\nequality.\n\n\n\n\n\n\nTip\n\n\n\nA common error is to use a single equal sign (=) instead\nof a double equal sign (==). Remember that =\nassigns a value to a variable and == compares two\nvalues.\n\n\nOther relational operators include:\nx != y # x is not equal to y\nx &gt; y  # x is greater than y\nx &lt; y  # x is less than to y\nx &gt;= y # x is greater than or equal to y\nx &lt;= y # x is less than or equal to y\nYou can combine boolean expressions with logical\noperators: and, or, and\nnot. For example:\nx &gt; 0 and x &lt; 10\nx % 2 == 0 or x % 3 == 0\nnot x &gt; y",
    "crumbs": [
      "Learning Modules",
      "03 | Functions, Flow Control, & Conditionals"
    ]
  },
  {
    "objectID": "learning-modules/03-functions-flow-control-and-conditionals.html#the-else-clause",
    "href": "learning-modules/03-functions-flow-control-and-conditionals.html#the-else-clause",
    "title": "03 | Functions, Flow Control, & Conditionals",
    "section": "13 The\nelse clause",
    "text": "13 The\nelse clause\nif can include an else clause:\nif x % 2 == 0:\n    print('x is even')\nelse:\n    print('x is odd')\nOne branch runs if the condition is true, the other if it’s\nfalse.",
    "crumbs": [
      "Learning Modules",
      "03 | Functions, Flow Control, & Conditionals"
    ]
  },
  {
    "objectID": "learning-modules/03-functions-flow-control-and-conditionals.html#chained-conditionals",
    "href": "learning-modules/03-functions-flow-control-and-conditionals.html#chained-conditionals",
    "title": "03 | Functions, Flow Control, & Conditionals",
    "section": "14\nChained conditionals",
    "text": "14\nChained conditionals\nWhen you have more than two possibilities, use elif:\nif x &lt; y:\n    print('x is less than y')\nelif x &gt; y:\n    print('x is greater than y')\nelse:\n    print('x and y are equal')\nConditions are checked in order, and only the first true branch\nruns.",
    "crumbs": [
      "Learning Modules",
      "03 | Functions, Flow Control, & Conditionals"
    ]
  },
  {
    "objectID": "learning-modules/03-functions-flow-control-and-conditionals.html#nested-conditionals",
    "href": "learning-modules/03-functions-flow-control-and-conditionals.html#nested-conditionals",
    "title": "03 | Functions, Flow Control, & Conditionals",
    "section": "15\nNested Conditionals",
    "text": "15\nNested Conditionals\nOne conditional can be nested within another, but it can be harder to\nread:\nif 0 &lt; x:\n    if x &lt; 10:\n        print('x is a positive single-digit number.')\nLogical operators often simplify nested conditionals:\nif 0 &lt; x and x &lt; 10:\n    print('x is a positive single-digit number.')\nFor this kind of condition, Python provides a more concise\noption:\nif 0 &lt; x &lt; 10:\n    print('x is a positive single-digit number.')",
    "crumbs": [
      "Learning Modules",
      "03 | Functions, Flow Control, & Conditionals"
    ]
  },
  {
    "objectID": "learning-modules/03-functions-flow-control-and-conditionals.html#some-functions-have-return-values",
    "href": "learning-modules/03-functions-flow-control-and-conditionals.html#some-functions-have-return-values",
    "title": "03 | Functions, Flow Control, & Conditionals",
    "section": "16 Some\nfunctions have return values",
    "text": "16 Some\nfunctions have return values\nFunctions like abs, round,\nmath.sqrt, and math.pow return a value. You\ncan assign that value to a variable or use it in an expression:\n\nimport math\nradius = math.sqrt(42 / math.pi)\narea = math.pi * radius**2\n\nYou can also write your own function with a return value:\n\ndef circle_area(radius):\n    area = math.pi * radius**2\n    return area\n\n\na = circle_area(radius)\na\n\n42.00000000000001\n\n\nHowever, local variables inside a function (like area)\ndon’t exist outside that function.\n\narea\n\n42.00000000000001",
    "crumbs": [
      "Learning Modules",
      "03 | Functions, Flow Control, & Conditionals"
    ]
  },
  {
    "objectID": "learning-modules/03-functions-flow-control-and-conditionals.html#and-some-have-none",
    "href": "learning-modules/03-functions-flow-control-and-conditionals.html#and-some-have-none",
    "title": "03 | Functions, Flow Control, & Conditionals",
    "section": "17 And\nsome have None",
    "text": "17 And\nsome have None\nIf a function doesn’t use return, it returns\nNone, a special value:\n\ndef repeat(word, n):\n    print(word * n)\n\nThis function uses the print function to display a\nstring, but it does not use a return statement to return a\nvalue. If we assign the result to a variable, it displays the string\nanyway.\n\nresult = repeat('Shots! ', 3)\nprint(result)  # Displays None\n\nShots! Shots! Shots! \nNone\n\n\nIf you want a function that returns a string rather than prints it,\nyou can do:\n\ndef repeat_string(word, n):\n    return word * n\n\nNotice that we can use an expression in a return statement, not just\na variable.",
    "crumbs": [
      "Learning Modules",
      "03 | Functions, Flow Control, & Conditionals"
    ]
  },
  {
    "objectID": "learning-modules/03-functions-flow-control-and-conditionals.html#return-values-and-conditionals",
    "href": "learning-modules/03-functions-flow-control-and-conditionals.html#return-values-and-conditionals",
    "title": "03 | Functions, Flow Control, & Conditionals",
    "section": "18\nReturn values and conditionals",
    "text": "18\nReturn values and conditionals\nA function can have multiple return statements, such as a\nreimplementation of abs:\n\ndef absolute_value(x):\n    if x &lt; 0:\n        return -x\n    else:\n        return x\n\nMake sure thath every possible path hits a return statement:\n\ndef absolute_value_wrong(x):\n    if x &lt; 0:\n        return -x\n    if x &gt; 0:\n        return x\n    # If x is 0, returns None (missing a final else branch)",
    "crumbs": [
      "Learning Modules",
      "03 | Functions, Flow Control, & Conditionals"
    ]
  },
  {
    "objectID": "learning-modules/03-functions-flow-control-and-conditionals.html#boolean-functions",
    "href": "learning-modules/03-functions-flow-control-and-conditionals.html#boolean-functions",
    "title": "03 | Functions, Flow Control, & Conditionals",
    "section": "19\nBoolean functions",
    "text": "19\nBoolean functions\nFunctions can return the boolean values True and\nFalse, which is often convenient for encapsulating a\ncomplex test in a function. For example, is_divisible\nchecks whether x is divisible by y with no remainder.\n\ndef is_divisible(x, y):\n    if x % y == 0:\n        return True\n    else:\n        return False\n\n\nis_divisible(6, 4)\n\nFalse\n\n\n\nis_divisible(6, 3)\n\nTrue\n\n\nInside the function, the result of the == operator is a\nboolean, so we can write the function more concisely by returning it\ndirectly:\n\ndef is_divisible(x, y):\n    return x % y == 0\n\nBoolean functions are often used in conditional statements:\n\nif is_divisible(6, 2):\n    print('divisible')\n\ndivisible\n\n\nIt might be tempting to write something like this:\n\nif is_divisible(6, 2) == True:\n    print('divisible')\n\ndivisible\n\n\nBut the comparison is unnecessary.",
    "crumbs": [
      "Learning Modules",
      "03 | Functions, Flow Control, & Conditionals"
    ]
  },
  {
    "objectID": "learning-modules/03-functions-flow-control-and-conditionals.html#input-validation",
    "href": "learning-modules/03-functions-flow-control-and-conditionals.html#input-validation",
    "title": "03 | Functions, Flow Control, & Conditionals",
    "section": "20 Input\nvalidation",
    "text": "20 Input\nvalidation\nWe now have all the tools we need to make sure that the programs we\nwrite will be executed fully, regardless of user error.\nRemember, if the end use can mess up your instructions they will.\nSound familiar?\nLet’s go back to the example of calculating the volume of a sphere\nwith a succinct function using what we’ve learned so far:\n\ndef volume_of_sphere(radius):\n    from math import pi\n    return (4/3) * pi * radius**3\n\nIf radius is an integer or float, no problem. But if we get a string,\nwe will get an error:\n\nprint(volume_of_sphere(4))\nprint(volume_of_sphere(\"4\"))\n\n268.082573106329\n\n\n\n---------------------------------------------------------------------------\nTypeError                                 Traceback (most recent call last)\nCell In[102], line 2\n      1 print(volume_of_sphere(4))\n----&gt; 2 print(volume_of_sphere(\"4\"))\n\nCell In[101], line 3, in volume_of_sphere(radius)\n      1 def volume_of_sphere(radius):\n      2     from math import pi\n----&gt; 3     return (4/3) * pi * radius**3\n\nTypeError: unsupported operand type(s) for ** or pow(): 'str' and 'int'\n\n\n\nWhile the default error message gives the user an idea of what’s\nwrong, we can handle this more gracefully:\n\ndef volume_of_sphere(radius):\n    if type(radius) == int or type(radius) == float:\n        from math import pi\n        return (4/3) * pi * radius**3\n    else:\n        print(\"Input was not a number, try again.\")\n        return None\n\nvolume_of_sphere(\"5\")\n\nInput was not a number, try again.\n\n\nIf this were a standalone program, it would return a result instead\nof stopping execution with an error.",
    "crumbs": [
      "Learning Modules",
      "03 | Functions, Flow Control, & Conditionals"
    ]
  },
  {
    "objectID": "learning-modules/03-functions-flow-control-and-conditionals.html#debugging",
    "href": "learning-modules/03-functions-flow-control-and-conditionals.html#debugging",
    "title": "03 | Functions, Flow Control, & Conditionals",
    "section": "21\nDebugging",
    "text": "21\nDebugging\nDebugging can be frustrating, but it is also challenging,\ninteresting, and sometimes even fun. And it is one of the most important\nskills you can learn.\nIn some ways debugging is like detective work. You are given clues\nand you have to infer the events that led to the results you see.\nDebugging is also like experimental science. Once you have an idea\nabout what is going wrong, you modify your program and try again. If\nyour hypothesis was correct, you can predict the result of the\nmodification, and you take a step closer to a working program. If your\nhypothesis was wrong, you have to come up with a new one.\nFor some people, programming and debugging are the same thing; that\nis, programming is the process of gradually debugging a program until it\ndoes what you want. The idea is that you should start with a working\nprogram and make small modifications, debugging them as you go.\nIf you find yourself spending a lot of time debugging, that is often\na sign that you are writing too much code before you start tests. If you\ntake smaller steps, you might find that you can move faster.\n\nWhen a syntax or runtime error occurs, the error message contains a\nlot of information, but it can be overwhelming. The most useful parts\nare usually:\n\nWhat kind of error it was, and\nWhere it occurred.\n\nSyntax errors are usually easy to find, but there are a few gotchas.\nErrors related to spaces and tabs can be tricky because they are\ninvisible and we are used to ignoring them.\n\nx = 5\n y = 6\n\n\n  Cell In[104], line 2\n    y = 6\n    ^\nIndentationError: unexpected indent\n\n\n\n\nIn this example, the problem is that the second line is indented by\none space. But the error message points to y, which is\nmisleading. Error messages indicate where the problem was discovered,\nbut the actual error might be earlier in the code.\nThe same is true of runtime errors. For example, suppose you are\ntrying to convert a ratio to decibels, like this:\n\nimport math\nnumerator = 9\ndenominator = 10\nratio = numerator // denominator\ndecibels = 10 * math.log10(ratio)\n\n\n---------------------------------------------------------------------------\nValueError                                Traceback (most recent call last)\nCell In[105], line 5\n      3 denominator = 10\n      4 ratio = numerator // denominator\n----&gt; 5 decibels = 10 * math.log10(ratio)\n\nValueError: math domain error\n\n\n\nThe error message indicates line 5, but there is nothing wrong with\nthat line. The problem is in line 4, which uses integer division instead\nof floating-point division – as a result, the value of\nratio is 0. When we call\nmath.log10, we get a ValueError with the\nmessage math domain error, because 0 is not in\nthe “domain” of valid arguments for math.log10, because the\nlogarithm of 0 is undefined.\nIn general, you should take the time to read error messages\ncarefully, but don’t assume that everything they say is correct.\n\nBreaking a large program into smaller functions creates natural\ncheckpoints for debugging. If a function is not working, there are three\npossibilities to consider:\n\nThere is something wrong with the arguments the function is getting\n– that is, a precondition is violated.\nThere is something wrong with the function – that is, a\npostcondition is violated.\nThe caller is doing something wrong with the return value.\n\nTo rule out the first possibility, you can add a print\nstatement at the beginning of the function that displays the values of\nthe parameters (and maybe their types). Or you can write code that\nchecks the preconditions explicitly.\n\n\n\n\n\n\nTip\n\n\n\nThis is a very basic version of logging.\n\n\nIf the parameters look good, you can add a print statement before\neach return statement and display the return value. If possible, call\nthe function with arguments that make it easy check the result.\nIf the function seems to be working, look at the function call to\nmake sure the return value is being used correctly – or used at all!\nAdding print statements at the beginning and end of a\nfunction can help make the flow of execution more visible for testing.\nFor example, here is a version of volume_of_sphere with\nprint statements:\n\ndef volume_of_sphere(radius):\n    if type(radius) == int or type(radius) == float:\n        print(f\"Radius is a valid type: {type(radius)}\") # Showing radius is fine\n        from math import pi\n        return (4/3) * pi * radius**3\n    else:\n        print(\"Input was not a number, try again.\") # In original example, showing radius was not fine\n        return None\n\n\nvol = volume_of_sphere(5)\nprint(vol)\n\nRadius is a valid type: &lt;class 'int'&gt;\n523.5987755982989\n\n\n\nvol = volume_of_sphere(\"5\")\nvol\n\nInput was not a number, try again.",
    "crumbs": [
      "Learning Modules",
      "03 | Functions, Flow Control, & Conditionals"
    ]
  },
  {
    "objectID": "learning-modules/03-functions-flow-control-and-conditionals.html#exercises",
    "href": "learning-modules/03-functions-flow-control-and-conditionals.html#exercises",
    "title": "03 | Functions, Flow Control, & Conditionals",
    "section": "22\nExercises",
    "text": "22\nExercises\n\n22.1\nRight-Align Text\nWrite a function named print_right() that takes a string\nnamed text as a parameter and prints the string with enough\nleading spaces that the last letter of the string is in the 40th column\nof the display.\nHint: Use len(), +, and *.\nHere’s an example output:\nprint_right(\"Monty\")\nprint_right(\"Python's\")\nprint_right(\"Flying Circus\")\n                                   Monty\n                                Python's\n                           Flying Circus\n\n\n22.2\nDraw a Triangle\nWrite a function called triangle that takes a string and\nan integer, then draws a pyramid of the given height using copies of the\nstring. For example:\ntriangle(\"L\", 5)\nL\nLL\nLLL\nLLLL\nLLLLL\n\n\n22.3\nDraw a Rectangle\nWrite a function called rectangle that takes a string\nand two integers, then draws a rectangle of the given width and height\nusing copies of the string. For example:\nrectangle(\"[]\", 5, 4)\n[][][][][]\n[][][][][]\n[][][][][]\n[][][][][]\n\n\n22.4\nTriangle Tester\nWrite a function named is_triangle that takes three\nintegers as arguments and returns True or False depending on whether you\ncan form a triangle with those lengths. Use the rule:\n\nIf any of the three lengths is greater than the sum of the other two,\nthen you cannot form a triangle. Otherwise, you can. (If the sum of two\nlengths equals the third, they form what is called a “degenerate”\ntriangle.)\n\nHint: Use a chained conditional.\n\n\n22.5\nCheck “Between”\nWrite a boolean function is_between(x, y, z), that\nreturns True if \\(x &lt; y &lt;\nz\\) or if \\(z &lt; y &lt; x\\),\nand False otherwise.",
    "crumbs": [
      "Learning Modules",
      "03 | Functions, Flow Control, & Conditionals"
    ]
  },
  {
    "objectID": "learning-modules/01-setting-up-your-workstation.html",
    "href": "learning-modules/01-setting-up-your-workstation.html",
    "title": "01 | Setting Up Your Workstation",
    "section": "",
    "text": "In this course, we will spend time learning three critical tools for\ndata science:\n\nThe Command Line\nSQL (which we’ll cover in depth the second half\nof the course)\nPython\n\nPython is usually ranked as the\nfirst or second most popular programming language in the world and, just\nas importantly, it’s also one of the easiest to learn. It’s a general\npurpose language, which means it can perform a wide range of tasks. The\njoke goes that Python is the 2nd best language at everything, and\nthere’s some truth to that (although Python is best at some tasks, like\nmachine learning).\nInstead of re-writing the great documentation offered by the\nproducts, I will provide you with links to the sections that are most\nimportant, as well as some extra resources that you might find\nhelpful.\nIn the realm of software, documentation is your friend, you will not\nalways have a teacher to tell you exactly what to do, so learning to go\nthrough documentation is an important skill of itself. Do not skim\nthrough the instructions provided. If there are any non-default options\nneeded, I will mention them.\n\n\n\n\n\n\nWarning\n\n\n\nThis is going to be by far the most tedious of the lectures in this\ncourse. Setting up your computer and environment is a pain but it must\nbe done. This module will comprise of a lot of reading and not a whole\nlot of doing, but it’s essential you understand the basics of these\ntools to be successful in class. The following modules will be much more\nhands on and interactive.",
    "crumbs": [
      "Learning Modules",
      "01 | Setting Up Your Workstation"
    ]
  },
  {
    "objectID": "learning-modules/01-setting-up-your-workstation.html#overview",
    "href": "learning-modules/01-setting-up-your-workstation.html#overview",
    "title": "01 | Setting Up Your Workstation",
    "section": "",
    "text": "In this course, we will spend time learning three critical tools for\ndata science:\n\nThe Command Line\nSQL (which we’ll cover in depth the second half\nof the course)\nPython\n\nPython is usually ranked as the\nfirst or second most popular programming language in the world and, just\nas importantly, it’s also one of the easiest to learn. It’s a general\npurpose language, which means it can perform a wide range of tasks. The\njoke goes that Python is the 2nd best language at everything, and\nthere’s some truth to that (although Python is best at some tasks, like\nmachine learning).\nInstead of re-writing the great documentation offered by the\nproducts, I will provide you with links to the sections that are most\nimportant, as well as some extra resources that you might find\nhelpful.\nIn the realm of software, documentation is your friend, you will not\nalways have a teacher to tell you exactly what to do, so learning to go\nthrough documentation is an important skill of itself. Do not skim\nthrough the instructions provided. If there are any non-default options\nneeded, I will mention them.\n\n\n\n\n\n\nWarning\n\n\n\nThis is going to be by far the most tedious of the lectures in this\ncourse. Setting up your computer and environment is a pain but it must\nbe done. This module will comprise of a lot of reading and not a whole\nlot of doing, but it’s essential you understand the basics of these\ntools to be successful in class. The following modules will be much more\nhands on and interactive.",
    "crumbs": [
      "Learning Modules",
      "01 | Setting Up Your Workstation"
    ]
  },
  {
    "objectID": "learning-modules/01-setting-up-your-workstation.html#your-computer-and-the-command-line",
    "href": "learning-modules/01-setting-up-your-workstation.html#your-computer-and-the-command-line",
    "title": "01 | Setting Up Your Workstation",
    "section": "2 Your\ncomputer and the command line",
    "text": "2 Your\ncomputer and the command line\nBefore we install these tools, we need to get comfortable using the\ncommand line. But what exactly is it? Let me explain.\nWhen people refer to the command line, you might hear terms like\nterminal, console, CLI\n(command-line interface), and shell used\ninterchangeably. While they’re related, they’re not exactly the same\nthing. For this course, you don’t need to fully understand every nuance,\nbut having a general sense of these terms will help clear up\nconfusion.\n\n2.1\nConsole\nA console historically refers to the physical device used to interact\nwith a computer. In modern terms, it includes the combination of your\ncomputer’s screen, keyboard, and mouse.\n\n\n\nIn the past, consoles were often standalone machines with\nbuilt-in screens and keyboards. Today, the term is used less often, but\nit’s good to understand its origins.\n\n\n\n\n2.2\nTerminal\nA terminal is a program that allows\nyou to enter commands into your computer. Think of it as the “window” or\n“app” where you type the instructions that your computer processes.\nFor example:\n\nOn Windows, the terminal is called Windows\nTerminal.\nOn Mac, it’s simply called Terminal.\n\nThe terminal is just like any other program on your computer, such as\nWord or Excel. You can even replace the default terminal with other\noptions or use terminals built into tools like Visual Studio Code\n(foreshadowing??). While it may seem intimidating, it’s just a\ntool for interacting with your computer through text commands.\n\n\n2.3\nCommand line or Command-Line Interface (CLI)\nThe command-line interface (CLI) is the actual\ninterface where you type commands for your computer to\nprocess. It’s a way of interacting with your operating system using\ntext, rather than clicking with a mouse (which is how you use a GUI, or\ngraphical user interface).\nThe CLI exists inside the terminal, and you can think of it as the\nengine running underneath. For simplicity, you can treat the terms\nterminal and CLI as interchangeable in this course.\n\n\n2.4\nShell\nA shell is a program that acts as\nthe interpreter for the commands you enter into the CLI. It takes what\nyou type, processes it, and returns the results.\nYour computer’s shell comes pre-installed:\n\nLinux: Bash (Bourne\nAgain Shell)\nMac: Zsh (Z Shell)\nWindows: PowerShell\n(successor to Command Prompt)\n\nA shell also allows you to create scripts, which are\nfiles containing sets of commands to automate tasks. While scripting is\nsimilar to programming in languages like Python or R, it’s not the focus\nof this course. For now, we’ll stick to typing individual commands.\n\n\n2.5 Web\nSearching as an Analogy\nLet’s connect what we’ve learned so far with an example of searching\nthe web:\n\nTerminal: the terminal is like your web\nbrowser (Chrome, Edge, or Safari). It’s the environment or\n“window” where everything happens.\nCLI: The CLI is like the search\nbar inside your browser (or the one on the mage page of Google\nor Bing). It’s where you type in your commands (or search queries) for\nthe system to process.\nShell: The Shell is the search engine\nitself (Google Search or Bing Search). It takes the query you\nentered, processes it, and returns the results.\n\n\n\n2.6 Why\nare we using the CLI?\nSimply put, many tools in the realm of data analytics, data science,\nand data engineering are designed with the command line in mind first.\nGraphical user interfaces (GUIs) may follow, but the command line often\nremains the most powerful and flexible way to interact with these tools.\nIn this class, we need a basic understanding of the CLI to install and\nset up essential tools and occasionally run scripts.\n\n\n\n\n\n\nTip\n\n\n\nDon’t be intimidated by the command line! While you may be more\nfamiliar with tools or apps that have a visual interface, the command\nline provides a powerful way to control your computer. If it’s any\nsolace, after this initial setup assignment, we will use the command\nline sparingly. It’s just essential for getting started.\n\n\n\n\n2.7\nUnderstanding working directories\nWhen you use the command line, the concept of a working directory is\ncrucial. The working directory is the folder where your commands operate\nby default. It’s like being inside the room in a building, you can only\ninteract with the items inside that room unless you explicitly move to a\ndifferent room.\nFor example, if you see this prompt on the command line:\n\n\nCLI\n\nC:\\Users\\oo0006\\Desktop&gt;\n\nIt means the current working directory is the Desktop\nfolder inside the user directory of the user oo0006. If you\ntype a command like dir (to list the files in the working\ndirectory), it will show the contents of the Desktop\nfolder.\n\n2.7.1\nCommon symbols and their meaning\n\n\\ (Backslash): Used in Windows paths to separate\nfolders (e.g., C:\\Users\\oo0006\\Desktop).\n/ (Forward Slash): Used in Unix-like systems (Linux,\nmacOS) for the same purpose (e.g.,\n/home/user/Desktop).\n$: In many tutorials, this symbol represents the\nstart of a command in the command line. It’s a convention to indicate\nyou should enter a command into the terminal. For instance,\nfollowing code cell means you should type ls into the\nterminal and press Enter.:\n\n\n\nCLI\n\n$ ls\n\n\n\n\n\n\n\nTip\n\n\n\nThis is the convention I will be following in my material.\n\n\n\n&gt;: In Windows, this symbol is part of the prompt and\nindicates the terminal is ready for your input.\n\n\n\n2.7.2\nChanging directories\nTo navigate the file system in the command line, you use the\ncd (change directory) command:\n\nTo move to a specific folder (if you’re in\nC:\\Users\\oo0006\\, this will take you to\nC:\\Users\\oo0006\\Documents):\n\n\n\nCLI\n\n$ cd Documents\n\n\nTo go up one level (if you’re in\nC:\\Users\\oo0006\\Documents, this will take you back to\nC:\\Users\\oo0006\\):\n\n\n\nCLI\n\n$ cd ..\n\n\nTo move directly to another folder:\n\n\n\nCLI\n\n$ cd C:\\Program Files\n\nThis takes you straight to C:\\Program Files, no matter\nwhere you were previously.\n\n\n\n2.8 Key\ntakeaways\n\nThe command line is a powerful tool, don’t let its simplicity fool\nyou.\nThe working directory determines where commands will execute by\ndefault.\nUnderstanding the prompt and basic navigation commands like\ncd can make the command line much less intimidating.",
    "crumbs": [
      "Learning Modules",
      "01 | Setting Up Your Workstation"
    ]
  },
  {
    "objectID": "learning-modules/01-setting-up-your-workstation.html#visual-studio-code",
    "href": "learning-modules/01-setting-up-your-workstation.html#visual-studio-code",
    "title": "01 | Setting Up Your Workstation",
    "section": "3 Visual\nStudio Code",
    "text": "3 Visual\nStudio Code\nNow, let’s get into our first general purpose tool: Visual Studio Code. Often\nreferred to as VS Code, this free, lightweight, and versatile code\neditor is beloved by developers worldwide. It’s available on macOS,\nLinux, and Windows, and it’s packed with features that make coding more\nefficient and enjoyable.\n\n3.1\nInstallation\nGetting started with VS Code is quick and straightforward. The\ninstallation process is user-friendly, with a small download size\nallowing you to get up and running in minutes.\n\nWindows Users: Follow the Windows\ninstallation guide. Select “Add to PATH” and “Register as default\neditor” during installation.\nmacOS Users: The macOS\ninstallation guide provides clear instructions. You can install it\nvia the .dmg file or with Homebrew if you’re familiar with\nit.\n\n\n\n3.2\nLearning VS Code\nVS Code has a ton of great resources to help you get started, whether\nyou prefer written guides or video tutorials:\n\nDocumentation: The official Getting\nStarted Guide walks you through the basics, including setting up\nyour first project and understanding the interface.\nTutorials: Explore Tips\nand Tricks to discover shortcuts, hidden features, and best\npractices.\nVideos: If you prefer visual learning, check out\ntheir Intro\nVideos for step-by-step walkthroughs.\n\nAt the minimum, read the Get Started module as it covers everything\nfrom navigation to extensions. For those already familiar with coding,\nthe tips and tricks section is a great way to optimize your\nworkflow.\n\n\n3.3\nExtensions\nOne of the best features of VS Code is its flexibility through its extensions.\n\n3.3.1\nRequired extensions\nThese extensions are necessary for completing the coursework:\n\nJupyter (Microsoft): Enables seamless interaction\nwith Jupyter Notebooks.\nPython (Microsoft): Provides Python language\nsupport, including IntelliSense, linting, and debugging.\nQuarto (Quarto): Allows you to write, render, and\npreview Quarto documents.\nRuff (Astral Software): A fast Python linter to\nensure clean, error-free code.\n\n\n\n3.3.2\nRecommended extensions\nOptional extensions to improve productivity and make coding more\nenjoyable:\n\nCode Spell Checker (Street Side Software): Helps\ncatch typos and spelling errors.\nMaterial Icon Theme (Philip Kief): Enhances the\nfile explorer with modern, visually appealing icons.\nRainbow CSV (mechatroner): Adds syntax highlighting\nfor CSV files, making them easier to work with.\nCustomize your coding environment with themes.\n\nI will be using NordStone (Rui Costa).",
    "crumbs": [
      "Learning Modules",
      "01 | Setting Up Your Workstation"
    ]
  },
  {
    "objectID": "learning-modules/01-setting-up-your-workstation.html#git-github-github-desktop",
    "href": "learning-modules/01-setting-up-your-workstation.html#git-github-github-desktop",
    "title": "01 | Setting Up Your Workstation",
    "section": "4 Git,\nGitHub, & GitHub Desktop",
    "text": "4 Git,\nGitHub, & GitHub Desktop\nGit\nis a version control system that intelligently tracks changes in files.\nGit is particularly useful when you and a group of people are all making\nchanges to the same files at the same time.\nTypically, to do this in a Git-based workflow, you would:\n\nCreate a branch off from the main copy of files\nthat you (and your collaborators) are working on.\nMake edits to the files independently and safely on\nyour own personal branch.\nLet Git intelligently merge your specific changes\nback into the main copy of files, so that your changes don’t impact\nother people’s updates.\nLet Git keep track of your and other people’s\nchanges, so you all stay working on the most up-to-date version of the\nproject.\n\nGitHub is a cloud-based platform\nwhere you can store, share, and work together with others to write code.\nYou can think of Git as the engine that GitHub runs on.\nStoring your code in a “repository” on GitHub allows you to:\n\nShowcase or share your work.\nTrack and manage changes to your code over time.\nLet others review your code, and make suggestions to improve\nit.\nCollaborate on a shared project, without worrying that your changes\nwill impact the work of your collaborators before you’re ready to\nintegrate them.\n\nWhen you upload files to GitHub, you’ll store them in a “Git\nrepository.” This means that when you make changes (or “commits”) to\nyour files in GitHub, Git will automatically start to track and manage\nyour changes.\nThere are plenty of Git-related actions that you can complete on\nGitHub directly in your browser, such as creating a Git repository,\ncreating branches, and uploading and editing files. But, most people\nwork on their files locally (on their own computer), then continually\nsync these local changes—and all the related Git data—with the central\n“remote” repository on GitHub. This is how we will interact with GitHub\nin this course, with the help of GitHub Desktop.\n\n\n\nGitHub Desktop Interface\n\n\nOnce you start to collaborate with others and all need to work on the\nsame repository at the same time, you’ll continually:\n\nPull all the latest changes made by your\ncollaborators from the remote repository on GitHub.\nPush back your own changes to the same remote\nrepository on GitHub.\n\nGit figures out how to intelligently merge this flow of changes, and\nGitHub helps you manage the flow through features such as “pull\nrequests.”\n\n\n\n\n\n\nNote\n\n\n\nWe will be sticking to GitHub’s tools for using Git, so you do not\nneed to install Git separately for this course. In the future, you may\nwant to spend some time understanding Git on its own, but for this\ncourse and most companies, understanding GitHub’s (below) workflows is\nmore important.\n\n\n\n4.1\nSetup GitHub\nFollow the guides in the order they are presented. Again, I recommend\nreading through the whole set of Get Started articles,\nbut these are the essentials for this course.\n\nCreating\nan account on GitHub\n\nUse your Mix account for the email. Your username doesn’t matter; I\nused Ozan Ozbeker - WVU. In this course, we will be using\nprivate repositories, but I recommend creating a personal account to add\nprojects for your resume. The final project of this class could be a\ngood start.\n\nHello\nWorld\n\nThis is the critical GitHub workflow, make sure you understand\nit.\n\nSetting\nup your profile\n\nThis will introduce you to using Markdown, which will be essential\nlater in this course and for formatting your READMEs.\n\n\n\n\n\n\n\n\nNote\n\n\n\nGitHub also provides hands-on exercises for many of their articles at\nGitHub Skills for free. I won’t\nrequire you to do any of these as I’m not sure how long they take, but\nthese ones may be of benefit: Introduction to\nGitHub, Communicate\nusing Markdown, Review pull\nrequests, & Resolve merge\nconflicts.\n\n\n\n\n4.2\nSetup GitHub Desktop\nGitHub Desktop is a free, open source application that helps you to\nwork with code hosted on GitHub or other Git hosting services. With\nGitHub Desktop, you can perform Git commands, such as committing and\npushing changes, in a graphical user interface, rather than using the\ncommand line.\nA typical workflow is:\n\nUse GitHub Desktop to download a GitHub repository to your computer\nand create a new branch.\nUse an editor such as Visual Studio Code to make changes to the\ncode.\nReturn to GitHub Desktop to commit and push the changes to\nGitHub.\n\nAgain, follow the guides in the order they are presented. Again x 2,\nI recommend reading through the whole set of Get\nStarted articles, but these are the essentials for this course.\n\nParts 1 & 2 of Getting\nstarted with GitHub Desktop\n\nThis guide, and all the following, will have specific steps for Mac\n& Windows.\n\nParts 2-5 of Creating\nyour first repository using GitHub Desktop\n\nThis will be similar to some parts of the GitHub (website) guides\nabove, that’s on purpose.",
    "crumbs": [
      "Learning Modules",
      "01 | Setting Up Your Workstation"
    ]
  },
  {
    "objectID": "learning-modules/01-setting-up-your-workstation.html#uv",
    "href": "learning-modules/01-setting-up-your-workstation.html#uv",
    "title": "01 | Setting Up Your Workstation",
    "section": "5 uv",
    "text": "5 uv\nSo far, we’ve only installed VS Code & GitHub Desktop, which are\ntools we need for this course, but they are not specific to Python. Now\nwe will focus on installing Python as well as a few other tools that\nwill make our coding lives easier.\nuv is an extremely fast\nPython package and project manager. It is how we will manage our project\ndependencies, including Python itself.\n\n\n\n\n\n\nNote\n\n\n\nFrom this point, all of the installation will be done via the command\nline.\n\n\n\n5.1\nInstallation\nYou can install uv using PowerShell on Windows:\n\n\nCLI\n\n$ powershell -ExecutionPolicy ByPass -c \"irm https://astral.sh/uv/install.ps1 | iex\"\n\nAnd curl on macOS:\n\n\nCLI\n\n$ curl -LsSf https://astral.sh/uv/install.sh | sh\n\n\n\n\n\n\n\nImportant\n\n\n\nAt this point, you need to restart your shell, which means close your\nterminal and open it again.\n\n\nNow, we check to see that uv is available by running the\nuv command:\n\n\nCLI\n\n$ uv --version\n\n\n\noutput\n\nuv 0.5.20 (1c17662b3 2025-01-15)\n\nWith that confirmation, we will now install Python to be used across\nthe system:\n\n\nCLI\n\n$ uv python install 3.12\n\nThen you can use uv python list to verify the\ninstallation went through:\n\n\nCLI\n\n$ uv python list\n\nYou will see list of the available versions of Python uv can download\nas well as where Python 3.12 was installed.\n\n\n5.2\nUsing uv\nTo fully appreciate the benefits of uv and why we are using it, it’s\nessential to understand Python environments, virtual environments, and\nhow uv simplifies these concepts through its Projects\ninterface.\nuv provides two ways to handle dependencies (a dependency is any\nextra package your project needs that doesn’t come with Python by\ndefault). The preferred approach is the uv project\ninterface, which includes commands like uv init,\nuv add, uv lock, and more. While uv also\nincludes an implementation of pip, we will not be using it\nin this course.\n\n\n\n\n\n\nTip\n\n\n\nUsing uv projects has fewer commands and guides you toward best\npractices, much like how GitHub Desktop simplifies workflows compared to\nthe full Git CLI tools.\n\n\nWhen we installed Python 3.12 earlier using\nuv python install 3.12, we were not in a project. As a\nresult, Python was installed into uv’s default environment. On most\nWindows systems, this environment is located at\nAppData/Roaming/uv/python/cpython-3.12.8-windows-x86_64-none/python.exe.\nHowever, you don’t need to worry about its location—uv manages it for\nyou.\nTo add dependencies to a project using uv, we use the command\nuv add [package]. Let’s try downloading Polars, a library we’ll use in the second\nhalf of this course:\n\n\nCLI\n\n$ uv add polars\n\n\n\noutput\n\nerror: No `pyproject.toml` found in current directory or any parent directory\n\nWe encountered an error! This happened because we’re not in a\nproject. This is one of the many guardrails uv provides when using its\nproject interface. If we had used uv pip install polars, we\ncould have installed the package into the default (global) environment.\nHowever, since this is considered bad practice, uv actively discourages\nit.\nInstead, uv projects leverage virtual\nenvironments using Python’s built-in venv module.\nEssentially, each project has its own dependencies without interfering\nwith others. This isolation prevents version conflicts and keeps your\nprojects organized.\nuv projects also provide a significant advantage: caching. When you\nuse the same dependency across multiple projects, uv only downloads it\nonce and stores it in a cache. For future projects, it reuses the cached\nfiles instead of downloading and installing them again. This drastically\nreduces disk space usage and installation time, especially when working\nwith large or repeated dependencies. For this course, where each Lab\n& Test will be its own uv project, this feature will save us\nconsiderable time.\nWe’ll get hands-on experience with uv projects in the the Lab, but\nyou can look at the official Working on\nprojects guide if you would like.",
    "crumbs": [
      "Learning Modules",
      "01 | Setting Up Your Workstation"
    ]
  },
  {
    "objectID": "learning-modules/01-setting-up-your-workstation.html#ruff",
    "href": "learning-modules/01-setting-up-your-workstation.html#ruff",
    "title": "01 | Setting Up Your Workstation",
    "section": "6\nRuff",
    "text": "6\nRuff\nMany Python packages provide applications that can be used as tools.\nuv has specialized support for easily invoking and installing tools. Ruff is an extremely fast Python\nlinter and code formatter, made by the creators of uv.\n\n6.1\nInstallation\nYou can install Ruff with:\n\n\nCommand Line\n\n$ uv tool install ruff\n\n\n\n6.2\nUsing Ruff\nRuff’s two main features are its linter and formatter.\nA linter analyzes your code for potential errors,\nbad practices, or violations of style rules. It can give warnings or\nerrors, but it won’t change your code automatically. It’s essentially a\nspellchecker for your code, pointing out what’s wrong without fixing\nit.\nA formatter automatically adjusts the layout and\nstyle of your code to match a predefined set of rules. It produces\nclean, consistently styled code by modifying it directly.\n\n\n6.3\nRuff’s linter\nruff check is the primary entrypoint to the Ruff linter.\nIt accepts a list of files or directories, and lints all discovered\nPython files, optionally fixing any fixable errors:\n\n\nCommand Line\n\nruff check # Lint all files in the current directory.\nruff check path/to/code/ # Lint all files in `path/to/code` (and any subdirectories).\n\nRuff supports automatic fixes for a variety of lint errors. For\nexample, Ruff can remove unused imports, reformat docstrings, rewrite\ntype annotations to use newer Python syntax, and more.\nTo enable fixes, pass the --fix flag to ruff check:\n\n\nCommand Line\n\nruff check --fix # Lint all files in the current directory, and fix any fixable errors.\n\nI don’t recommend using automatic fixes as it can help develop bad\nhabits in coding. Using the Ruff linter to find mistakes is good, but\nyou should work on not making the mistakes to begin with.\n\n\n6.4\nRuff’s formatter\nruff format is the primary entrypoint to the formatter.\nIt accepts a list of files or directories, and formats all discovered\nPython files:\n\n\nCommand Line\n\nruff format # Format all files in the current directory.\nruff format path/to/code/ # Format all files in `path/to/code` (and any subdirectories).\nruff format path/to/file.py # Format a single file.\n\nRun the linter first to identify and fix any errors, then use the\nformatter to clean up your code’s style. While you’re free to choose any\ncode style (as long as it’s syntactically valid), adhering to a standard\nmakes it easier to learn best practices and collaborate with others.\nFollowing a standard format also helps minimize unnecessary diffs in\nyour GitHub changes.",
    "crumbs": [
      "Learning Modules",
      "01 | Setting Up Your Workstation"
    ]
  },
  {
    "objectID": "learning-modules/01-setting-up-your-workstation.html#marimo",
    "href": "learning-modules/01-setting-up-your-workstation.html#marimo",
    "title": "01 | Setting Up Your Workstation",
    "section": "7\nmarimo",
    "text": "7\nmarimo\nThe final tool we’ll be installing is marimo. marimo is an open-source reactive notebook\nfor Python — reproducible, git-friendly, executable as a script, and\nshareable as an app.\n\n7.1\nInstallation\nYou can install marimo with:\n\n\nCommand Line\n\nuv tool install marimo\n\n\n\n7.2 Why\nmarimo (over VS Code)\nWe already installed VS Code, why am I making you install another\ntool to use Python with? I’m glad you asked.\nThe main difference between traditional Python programming in tools\nlike VS Code vs interactive notebooks like marimo (or Jupyter Notebook)\nis how you write and run your code. In VS Code, you typically write your\nentire script in a .py file and run the whole program at\nonce, with the output appearing in a terminal or console. This approach\nis great for building full applications, like downloading data,\nautomatically refreshing a dashboard, or scraping a website. On the\nother hand, interactive notebooks allow you to write and execute code in\nsmaller chunks, or cells, and see the results (including graphs or\ntables) immediately beside the code. This makes notebooks ideal for data\nanalysis, visualization, prototyping, and/or teaching, as they encourage\nexperimentation and provide instant feedback.\nWhile VS Code is better suited for maintaining well-organized,\nmodular code, notebooks excel in scenarios that involve step-by-step\nexploration and explanation. They serve different purposes, but are\ncomplementary.\n\n\n\n\n\n\nNote\n\n\n\nA typical workflow in industry is using notebooks to explore new\ndata, experiment with visuals, try models, and so on. Once the code is\nin a stable state, the code in the notebook will be turned into a Python\npackage or\nmodule to be used in production (software\nengineering loves to use manufacturing terms.).\n\n\n\n\n7.3 Why\nmarimo (over Jupyter Notebook)\nWe already covered why we may want to use a notebook instead of a\nregular IDE like VS Code, so why marimo over Jupyter?\nmarimo is the new kid on the block when it comes to comes to coding\nnotebooks. Jupyter has been the\nstandard for interactive computing for years now, and absolutely\ndeserves its flowers.\nFrom the marimo FAQ: marimo\nis a reinvention of the Python notebook as a reproducible, interactive,\nand shareable Python program that can be executed as scripts or deployed\nas interactive web apps.\n\nConsistent state: In marimo, your notebook code,\noutputs, and program state are guaranteed to be consistent. Run a cell\nand marimo reacts by automatically running the cells that reference its\nvariables. Delete a cell and marimo scrubs its variables from program\nmemory, eliminating hidden state.\nBuilt-in interactivity: marimo also comes with UI\nelements like sliders, a DataFrame transformer, and interactive plots\nthat are automatically synchronized with Python. Interact with an\nelement and the cells that use it are automatically re-run with its\nlatest value.\nPure Python programs: Unlike Jupyter notebooks,\nmarimo notebooks are stored as pure Python files that can be executed as\nscripts, deployed as interactive web apps, and versioned easily with\nGit.\n\n\n\n7.4\nLearning marimo\nFeel free to look at the User Guide, but we will be\ngoing through their interactive tutorials in a later Lab.\nYou can see some examples of marimo notebooks at their gallery.",
    "crumbs": [
      "Learning Modules",
      "01 | Setting Up Your Workstation"
    ]
  },
  {
    "objectID": "course-information/schedule.html",
    "href": "course-information/schedule.html",
    "title": "Schedule",
    "section": "",
    "text": "Course weeks with modules follow a consistent cycle:",
    "crumbs": [
      "Course Information",
      "Schedule"
    ]
  },
  {
    "objectID": "course-information/schedule.html#calendar",
    "href": "course-information/schedule.html#calendar",
    "title": "Schedule",
    "section": "Calendar",
    "text": "Calendar\nSchedule subject to change, changes will be announced in class\nand on eCampus.\n\nLabs: due on Wednesday at 11:59 PM of the following\nweek.\n\nExample - Week 3:\n\nTuesday (2025-02-04), we will go over the exercises from\nFlow Control and Functions.\nThursday (2025-02-06), you will work on Lab 3 in\nclass.\nWednesday (2025-02-12), Lab 3 is due.\n\n\nTests: due on Wednesday at 11:59 PM following the\nprep week.\n\nExample - Test 1:\n\nTuesday (2025-02-18): No new lecture material for this week, give\ntime to ask questions for test.\nThursday (2025-02-20): No new lecture material for this week, give\ntime to ask questions for test.\nWednesday (2025-02-26): Test is due at 11:59 PM.\nNote: New material will start on Tuesday, 2025-02-25, and I will not\nbe helping with tests outside of technical issues.\n\n\nFinal Project: due at 11:59 PM on Monday, April\n28th, 2025.\n\n\n\n\n\n\n\n\n\n\n\nWeek\nStart\nLearning Module(s)\nCourse Deliverable Due\n\n\n\n\n1\n2025-01-13\nCourse Intro\n\n\n\n2\n2025-01-20\n01 | Setting Up Your Workstation\n\n\n\n3\n2025-01-27\n02 | Intro to Python\nLab 01\n\n\n4\n2025-02-03\n03 | Flow Control and Functions\nLab 02\n\n\n5\n2025-02-10\n04 | Data Structures\nLab 03\n\n\n6\n2025-02-17\nTest 01 (Modules 02-04) Prep\nLab 04\n\n\n7\n2025-02-24\n05 | Intro to Data Science\nTest 01\n\n\n8\n2025-03-03\n06 | Data Visualization\n\n\n\n9\n2025-03-10\n07 | Data Transformation\nLab 05, Lab 06\n\n\n10\n2025-03-17\nTest 02 (Modules 05-07) Prep\nLab 07\n\n\n11\n2025-03-24\nSpring Recess\nRecess\n\n\n12\n2025-03-31\n08 | Data Communication\nTest 02\n\n\n13\n2025-04-07\n09 | SQL for Data Analysis\nLab 08\n\n\n14\n2025-04-14\n10 | Excel for Data Analysis\nLab 09\n\n\n15\n2025-04-21\nFinal Project Prep\nLab 10\n\n\n16\n2025-04-28\nPresentations\nFinal Project\n\n\n17\n2025-05-05\nFinals Week (No Final)",
    "crumbs": [
      "Course Information",
      "Schedule"
    ]
  },
  {
    "objectID": "course-information/policies.html",
    "href": "course-information/policies.html",
    "title": "Policies",
    "section": "",
    "text": "The integrity of the classes offered by any academic institution\nsolidifies the foundation of its mission and cannot be sacrificed to\nexpediency, ignorance, or blatant fraud. Therefore, instructors will\nenforce rigorous standards of academic integrity in all aspects and\nassignments of their courses. For the detailed policy of West Virginia\nUniversity regarding the definitions of acts considered to fall under\nacademic dishonesty and possible ensuing sanctions, please see the West\nVirginia University Academic\nStandards Policy. Should you have any questions about possibly\nimproper research citations or references, or any other activity that\nmay be interpreted as an attempt at academic dishonesty, please see your\ninstructor before the assignment is due to discuss the matter.\n\nIt is common to have questions about what amount of collaboration and\nreliance on tools is acceptable, simply put: In this course, you\nare expected to primarily turn in code you wrote.\nCode written by a peer, TA, stranger on the internet, or LLM\nis not code you wrote. While you may use code written\nby others within reason, you must give proper credit, and it will not be\nconsidered your own work for evaluation purposes.\n\n\n\n\n\n\nWarning\n\n\n\nPlease also see Artificial\nIntelligence (AI) for specifics of how this policy relates to\nthe use of AI tools in this course.\n\n\nWhile outside of the classroom programming is often a very\ncollaborative process, you should be working on coming up with your own\nsolutions to problems, to ensure you are learning what you came here to\nlearn. You may generally use outside resources, talk to peers, etc. so\nlong as the significant majority of your code is your own work and all\nsources are properly credited. Furthermore, if you use code from the\ninternet, you are expected to understand and adhere to the license of\nthat code. Failure to do so may result in a significant penalty to a\ngrade. Finally, if you have any questions regarding what would or would\nnot be considered academic dishonesty in this course, please don’t\nhesitate to ask me.",
    "crumbs": [
      "Course Information",
      "Policies"
    ]
  },
  {
    "objectID": "course-information/policies.html#academic-integrity",
    "href": "course-information/policies.html#academic-integrity",
    "title": "Policies",
    "section": "",
    "text": "The integrity of the classes offered by any academic institution\nsolidifies the foundation of its mission and cannot be sacrificed to\nexpediency, ignorance, or blatant fraud. Therefore, instructors will\nenforce rigorous standards of academic integrity in all aspects and\nassignments of their courses. For the detailed policy of West Virginia\nUniversity regarding the definitions of acts considered to fall under\nacademic dishonesty and possible ensuing sanctions, please see the West\nVirginia University Academic\nStandards Policy. Should you have any questions about possibly\nimproper research citations or references, or any other activity that\nmay be interpreted as an attempt at academic dishonesty, please see your\ninstructor before the assignment is due to discuss the matter.\n\nIt is common to have questions about what amount of collaboration and\nreliance on tools is acceptable, simply put: In this course, you\nare expected to primarily turn in code you wrote.\nCode written by a peer, TA, stranger on the internet, or LLM\nis not code you wrote. While you may use code written\nby others within reason, you must give proper credit, and it will not be\nconsidered your own work for evaluation purposes.\n\n\n\n\n\n\nWarning\n\n\n\nPlease also see Artificial\nIntelligence (AI) for specifics of how this policy relates to\nthe use of AI tools in this course.\n\n\nWhile outside of the classroom programming is often a very\ncollaborative process, you should be working on coming up with your own\nsolutions to problems, to ensure you are learning what you came here to\nlearn. You may generally use outside resources, talk to peers, etc. so\nlong as the significant majority of your code is your own work and all\nsources are properly credited. Furthermore, if you use code from the\ninternet, you are expected to understand and adhere to the license of\nthat code. Failure to do so may result in a significant penalty to a\ngrade. Finally, if you have any questions regarding what would or would\nnot be considered academic dishonesty in this course, please don’t\nhesitate to ask me.",
    "crumbs": [
      "Course Information",
      "Policies"
    ]
  },
  {
    "objectID": "course-information/policies.html#adverse-weather",
    "href": "course-information/policies.html#adverse-weather",
    "title": "Policies",
    "section": "Adverse Weather",
    "text": "Adverse Weather\nIn the event of inclement or threatening weather, everyone should use\nhis or her best judgment regarding travel to and from campus. Safety\nshould be the main concern. If you cannot get to class because of\nadverse weather conditions, you should contact your instructor as soon\nas possible. Similarly, if your instructor(s) are unable to reach the\nclass location, they will notify you of any cancellation or change as\nsoon as possible, using agreed upon methods to prevent students from\nembarking on any unnecessary travel. If you cannot get to class because\nof weather conditions, instructors will make allowances relative to\nrequired attendance policies, as well as any scheduled tests, quizzes,\nor other assessments. [adopted 9-8-2014]",
    "crumbs": [
      "Course Information",
      "Policies"
    ]
  },
  {
    "objectID": "course-information/policies.html#appropriate-use-of-technology",
    "href": "course-information/policies.html#appropriate-use-of-technology",
    "title": "Policies",
    "section": "Appropriate Use of Technology",
    "text": "Appropriate Use of Technology\nUse of technology in the classroom should always be directly related\nto class activities and/or course learning outcomes. Inappropriate\ntechnology use can be an impediment to learning and a distraction to all\nmembers of the class. As such, inappropriate use of technology in the\nclassroom may be considered a disruption of the class and constitute a\nviolation of the WVU\nStudent Conduct Code and could potentially result in a referral to\nthe Office of Student Rights and Responsibilities. Use of technology in\nthe classroom when specifically prohibited by the instructor may also\nconstitute a violation of WVU’s Academic\nIntegrity policy.",
    "crumbs": [
      "Course Information",
      "Policies"
    ]
  },
  {
    "objectID": "course-information/policies.html#artificial-intelligence",
    "href": "course-information/policies.html#artificial-intelligence",
    "title": "Policies",
    "section": "Artificial Intelligence",
    "text": "Artificial Intelligence\nArtificial intelligence (AI) tools that can create and develop\nacademic content are not allowed unless permission is given by an\ninstructor. Students must receive instructor permission prior to\nutilizing AI tools. Unauthorized use of AI tools may result in academic\ndishonesty charges.\nIn this course, we will be developing foundational skills and\nknowledge that are very important to discover and practice on your own.\nAt this stage of learning, it is far too easy to overuse these tools and\nnot gain the skills and understanding you came here for. Only as the\nproblems you aim to solve grow in complexity will the extent to which\nthe gaps in your understanding start to become a problem.\nAs a result, and to help avoid potential academic honesty issues\n— the use of AI tools, such as ChatGPT or CoPilot, to write code\nsubmitted for this course is not allowed.\nAs stated in the Academic\nIntegrity policy, the code you turn in should be your own\ncreation, not code that AI originated or in any way modified.\n\n\n\n\n\n\nImportant\n\n\n\nUsing AI tools to generate code for assignments in this course will\nviolate WVU’s\nAcademic Integrity policy.\n\n\nIn general, this means pasting your code into an AI tool or copying\nany code from it should be avoided.\n\nWhat you may do with AI tools:\n\nUse these tools to ask questions unrelated to the assignment. While\nI only have time in class to provide 1-2 examples on a topic, you may\nfind it useful to explore additional ones by asking AI for them. This\ntends to work quite well and avoids any academic honestly issues.\nAsk AI to explain an error message to you. Instead of pasting in\nyour code and saying “fix this”, instead pasting just the error message\nand asking the AI how to diagnose the problem. If in doubt, ask me\nbefore using any tools if you are unsure about this policy.",
    "crumbs": [
      "Course Information",
      "Policies"
    ]
  },
  {
    "objectID": "course-information/policies.html#attendance-participation",
    "href": "course-information/policies.html#attendance-participation",
    "title": "Policies",
    "section": "Attendance & Participation",
    "text": "Attendance & Participation\nAttendance is not required; however, in-class benefits\ninclude live guidance, interactive practice, and exercises reviewed only\nin class. Students who prefer or need additional help will find regular\nattendance invaluable.\nThe WVU Catalog contains the full Attendance\nPolicy.",
    "crumbs": [
      "Course Information",
      "Policies"
    ]
  },
  {
    "objectID": "course-information/policies.html#inclusivity-statement",
    "href": "course-information/policies.html#inclusivity-statement",
    "title": "Policies",
    "section": "Inclusivity Statement",
    "text": "Inclusivity Statement\nThe West Virginia University community is committed to creating and\nfostering a positive learning and working environment based on open\ncommunication, mutual respect, and inclusion.\nIf you are a person with a disability and anticipate needing any type\nof accommodation in order to participate in your classes, please advise\nyour instructors and make appropriate arrangements with the Office of Student Accommodations.\nMore information is available at the Division of Diversity, Equity, and\nInclusion website as well. [adopted 2-11-2013]",
    "crumbs": [
      "Course Information",
      "Policies"
    ]
  },
  {
    "objectID": "course-information/policies.html#incomplete-policy",
    "href": "course-information/policies.html#incomplete-policy",
    "title": "Policies",
    "section": "Incomplete Policy",
    "text": "Incomplete Policy\nThe WVU Catalog contains the full Incomplete\nPolicy.",
    "crumbs": [
      "Course Information",
      "Policies"
    ]
  },
  {
    "objectID": "course-information/policies.html#sale-of-course-material-statement",
    "href": "course-information/policies.html#sale-of-course-material-statement",
    "title": "Policies",
    "section": "Sale of Course Material Statement",
    "text": "Sale of Course Material Statement\nAll course materials, including lectures, class notes, quizzes,\nexams, handouts, presentations, and other course materials provided to\nstudents for their courses are protected intellectual property. As such,\nthe unauthorized purchase or sale of these materials may result in\ndisciplinary sanctions under the Student\nConduct Code. [adopted 5-11-2015]",
    "crumbs": [
      "Course Information",
      "Policies"
    ]
  },
  {
    "objectID": "course-information/policies.html#sexual-misconduct-statement",
    "href": "course-information/policies.html#sexual-misconduct-statement",
    "title": "Policies",
    "section": "Sexual Misconduct Statement",
    "text": "Sexual Misconduct Statement\nWest Virginia University does not tolerate sexual misconduct,\nincluding harassment, stalking, sexual assault, sexual exploitation, or\nrelationship violence: BOG\nRule 1.6. It is important for you to know that there are resources\navailable if you or someone you know needs assistance. You may speak to\na member of university administration, faculty, or staff; keep in mind\nthat they have an obligation to report the incident to the Title\nIX Coordinator.\nIf you want to speak to someone who is permitted to keep your\ndisclosure confidential, please seek assistance from the Carruth Center,\n304-293-9355 or 304-293-4431 (24-hour\nhotline), and locally within the community at the Rape and Domestic Violence Information\nCenter (RDVIC), 304-292-5100 or\n304-292-4431 (24-hour hotline).\nFor more information, please consult WVU’s Title IX\nOffice.",
    "crumbs": [
      "Course Information",
      "Policies"
    ]
  },
  {
    "objectID": "course-information/policies.html#student-evaluation-of-instruction-statement",
    "href": "course-information/policies.html#student-evaluation-of-instruction-statement",
    "title": "Policies",
    "section": "Student Evaluation of Instruction Statement",
    "text": "Student Evaluation of Instruction Statement\nEffective teaching is a primary mission of West Virginia University.\nStudent evaluation of instruction provides the university and the\ninstructor with feedback about your experiences in the course for review\nand course improvement. Your participation in the evaluation of course\ninstruction is both strongly encouraged and highly valued. Results are\nstrictly confidential, anonymous, and not available to the instructor\nuntil after final grades are released by Admissions and Records.\nInformation about how you can complete this evaluation will provided by\nyour instructor. [adopted 4-14-2008]",
    "crumbs": [
      "Course Information",
      "Policies"
    ]
  },
  {
    "objectID": "course-information/grading-and-deliverables.html",
    "href": "course-information/grading-and-deliverables.html",
    "title": "Grading & Deliverables",
    "section": "",
    "text": "If you are new to using specifications grading, here’s what you can\nexpect:\n\nFor each assignment you will be given a set of specifications.\nMeeting all/most of those will earn the highest grade. This is described\nin detail below, but aims to allow you to focus on learning and not on\nthe difference between an 89 and a 90 on an\nassignment. (It also more closely resembles how work is evaluated in\nmost workplaces.)\nWe will allow a limited amount of Resubmissions of Labs to learn from\nmistakes.\n\nLabs & Test Questions are assigned one of three marks:\n\nS (Satisfactory): Meets or exceeds all outlined\nspecifications (specs) in completeness, clarity/quality, and\nrelevance.\nN (Needs Improvement): Partially meets the specs\nbut has notable issues. Additional revision, clarity, or corrections\nneeded.\nU (Ungradable): Does not meet the basic specs;\nsignificantly incomplete or non-functional.\n\nThese will be assessed on:\n\nCompleteness\n\nTheory: Does the submission thoroughly address each\npart of the question(s)?\nCoding: Does the code accomplish\nall required tasks and functionalities?\n\nConceptual Clarity & Code Quality\n\nTheory: Are explanations accurate, logically\nstructured, and well-supported by examples or evidence?\nCoding:\n\nIs the code readable and well-styled (e.g., PEP 8)?\nAre chosen algorithms/data structures appropriate for the\nproblem?\nDoes the solution exhibit clear organization (functions, classes,\nmodules)?\n\n\n\nAn assignment’s specs will be provided with the instructions.\n\n\nThere will be a Lab for each Learning Module. Multiple Labs can be\ndue in a single week if multiple Learning Modules are covered.\nThe Labs will be a mix of Theory & Coding questions designed to\ngauge students’ understanding of topics discussed in the Learning\nModule(s).\nEach Lab will receive one S/N/U mark.\n\n\n\nThere will be two tests, aligned with major textbooks/readings:\n\nTest 1: “Think Python, 3E” (Allen Downey)\nTest 2: Modified “R for Data Science”\n(Hadley Wickham et al.)\n\nThe test format will be Take Home with a single\nsubmission by team.\nTests will consist of a mix of 4 problems:\n\nTheory problems which will be short answer and\nopen-ended.\nCoding problems which will comprise of analysis,\ncoding solutions, & interpretation of results.\n\nEach problem will receive its own S/N/U mark based\non completeness and clarity.\n\n\n\n\nComprehensive group project applying the full range\nof skills from the course.\nStudents choose a dataset and research question that interests them;\nanalyze and present findings.\nFinal Project must be completed to pass the course\nWill include a team presentation the final week of class + a written\nreport.\n\nProject Grade P will be used in the\nfinal letter grade matrix.",
    "crumbs": [
      "Course Information",
      "Grading & Deliverables"
    ]
  },
  {
    "objectID": "course-information/grading-and-deliverables.html#specifications-grading",
    "href": "course-information/grading-and-deliverables.html#specifications-grading",
    "title": "Grading & Deliverables",
    "section": "",
    "text": "If you are new to using specifications grading, here’s what you can\nexpect:\n\nFor each assignment you will be given a set of specifications.\nMeeting all/most of those will earn the highest grade. This is described\nin detail below, but aims to allow you to focus on learning and not on\nthe difference between an 89 and a 90 on an\nassignment. (It also more closely resembles how work is evaluated in\nmost workplaces.)\nWe will allow a limited amount of Resubmissions of Labs to learn from\nmistakes.\n\nLabs & Test Questions are assigned one of three marks:\n\nS (Satisfactory): Meets or exceeds all outlined\nspecifications (specs) in completeness, clarity/quality, and\nrelevance.\nN (Needs Improvement): Partially meets the specs\nbut has notable issues. Additional revision, clarity, or corrections\nneeded.\nU (Ungradable): Does not meet the basic specs;\nsignificantly incomplete or non-functional.\n\nThese will be assessed on:\n\nCompleteness\n\nTheory: Does the submission thoroughly address each\npart of the question(s)?\nCoding: Does the code accomplish\nall required tasks and functionalities?\n\nConceptual Clarity & Code Quality\n\nTheory: Are explanations accurate, logically\nstructured, and well-supported by examples or evidence?\nCoding:\n\nIs the code readable and well-styled (e.g., PEP 8)?\nAre chosen algorithms/data structures appropriate for the\nproblem?\nDoes the solution exhibit clear organization (functions, classes,\nmodules)?\n\n\n\nAn assignment’s specs will be provided with the instructions.\n\n\nThere will be a Lab for each Learning Module. Multiple Labs can be\ndue in a single week if multiple Learning Modules are covered.\nThe Labs will be a mix of Theory & Coding questions designed to\ngauge students’ understanding of topics discussed in the Learning\nModule(s).\nEach Lab will receive one S/N/U mark.\n\n\n\nThere will be two tests, aligned with major textbooks/readings:\n\nTest 1: “Think Python, 3E” (Allen Downey)\nTest 2: Modified “R for Data Science”\n(Hadley Wickham et al.)\n\nThe test format will be Take Home with a single\nsubmission by team.\nTests will consist of a mix of 4 problems:\n\nTheory problems which will be short answer and\nopen-ended.\nCoding problems which will comprise of analysis,\ncoding solutions, & interpretation of results.\n\nEach problem will receive its own S/N/U mark based\non completeness and clarity.\n\n\n\n\nComprehensive group project applying the full range\nof skills from the course.\nStudents choose a dataset and research question that interests them;\nanalyze and present findings.\nFinal Project must be completed to pass the course\nWill include a team presentation the final week of class + a written\nreport.\n\nProject Grade P will be used in the\nfinal letter grade matrix.",
    "crumbs": [
      "Course Information",
      "Grading & Deliverables"
    ]
  },
  {
    "objectID": "course-information/grading-and-deliverables.html#final-grade-calculation",
    "href": "course-information/grading-and-deliverables.html#final-grade-calculation",
    "title": "Grading & Deliverables",
    "section": "Final Grade Calculation",
    "text": "Final Grade Calculation\nYour final grade will be determined by your 18 SNU\ngrades (Labs: 10, Test 1: 4, Test 2: 4) and your final project\nscore:\n\nS: The total number of Satisfactory marks\nyou received.\nU: The maximum number of Ungradable marks\nyou received.\nP: Your exam grade, P, which will be\nbetween 0-100.\n\nBelow is the table for your Final Grade\ncalculation.\n\n\n\n\n\n\n\n\n\n\n\nS &gt;=\nU &lt;=\n50 &lt;= P &lt; 70\n70 &lt;= P &lt; 80\n80 &lt;= P &lt; 90\nP &gt;= 90\n\n\n\n\n16\n0\nB\nB\nA\nA\n\n\n14\n2\nB\nB\nB\nA\n\n\n12\n3\nC\nB\nB\nB\n\n\n10\n4\nC\nC\nB\nB\n\n\n9\n5\nC\nC\nC\nB\n\n\n8\n6\nD\nC\nC\nC\n\n\n\nExamples:\n\nIf you have 16 S, 2 N, 0\nU: then you are in the top row. An 80 on the final\nproject will earn you an A.\nIf you miss two labs and earn 2 U, but have at\nleast 14 S: you are in the second row. An 80 on the\nfinal project would earn you an B overall.\n\nAnything lower than what is represented in the chart will need to be\naddressed on a case-by-case basis.\n\n\n\n\n\n\nNote\n\n\n\nRemember: “C” is a passing grade for IENG courses.",
    "crumbs": [
      "Course Information",
      "Grading & Deliverables"
    ]
  },
  {
    "objectID": "course-information/grading-and-deliverables.html#midterm-grade-calculation",
    "href": "course-information/grading-and-deliverables.html#midterm-grade-calculation",
    "title": "Grading & Deliverables",
    "section": "Midterm Grade Calculation",
    "text": "Midterm Grade Calculation\nThe midterm grade uses a similar approach but only\nincludes:\n\nLabs 01 through 04 (one S/N/U mark per Lab).\nTest 01 (one S/N/U mark per Test Problem).\nThis table assumes a final project grade of P &gt;=\n90 for the sake of calculating a provisional grade. This\nassumption simply provides a midpoint reference for where students\nstand.\n\nBelow is the table for your Midterm Grade\ncalculation.\n\n\n\nS &gt;=\nU &lt;=\nMidterm\n\n\n\n\n6\n2\nA\n\n\n4\n4\nB\n\n\n2\n6\nC\n\n\n0\n8\nD",
    "crumbs": [
      "Course Information",
      "Grading & Deliverables"
    ]
  },
  {
    "objectID": "course-information/grading-and-deliverables.html#resubmissions",
    "href": "course-information/grading-and-deliverables.html#resubmissions",
    "title": "Grading & Deliverables",
    "section": "Resubmissions",
    "text": "Resubmissions\nI will allow 5 Lab revisions to change a\nNeeds Improvement mark to a\nSatisfactory mark.\nOnce a Lab is graded and returned to you, there will be a one\nweek window for you to resubmit that Lab. This means that, if\nyou produce work that needs some improvement, you will have a chance to\naddress the grader’s feedback to improve your score on that Lab.\nThere will be no revisions for Quizzes or Test Questions.\n\n\n\n\n\n\nNote\n\n\n\nResubmissions should be submitted via email to the instructor with\n“Lab # Resubmission” as the\n{Concise Question}.",
    "crumbs": [
      "Course Information",
      "Grading & Deliverables"
    ]
  },
  {
    "objectID": "course-information/grading-and-deliverables.html#late-submissions",
    "href": "course-information/grading-and-deliverables.html#late-submissions",
    "title": "Grading & Deliverables",
    "section": "Late Submissions",
    "text": "Late Submissions\nLate submissions will not be accepted in this class, except under\nextraordinary circumstances. Please bear in mind that the grading scheme\nwill be set up to absorb a reasonable amount of sub-par work, and also\nallows you to resubmit at most one programming homework (no tests or\nfinal project).\nThat said, to be clear: if you encounter some sort of\nemergency (medical, family, etc.) please reach out to your instructor as\nsoon as you are able to do so. I am more than happy to find\nways to provide additional flexibility in these situations. Ideally, you\nshould notify me of these circumstances before the work is due so we can\ndiscuss options with you.\nIn other words, the late submission policy applies to\nordinary circumstances: if you are having a busy week, you have\nan event that overlaps with a deadline, etc., then the grading scheme\nwill have some built-in flexibility for this. Instead of trying to argue\nfor a few extra days to work on a homework, you should just submit the\nwork you have completed by the deadline, so you can get feedback on that\nwork and use that feedback to improve your work in future assignments,\nor even to resubmit the homework as described above.",
    "crumbs": [
      "Course Information",
      "Grading & Deliverables"
    ]
  },
  {
    "objectID": "course-information/grading-and-deliverables.html#grading-disputes",
    "href": "course-information/grading-and-deliverables.html#grading-disputes",
    "title": "Grading & Deliverables",
    "section": "Grading Disputes",
    "text": "Grading Disputes\nExcept in very specific cases (described below), you cannot dispute\nthe score assigned to you on a piece of work. There is one exception to\nthis: if a grader made an factual mistake in your grading. Please note\nthat this only includes cases where a grader makes an erroneous\nstatement about your code in their feedback. It does not include cases\nwhere you simply disagree with whether something deserves to be flagged\nas incorrect.\nFor example, suppose you receive a piece of feedback that says\n“Incorrect: Function X did not check that parameter Y is greater than\nzero”. If function X in your code did perform this check, and the grader\nmissed this fact (and erroneously gave you that feedback), you can ask\nus to review this decision. Please note that, even if the feedback is\namended, it may not affect your actual SNU score.\nWe ask that you keep these requests brief and to the point: no more\nthan a few sentences identifying the exact statement that the grader\nmade and the reasons you believe the statement was mistaken, including\nreferences to specific parts of your code (e.g., “I did check the value\nof the parameter in line 107”). Focus on laying out the facts, and\nnothing else.\nFinally, it is also your responsibility to make these requests in a\ntimely manner. Requests to review grading mistakes must be submitted no\nlater than one week after a graded piece of work is\nreturned to you. After that time, we will not consider any such\nrequests, regardless of whether the request is reasonable and\njustified.\n\n\n\n\n\n\nNote\n\n\n\nDisputes should be submitted via email to the instructor with\n“Lab # | Test # Grading Dispute” as the\n{Concise Question}.",
    "crumbs": [
      "Course Information",
      "Grading & Deliverables"
    ]
  },
  {
    "objectID": "course-information/grading-and-deliverables.html#academic-integrity-violation",
    "href": "course-information/grading-and-deliverables.html#academic-integrity-violation",
    "title": "Grading & Deliverables",
    "section": "Academic Integrity Violation",
    "text": "Academic Integrity Violation\nThe minimum penalty for an Academic\nIntegrity violation is a U for all grades on\nthe assignment in question and a drop in a letter grade for each\nviolation.",
    "crumbs": [
      "Course Information",
      "Grading & Deliverables"
    ]
  },
  {
    "objectID": "course-information/grading-and-deliverables.html#curving",
    "href": "course-information/grading-and-deliverables.html#curving",
    "title": "Grading & Deliverables",
    "section": "Curving",
    "text": "Curving\nIn lieu of traditional curving, I reserve the right to lower the\nthresholds for each grade. I will not raise the thresholds. (So if you\nearn an B according to the above chart, you will get an B or\nbetter.)",
    "crumbs": [
      "Course Information",
      "Grading & Deliverables"
    ]
  },
  {
    "objectID": "course-information/resources.html",
    "href": "course-information/resources.html",
    "title": "Resources",
    "section": "",
    "text": "Office Hours are regular time that course staff sets aside for you to\nget help on concepts and assignments.\nYou can come by at an point during this period and we’ll do our best\nto answer your question. Please come with your laptop and questions\nprepared ahead of time as sometimes there will be a line and it’s\nimportant we make time for everyone.\n\n\n\nWho\nWhere\nWhen\n\n\n\n\nOzan Ozbeker\nESB 337\nTuesday/Thursday 12:30 PM - 1:45 PM\n\n\n\n\n\n\n\n\n\nInstructor Note\n\n\n\nIn addition to teaching, I work full-time in industry. As a result,\nmy availability for school-related matters will primarily be on Tuesdays\nand Thursdays. While I may occasionally check my email on other days,\nplease plan to contact me during these designated times for the most\ntimely responses.\nI can meet by appointment (schedule via email) on Tuesday/Thursday\nafter 4:00 PM, sparingly. Must show proof that you could not\nattend regular office hours.",
    "crumbs": [
      "Course Information",
      "Resources"
    ]
  },
  {
    "objectID": "course-information/resources.html#office-hours",
    "href": "course-information/resources.html#office-hours",
    "title": "Resources",
    "section": "",
    "text": "Office Hours are regular time that course staff sets aside for you to\nget help on concepts and assignments.\nYou can come by at an point during this period and we’ll do our best\nto answer your question. Please come with your laptop and questions\nprepared ahead of time as sometimes there will be a line and it’s\nimportant we make time for everyone.\n\n\n\nWho\nWhere\nWhen\n\n\n\n\nOzan Ozbeker\nESB 337\nTuesday/Thursday 12:30 PM - 1:45 PM\n\n\n\n\n\n\n\n\n\nInstructor Note\n\n\n\nIn addition to teaching, I work full-time in industry. As a result,\nmy availability for school-related matters will primarily be on Tuesdays\nand Thursdays. While I may occasionally check my email on other days,\nplease plan to contact me during these designated times for the most\ntimely responses.\nI can meet by appointment (schedule via email) on Tuesday/Thursday\nafter 4:00 PM, sparingly. Must show proof that you could not\nattend regular office hours.",
    "crumbs": [
      "Course Information",
      "Resources"
    ]
  },
  {
    "objectID": "course-information/resources.html#readings",
    "href": "course-information/resources.html#readings",
    "title": "Resources",
    "section": "Readings",
    "text": "Readings\nAll materials for the course are open-source and freely available\nonline. You do not need to purchase any literature or software to\nsucceed in this class.\nWhile there are no required textbooks for this course, the Learnings\nare adapted from the following books:\n\nThink Python,\n3E\nR for Data Science, 2E1\n\nWhile not directly referenced, these may aid in understanding course\nmaterial as well as in future endeavors:\n\nElements of\nData Science\nThink Stats,\n3E\nData Structures and\nInformation Retrieval in Python\nTidy\nData\nModeling and\nSimulation in Python\nAutomate The Boring\nStuff with Python\nBeyond the Basic\nStuff with Python\nThe Big Book\nof Small Python Projects",
    "crumbs": [
      "Course Information",
      "Resources"
    ]
  },
  {
    "objectID": "course-information/resources.html#software",
    "href": "course-information/resources.html#software",
    "title": "Resources",
    "section": "Software",
    "text": "Software\nRequired software, with references and documentation:\n\nVisual Studio\nCode\nGitHub Desktop\nuv\nRuff\nmarimo\n\nThese will be explained & installed in Lab\n1.",
    "crumbs": [
      "Course Information",
      "Resources"
    ]
  },
  {
    "objectID": "course-information/resources.html#ecampus-discussion-board",
    "href": "course-information/resources.html#ecampus-discussion-board",
    "title": "Resources",
    "section": "eCampus Discussion Board",
    "text": "eCampus Discussion Board\nThe discussion board is a forum that you may use to ask questions\nthat can be answered by course staff and you fellow students. Asking\ntechnical questions is an important skill and you’ll be asking your\ncolleagues and friends technical questions in your job. Best to get some\npractice now.\n\nSearch Before Asking\nBefore posting a question, check whether it has already been answered\nin a previous post. For example, suppose you are an\nIndexError; you could search just for that word to see if\nany other students have encountered that same error.\nMake sure to always check the “pinned” posts. We\nwill often “pin” a post about a particular assignment that might contain\nthe information you are looking for. Be sure to read these first.\n\n\nAsk A Question\nMake sure you’re going to ask an actual question.\nYou need to tell us about a specific issue you’re encountering, and why\nyou’re stuck on it (e.g., you are not getting the expected result, the\ntests are failing in a way you do not understand, etc.). Writing a post\nthat says “I can’t get Task 4 to work, I’ve pushed my code. Please look\nat it.” is not a question.\nIt may be helpful to write your question in the format of “I did {X},\nexpecting {Y}, but {Z} happened instead.” This can help us understand\nthe source of the error and reduce the time it takes to get you a high\nquality answer.\n\n\nPublic vs. Private\nAll questions about coursework, course logistics, etc. should be\nasked publicly (please note that you do have the option of asking the\nquestion anonymously if you prefer). If you ask such a question\nprivately, we will not answer it: we will ask you to ask it publicly,\nand will answer it once you do. This way, everyone can benefit from the\nanswer to the question and, if someone runs into the same issue you do,\nwe can refer them to the answer we provided in your post.\n\n\nThe more information, the better!\nSometimes people are brief to avoid wasting people’s time. With code,\nthe opposite is usually true — the more information you provide the more\neasily we can solve your problem.\nIn particular, it will be much easier for us to help you if we are\nable to reproduce the exact issue you are encountering (i.e., when we\nrun your code, we must be able to observe the exact same issue you’re\nencountering). And to do so, we need as much information as possible\nfrom you:\n\nIf your question relates to your code, make sure you push your code\nto GitHub before asking for help.\nInclude a detailed description of the exact chain of events that\nlead to the issue you’re encountering (Are you testing a specific\nfunction? If so, with what inputs? Etc.).\nIf you encounter an error message (or any other unexpected output)\nwhen running a command (like a Python program, Ruff, marimo, etc.) or\nwhen testing a piece of code in the interpreter, please make sure you\ninclude the full and unabridged error message (or unexpected output).\nSummarizing the message (e.g., “Python says something about a KeyError”)\nmakes it harder for us to figure out what the issue is.\nIf something is “wrong”, please describe in what way it seems wrong\nto you. For example, were you expecting a particular output but got a\ndifferent one? Is a piece of code behaving in a way you were not\nexpecting? Etc. It can be useful to tell us what you were expecting the\ncode to do, and what you encountered instead.\n\n\n\nNo Code or Screenshots\n\nNever post your code in the discussion board. As\nnoted in our Academic Integrity policies, you should never share your\ncode with other students (unless they are on your team), which means you\nshould never post it on the discussion board. If you need us to look at\nyour code, just push it to the GitHub and we will look at it there.\nPlease note that, if a test prints out a few lines of code as part of\nits output, that’s ok.\nNo screenshots or phone pictures. Do not post\nscreenshots of the output. Screenshots are not searchable, and may pose\nreadability issues for some people. Instructor/TAs may also want to\ncopy-paste that output somewhere else, which is not possible if you post\na screenshot.\n\nIf you need to share some output with us, copy-paste from the\nterminal and use the discussion board’s “code block” formatting. To copy\nsomething on the terminal, just select it (the same way you would do in\na word processor: click, and then drag until the end of the output) and\npress Control-Shift-C.\n\n\nOther Discussion Board Tips\n\nAvoid posts that have multiple unrelated questions:\nInstead, write a separate post for each question. Please note that it is\nok to ask multiple questions in one post if they all relate to the same\nissue.\nWhen to use follow-ups and when to post a new\nquestion: If you need to provide additional information (say,\nbecause we pointed you to this page), please use a follow-up in the same\nthread. If, on the other hand, you have an entirely new question, please\nwrite a new post for it. That way, if others have that same question, it\nwill be easier for them to find your post (and our answer to it),\ninstead of having to dig through the followup discussions of unrelated\nposts. Do not edit the original question: it is unlikely that we will\nnotice your change.\nFound the answer yourself?: If you solved your\nproblem before we got around to helping you, please note that the issue\nis resolved. If the solution is not specific to your implementation,\nplease add a brief explanation of how you solved the problem in case\nanyone else runs into the same issue.",
    "crumbs": [
      "Course Information",
      "Resources"
    ]
  },
  {
    "objectID": "course-information/resources.html#footnotes",
    "href": "course-information/resources.html#footnotes",
    "title": "Resources",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nWill be used for theory, but applications will be in\nPython.↩︎",
    "crumbs": [
      "Course Information",
      "Resources"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "IENG 331: Computer Applications in Industrial\nEngineering",
    "section": "",
    "text": "WVU Catalog: Introduction to computer\napplications in industrial engineering: emphasis on system design and\nanalysis and the role of computers in productivity improvement.\nPrerequisite Course(s): ENGR 102 - Engineering\nProblem Solving 2\nClass Meets: Tuesday/Thursday 11:00 AM - 12:15\nPM\nClass Location: Engineering Sciences Building (ESB)\n| Room G87B\nInstructor: Ozan Ozbeker (ozan.ozbeker@mail.wvu.edu)\nTeaching Assistants: None\n\n\n\n\n\n\nImportant\n\n\n\nAll emails related to the course must have the following subject\nformat:\n{Course} - {Term} - {WVU MIX ID} - {Concise Question}\nFor example:\nIENG 331 - Spring 2025 - oo0006 - Question about XYZ. You\ncan put more details in the email body."
  },
  {
    "objectID": "index.html#course-info",
    "href": "index.html#course-info",
    "title": "IENG 331: Computer Applications in Industrial\nEngineering",
    "section": "",
    "text": "WVU Catalog: Introduction to computer\napplications in industrial engineering: emphasis on system design and\nanalysis and the role of computers in productivity improvement.\nPrerequisite Course(s): ENGR 102 - Engineering\nProblem Solving 2\nClass Meets: Tuesday/Thursday 11:00 AM - 12:15\nPM\nClass Location: Engineering Sciences Building (ESB)\n| Room G87B\nInstructor: Ozan Ozbeker (ozan.ozbeker@mail.wvu.edu)\nTeaching Assistants: None\n\n\n\n\n\n\nImportant\n\n\n\nAll emails related to the course must have the following subject\nformat:\n{Course} - {Term} - {WVU MIX ID} - {Concise Question}\nFor example:\nIENG 331 - Spring 2025 - oo0006 - Question about XYZ. You\ncan put more details in the email body."
  },
  {
    "objectID": "index.html#course-description",
    "href": "index.html#course-description",
    "title": "IENG 331: Computer Applications in Industrial\nEngineering",
    "section": "Course Description",
    "text": "Course Description\nThis course introduces Industrial Engineering students to the\npractical application of Python, SQL, and Excel for data analysis,\nprocess automation, and visualization, emphasizing real-world relevance\nand hands-on learning. Through projects and assignments, students will\nacquire skills to automate workflows, analyze datasets, and create\neffective data-driven solutions. The curriculum is designed to align\nwith industry needs, fostering technical proficiency and communication\nskills for future engineering challenges​."
  },
  {
    "objectID": "index.html#learning-objectives",
    "href": "index.html#learning-objectives",
    "title": "IENG 331: Computer Applications in Industrial\nEngineering",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nUpon successful completion of this course, students will be able\nto:\n\nImplement Python Programming Skills: Master the\nfundamentals of computer programming using Python, with a focus on\nindustrial engineering applications.\nRecognize and Utilize Data Structures: Identify\ncommon data structures and their practical applications in solving\nengineering problems.\nAutomate Analytical Workflows: Develop, debug, and\nrefine programs to automate data processing and analytical\noperations.\nLeverage Data Libraries: Apply specialized Python\nlibraries for data cleaning, manipulation, visualization, and analysis,\nstreamlining complex workflows.\nIntegrate with Databases: Connect to, query,\ndesign, and manage external datasets using tools like SQL and relevant\nPython libraries.\nVisualize and Communicate Insights: Create\neffective data visualizations to communicate findings to technical and\nnon-technical audiences, aligning with industry expectations.\nCollaborate and Utilize Version Control: Utilize\nGit and GitHub for collaboration, version control, and portfolio\nbuilding, fostering professional software engineering practices.\nEngage with Real-World Data: Develop proficiency in\nhandling diverse, real-world datasets through hands-on projects,\npreparing for industry or academic pursuits.\n\nThese objectives are designed to align with ABET-defined Student\nOutcomes, fostering critical skills in problem-solving, communication,\nteamwork, and lifelong learning. Additionally, they emphasize practical\nrelevance, ensuring students are prepared for dynamic roles in\nindustrial engineering and beyond."
  },
  {
    "objectID": "learning-modules/02-intro-to-python.html",
    "href": "learning-modules/02-intro-to-python.html",
    "title": "02 | Intro to Python",
    "section": "",
    "text": "This module covers the Python basics you need for this course. It\nisn’t an exhaustive guide to Python, but it’s enough for anyone with\nprevious coding experience (see Prerequisite Course(s)).\nYou will learn how Python represents numbers, letters, and words,\nfollowed by arithmetic operations. We’ll also build important\nprogramming vocabulary. I won’t test you on these terms, but you’ll need\nthem for future lessons.\nNext, we’ll learn about variables, statements, the\nimport statement, and the print() function.\nWe’ll also discuss function arguments and Python modules.",
    "crumbs": [
      "Learning Modules",
      "02 | Intro to Python"
    ]
  },
  {
    "objectID": "learning-modules/02-intro-to-python.html#overview",
    "href": "learning-modules/02-intro-to-python.html#overview",
    "title": "02 | Intro to Python",
    "section": "",
    "text": "This module covers the Python basics you need for this course. It\nisn’t an exhaustive guide to Python, but it’s enough for anyone with\nprevious coding experience (see Prerequisite Course(s)).\nYou will learn how Python represents numbers, letters, and words,\nfollowed by arithmetic operations. We’ll also build important\nprogramming vocabulary. I won’t test you on these terms, but you’ll need\nthem for future lessons.\nNext, we’ll learn about variables, statements, the\nimport statement, and the print() function.\nWe’ll also discuss function arguments and Python modules.",
    "crumbs": [
      "Learning Modules",
      "02 | Intro to Python"
    ]
  },
  {
    "objectID": "learning-modules/02-intro-to-python.html#arithmetic-operators",
    "href": "learning-modules/02-intro-to-python.html#arithmetic-operators",
    "title": "02 | Intro to Python",
    "section": "2\nArithmetic operators",
    "text": "2\nArithmetic operators\nAn arithmetic operator is a symbol that represents a\ncomputation. For example:\n\n+ performs addition:\n\n\n2000 + 25\n\n2025\n\n\n\n- performs subtraction:\n\n\n2030 - 5\n\n2025\n\n\n\n* performs multiplication:\n\n\n405 * 25\n\n10125\n\n\n\n/ performs division:\n\n\n10125 / 5\n\n2025.0\n\n\nNotice that the result of division is 42.0 vs\n42. Python recognizes two numeric types:\n\nintegers: numbers without a decimal part\nfloating-point numbers (float): numbers with a\ndecimal point (including integer-like values stored in floating\nform)\n\nIf you add, subtract, or multiply two integers, the result remains an\ninteger. However, dividing two integers produces a floating-point\nresult.\nPython also supports integer division with the\noperator //, which always return an integer:\n\n4050 // 2\n\n2025\n\n\nThis operator is called “floor division” because it always rounds\ndown:\n\n4051 // 2\n\n2025\n\n\nThe modulus operator % returns the\nremainder after dividing two numbers:\n\n4051 % 2 # remainder is 1\n\n1\n\n\nIf a number divides evenly, % returns\n0:\n\n4050 % 2 # remainder is 0\n\n0\n\n\nFinally, ** performs exponentiation (raising a number to\na power):\n\n4.58442641 ** 5\n\n2025.0000056375889\n\n\n\n\n\n\n\n\nTip\n\n\n\nIn other languages, like R, you use the caret\n^ for exponentiation, but in Python ^ is the\n“XOR” operator, which we won’t cover here.",
    "crumbs": [
      "Learning Modules",
      "02 | Intro to Python"
    ]
  },
  {
    "objectID": "learning-modules/02-intro-to-python.html#expressions",
    "href": "learning-modules/02-intro-to-python.html#expressions",
    "title": "02 | Intro to Python",
    "section": "3\nExpressions",
    "text": "3\nExpressions\nAn expression is a combination of operators and\nvalues:\n\n6 + 6 ** 2\n\n42\n\n\nPython follows standard order of operations:\n\n12 + 5 *6\n\n42\n\n\nUse parentheses to change that order:\n\n(12 + 5) * 6\n\n102\n\n\nEvery expression evaluates to a value, so\n6 * 7 becomes 42.",
    "crumbs": [
      "Learning Modules",
      "02 | Intro to Python"
    ]
  },
  {
    "objectID": "learning-modules/02-intro-to-python.html#arithmetic-functions",
    "href": "learning-modules/02-intro-to-python.html#arithmetic-functions",
    "title": "02 | Intro to Python",
    "section": "4\nArithmetic functions",
    "text": "4\nArithmetic functions\nPython provides functions that work with numbers,\nsuch as:\n\nround() rounds a float to the nearest integer:\n\n\nround(4.58442641 ** 5)\n\n2025\n\n\n\nabs() returns the absolute value\n\n\nabs(-2025)\n\n2025\n\n\nWhen you call a function, you must use parentheses.\nOmitting them causes a syntax error:\n\nabs 42 # correct usage: abs(42)\n\n\n  Cell In[15], line 1\n    abs 42 # correct usage: abs(42)\n        ^\nSyntaxError: invalid syntax\n\n\n\n\nIf you type only the function name:\n\nabs\n\n&lt;function abs(x, /)&gt;\n\n\nPython tells you that abs is indeed a function, along\nwith some extra details.",
    "crumbs": [
      "Learning Modules",
      "02 | Intro to Python"
    ]
  },
  {
    "objectID": "learning-modules/02-intro-to-python.html#strings",
    "href": "learning-modules/02-intro-to-python.html#strings",
    "title": "02 | Intro to Python",
    "section": "5\nStrings",
    "text": "5\nStrings\nA string is a sequence of characters. You can\nenclose them in single or double quotes:\n\nprint('Hello')\nprint(\"World\")\n\nHello\nWorld\n\n\nUse double quotes if you need an apostrophe, or single quotes if you\nneed a double quote:\n\nprint(\"That's her book\")\nprint('\"I see,\" he said')\n\nThat's her book\n\"I see,\" he said\n\n\n\n\n\n\n\n\nTip\n\n\n\nPython treats single and double quotes the same; you can choose\neither as long as you’re consistent.\n\n\nTriple-quoted strings can span multiple lines or\ncontain both single and double quotes:\n\nprint('''\"That's great\", she said.''')\n\nprint(\"\"\"\nTo be,\nor not to be,\nthat is definitely a question.\n\"\"\")\n\n\"That's great\", she said.\n\nTo be,\nor not to be,\nthat is definitely a question.\n\n\n\nStrings can hold spaces, punctuation, and digits:\n\nprint(\"How the turn tables... uhh wait. What was line 5?\")\n\nHow the turn tables... uhh wait. What was line 5?\n\n\nUse the + operator to concatenate\n(join) strings:\n\nprint('Well, ' + \"it's a small \" + 'world.')\n\nWell, it's a small world.\n\n\nUse the * operator to repeat strings:\n\nprint('RA' + 'TA' * 3)\n\nRATATATA\n\n\nOther arithmetic operators don’t work on strings.\nYou can use len() to find a string’s length:\n\nlen('12345')\n\n5\n\n\n\n\n\n\n\n\nNote\n\n\n\nNotice that len() counts the the letters between the\nquotes, but not the quotes themselves.\n\n\nAvoid backticks ` or curly quotes “ ”\nbecause they cause syntax errors:\n\nprint(`hello`)\n\n\n  Cell In[24], line 1\n    print(`hello`)\n          ^\nSyntaxError: invalid syntax\n\n\n\n\n\nprint(“hello”)\n\n\n  Cell In[25], line 1\n    print(“hello”)\n          ^\nSyntaxError: invalid character '“' (U+201C)\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nMost code editors color valid strings differently, so keep an eye on\nsyntax highlighting to avoid mistakes.",
    "crumbs": [
      "Learning Modules",
      "02 | Intro to Python"
    ]
  },
  {
    "objectID": "learning-modules/02-intro-to-python.html#values-and-types",
    "href": "learning-modules/02-intro-to-python.html#values-and-types",
    "title": "02 | Intro to Python",
    "section": "6 Values\nand types",
    "text": "6 Values\nand types\nWe’ve encountered three kinds of values:\n\n2 (integer)\n42.0 (float)\n\"text\" (string)\n\nA kind of value is called a type. Every value has a\ntype, also referred to as “belongs to” a type.\nPython provides a function, type(), that tells you the\ntype of any value:\n\ntype(2)\n\nint\n\n\n\ntype(42.0)\n\nfloat\n\n\n\ntype(\"text\")\n\nstr\n\n\nint, float, and str can also\nconvert values:\n\nint(42.9) # rounds down to 42\n\n42\n\n\n\nfloat(42) # converts integer 42 to float 42.0\n\n42.0\n\n\n\nstr(123) # converts number 123 to the string \"123\"\n\n'123'\n\n\nIf you try arithmetic on a string, you get an error:\n\nprint(123 * 3)   # numeric multiplication\nprint(\"123\" * 3) # string repetition\n\n369\n123123123\n\n\n\nprint(\"500\" / 5) # TypeError: can't divide a string by an integer\n\n\n---------------------------------------------------------------------------\nTypeError                                 Traceback (most recent call last)\nCell In[33], line 1\n----&gt; 1 print(\"500\" / 5) # TypeError: can't divide a string by an integer\n\nTypeError: unsupported operand type(s) for /: 'str' and 'int'\n\n\n\nTo fix this, cast to the right type:\n\nint(\"126\") * 3\n\n378\n\n\nIf you have a large integer, you may type it like\n1,000,000. This is a legal expression in Python, but the\nvalue is not what you would expect:\n\n1,000,000\n\n(1, 0, 0)\n\n\nPython interprets 1,000,000 as a comma-separated\nsequence of integers. We’ll learn about this kind of sequence later.\nYou can use underscores to make large numbers easier to read:\n\n1_000_000\n\n1000000",
    "crumbs": [
      "Learning Modules",
      "02 | Intro to Python"
    ]
  },
  {
    "objectID": "learning-modules/02-intro-to-python.html#formal-and-natural-languages",
    "href": "learning-modules/02-intro-to-python.html#formal-and-natural-languages",
    "title": "02 | Intro to Python",
    "section": "7 Formal\nand natural languages",
    "text": "7 Formal\nand natural languages\nNatural languages (English, Spanish, etc.) evolved over time and rely\non context, idioms, and sometimes ambiguity. Formal languages like\nPython are precise and unambiguous. Python does exactly what you write,\nso details matter. Small mistakes in spelling or punctuation can cause\nbig errors. You might find this rigid at first, but you’ll adapt with\npractice.",
    "crumbs": [
      "Learning Modules",
      "02 | Intro to Python"
    ]
  },
  {
    "objectID": "learning-modules/02-intro-to-python.html#variables",
    "href": "learning-modules/02-intro-to-python.html#variables",
    "title": "02 | Intro to Python",
    "section": "8\nVariables",
    "text": "8\nVariables\nA variable is a name that refers to a value. Create\none with an assignment statement:\n\nn = 17\n\nThe assignment has three parts:\n\nThe variable name\nThe = operator\nAn expression (17 here)\n\n\npi = 3.141592653589793\nmessage = \"pie &gt; π\"\n\nOnce assigned, you can use these variables:\n\nprint(message)\nprint(n + 5)\nprint(2 * pi)\nprint(round(pi))\nprint(len(message))\n\npie &gt; π\n22\n6.283185307179586\n3\n7",
    "crumbs": [
      "Learning Modules",
      "02 | Intro to Python"
    ]
  },
  {
    "objectID": "learning-modules/02-intro-to-python.html#variable-names",
    "href": "learning-modules/02-intro-to-python.html#variable-names",
    "title": "02 | Intro to Python",
    "section": "9\nVariable names",
    "text": "9\nVariable names\nYou can use letters and digits in a variable name but cannot start\nwith a digit. Although uppercase letters are allowed, most Python code\nuses lowercase. Use underscores to connect words: your_name\nor airspeed_of_unladen_swallow.\nA name containing punctuation (million!) or starting\nwith a number (76trombones) triggers a syntax error. Some\nwords, like class, are keywords and cannot be variable\nnames.\n\nmillion! = 1000000\n\n\n  Cell In[40], line 1\n    million! = 1000000\n           ^\nSyntaxError: invalid syntax\n\n\n\n\n76trombones is illegal because it starts with a\nnumber.\n\n76trombones = 'big parade'\n\n\n  Cell In[41], line 1\n    76trombones = 'big parade'\n     ^\nSyntaxError: invalid decimal literal\n\n\n\n\nclass is also illegal, but it might not be obvious\nwhy.\n\nclass = 'Defense Against the Dark Arts'\n\n\n  Cell In[42], line 1\n    class = 'Defense Against the Dark Arts'\n          ^\nSyntaxError: invalid syntax\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nYour editor will often highlight keywords in a different color so you\ncan recognize them.",
    "crumbs": [
      "Learning Modules",
      "02 | Intro to Python"
    ]
  },
  {
    "objectID": "learning-modules/02-intro-to-python.html#the-import-statement",
    "href": "learning-modules/02-intro-to-python.html#the-import-statement",
    "title": "02 | Intro to Python",
    "section": "10 The\nimport statement",
    "text": "10 The\nimport statement\nSome features require importing. For example, to use\nthe math module:\n\nimport math\n\nA module is a collection of variables and functions.\nPython’s math\nmodule provides a variable called pi that contains the\nvalue of the mathematical constant π:\n\nmath.pi\n\n3.141592653589793\n\n\nUse the dot to access module features:\n\nprint(math.sqrt(25))\nprint(math.pow(5, 2)) # 5 ** 2 behaves the same as math.pow(5, 2)\n\n5.0\n25.0",
    "crumbs": [
      "Learning Modules",
      "02 | Intro to Python"
    ]
  },
  {
    "objectID": "learning-modules/02-intro-to-python.html#expressions-vs-statements",
    "href": "learning-modules/02-intro-to-python.html#expressions-vs-statements",
    "title": "02 | Intro to Python",
    "section": "11\nExpressions vs statements",
    "text": "11\nExpressions vs statements\nAn expression calculates a value, regardless of its\ncomplexity:\n\n19 + n + round(math.pi) * 2\n\n42\n\n\nA statement performs an action without producing a\nvalue you can use:\n\nn = 17\n\nWe evaluate expressions to get their value and\nexecute statements to perform actions.",
    "crumbs": [
      "Learning Modules",
      "02 | Intro to Python"
    ]
  },
  {
    "objectID": "learning-modules/02-intro-to-python.html#the-print-function",
    "href": "learning-modules/02-intro-to-python.html#the-print-function",
    "title": "02 | Intro to Python",
    "section": "12 The\nprint() function",
    "text": "12 The\nprint() function\nWhen you type an expression in many Python environments, it displays\nthe result. But if you have multiple expressions in a single cell (or\nscript), only the last one appears. Use print() to display\nmore than one item:\n\nprint(n + 2)\nprint(n + 3)\nprint(\"The value of pi is approximately\", math.pi)\n\n19\n20\nThe value of pi is approximately 3.141592653589793\n\n\n\n\n\n\n\n\nNote\n\n\n\nprint() separates arguments with a space by default.",
    "crumbs": [
      "Learning Modules",
      "02 | Intro to Python"
    ]
  },
  {
    "objectID": "learning-modules/02-intro-to-python.html#function-arguments",
    "href": "learning-modules/02-intro-to-python.html#function-arguments",
    "title": "02 | Intro to Python",
    "section": "13\nFunction Arguments",
    "text": "13\nFunction Arguments\nThe expressions inside a function call’s parentheses are\narguments. Different functions accept different numbers\nof arguments:\n\nint() can take one required argument and an optional\nbase:\n\n\nint(\"101\", 2)\n\n5\n\n\n\nmath.pow() takes two arguments:\n\n\nmath.pow(5, 2)\n\n25.0\n\n\n\nround() can take an optional second argument (decimals\nto round):\n\n\nround(math.pi, 3)\n\n3.142\n\n\n\nprint() accepts any number of arguments:\n\n\nprint(\"Any\", \"number\", \"of\", \"arguments\")\n\nAny number of arguments\n\n\nIf you supply too many or too few arguments, or if the arguments are\nthe wrong type, Python raises a TypeError:\n\nfloat(\"123\", 2)\n\n\n---------------------------------------------------------------------------\nTypeError                                 Traceback (most recent call last)\nCell In[53], line 1\n----&gt; 1 float(\"123\", 2)\n\nTypeError: float expected at most 1 argument, got 2\n\n\n\n\nmath.pow(2)\n\n\n---------------------------------------------------------------------------\nTypeError                                 Traceback (most recent call last)\nCell In[54], line 1\n----&gt; 1 math.pow(2)\n\nTypeError: pow expected 2 arguments, got 1\n\n\n\n\nmath.sqrt(\"25\")\n\n\n---------------------------------------------------------------------------\nTypeError                                 Traceback (most recent call last)\nCell In[55], line 1\n----&gt; 1 math.sqrt(\"25\")\n\nTypeError: must be real number, not str",
    "crumbs": [
      "Learning Modules",
      "02 | Intro to Python"
    ]
  },
  {
    "objectID": "learning-modules/02-intro-to-python.html#comments",
    "href": "learning-modules/02-intro-to-python.html#comments",
    "title": "02 | Intro to Python",
    "section": "14\nComments",
    "text": "14\nComments\nAs code grows, comments clarify your reasoning or\nrecord important details. Python ignores text after a\n#:\n\n# Variables\nforce = 500 # Force in Newtons (N)\narea = 0.01 # Cross-sectional area in square meters (m²)\n\n# Formula\nstress = force / area\n\n# Output\nprint(\"Stress:\", stress, \"in (Pa)\")\n\nStress: 50000.0 in (Pa)\n\n\nGood comments explain why you wrote the code in a\ncertain way (especially if it’s not obvious):\n\n# Use SI units for consistency throughout the program\narea = 0.01\n\nBad comments restate the obvious:\n\narea = 0.01  # set area to 0.01\n\nWell-chosen variable names can reduce the need for comments, but\navoid names so long that they make expressions unreadable.",
    "crumbs": [
      "Learning Modules",
      "02 | Intro to Python"
    ]
  },
  {
    "objectID": "learning-modules/02-intro-to-python.html#debugging",
    "href": "learning-modules/02-intro-to-python.html#debugging",
    "title": "02 | Intro to Python",
    "section": "15\nDebugging",
    "text": "15\nDebugging\nWe call mistakes in code bugs, and the process of finding and fixing\nthem debugging. You might feel frustrated when things break, but\nremember it’s normal and part of learning.\nThink of the computer as precise but inflexible. You must provide\nexact instructions because it doesn’t infer or guess what you mean.\n\n15.1\nCommon Errors\n\nSyntax erros: The code violates Python’s structure\nrules. Python refuses to run the code and points out where it got\nstuck:\n\n\nmillion! = 1000000\n\n\n  Cell In[59], line 1\n    million! = 1000000\n           ^\nSyntaxError: invalid syntax\n\n\n\n\n\nRuntime errors: The code starts running but fails\nduring execution, like dividing a string by an integer:\n\n\n\"126\" / 3\n\n\n---------------------------------------------------------------------------\nTypeError                                 Traceback (most recent call last)\nCell In[60], line 1\n----&gt; 1 \"126\" / 3\n\nTypeError: unsupported operand type(s) for /: 'str' and 'int'\n\n\n\n\nSemantic errors: The code runs but does something\nunintended. For example, mixing up units might produce the wrong numeric\nresult without an obvious error:\n\n\n# This uses area in cm² instead of m²\nforce = 500       # Newtons\narea = 10         # cm² (wrong units)\nstress = force / area\nprint(stress)     # No error, but incorrect value =&gt; semantic error\n\n50.0",
    "crumbs": [
      "Learning Modules",
      "02 | Intro to Python"
    ]
  },
  {
    "objectID": "learning-modules/02-intro-to-python.html#exercises",
    "href": "learning-modules/02-intro-to-python.html#exercises",
    "title": "02 | Intro to Python",
    "section": "16\nExercises",
    "text": "16\nExercises\n\n16.1\nRounding Behavior\nExperiment with round() when a number ends in\n0.5. It sometimes rounds up and sometimes down. Figure out\nthe pattern:\n\nround(42.5)\n\n42\n\n\n\nround(43.5)\n\n44\n\n\n\n\n16.2\nDeliberate Mistakes\n\nWhat happens if you use a + sign before a number\n(+2) or repeat it (2++2)? What about\n2--2?\nWhat if you write two values without an operator\n(4 2)?\nWhat if you call round(42.5) but remove one or both\nparentheses?\n\n\n\n16.3\nType Checking\nGuess each expression’s type and then use type() to\ncheck:\n\n765\n2.718\n\"2 pi\"\nabs(-7)\nabs\nint\ntype\n\n\n\n16.4\nMore Arithmetic\n\nHow many seconds are there in 42 minutes 42 seconds?\nHow many miles are there in 10 kilometers\n(1.61 kilometers/mile)?\nIf you run a 10 kilometer race in 42 minutes 42 seconds, what is\nyour average pace in seconds per mile?\n\n\n\n16.5\nIntentional Errors\n\nWe’ve seen n = 17 is legal, what about\n17 = n?\nWhat about x = y = 1?\nIn some languages every statement ends with a semi-colon\n(;). What happens if you put a semi-colon at the end of a\nPython statement?\nWhat if you put a period at the end of a statement?\nWhat happens if you spell the name of a module wrong and try to\nimport maath?\n\n\n\n16.6\nVolume of a Sphere\nThe formula for the volume of a sphere with radius \\(r\\) is \\(\\frac{4}{3} \\pi r^3\\). Compute it for \\(r = 5\\).\n\nStart with a variable names radius (in\ncentimeters)\nCompute volume (in cubic centimeters)\nPrint the result and include comments\n\n\n\n16.7\nTrigonometry\nAccording to a trig identity, \\((\\cos x)^2\n+ (\\sin x)^2 = 1\\). Test this for x = 42.\n\nCreate a variable named x to 42\nUse math.cos() and math.sin() to\ncompute\n\n\n\n\n\n\n\nNote\n\n\n\nIt might not be exactly 1 because of floating-point imprecision.\n\n\n\n\n16.8\nExploring \\(e\\)\nThe math module defines e. Compute \\(e^2\\) in three ways:\n\nUse math.e and the exponentiation operator.\nUse math.pow to raise math.e to the power\n2.\nUse math.exp, which takes as an argument a value, \\(x\\), and computes \\(e^x\\).\n\nCompare the results and see which appears most accurate.",
    "crumbs": [
      "Learning Modules",
      "02 | Intro to Python"
    ]
  },
  {
    "objectID": "learning-modules/04-data-structures.html",
    "href": "learning-modules/04-data-structures.html",
    "title": "04 | Strings, Lists, Dictionaries, and Tuples",
    "section": "",
    "text": "In this module, you will learn about Python’s most commonly used\ndata structures: strings,\nlists, dictionaries, and\ntuples. You will also explore how to leverage\nregular expressions to search for patterns in text.\nFinally, you will see examples that combine these structures to solve\nmore advanced tasks, followed by tips for debugging and practice\nexercises.\nWhy are these data structures important?\n\nStrings handle textual data, which is central to\nuser input, file processing, and general communication in software.\nLists store ordered collections, perfect for\ndynamic or changing sets of elements.\nDictionaries map from keys to\nvalues for fast lookups and flexible data storage.\nTuples group multiple items into a single,\nimmutable structure (and can serve as dictionary keys).\nRegular expressions simplify complex text matching\nand replacement tasks.",
    "crumbs": [
      "Learning Modules",
      "04 | Strings, Lists, Dictionaries, and Tuples"
    ]
  },
  {
    "objectID": "learning-modules/04-data-structures.html#overview",
    "href": "learning-modules/04-data-structures.html#overview",
    "title": "04 | Strings, Lists, Dictionaries, and Tuples",
    "section": "",
    "text": "In this module, you will learn about Python’s most commonly used\ndata structures: strings,\nlists, dictionaries, and\ntuples. You will also explore how to leverage\nregular expressions to search for patterns in text.\nFinally, you will see examples that combine these structures to solve\nmore advanced tasks, followed by tips for debugging and practice\nexercises.\nWhy are these data structures important?\n\nStrings handle textual data, which is central to\nuser input, file processing, and general communication in software.\nLists store ordered collections, perfect for\ndynamic or changing sets of elements.\nDictionaries map from keys to\nvalues for fast lookups and flexible data storage.\nTuples group multiple items into a single,\nimmutable structure (and can serve as dictionary keys).\nRegular expressions simplify complex text matching\nand replacement tasks.",
    "crumbs": [
      "Learning Modules",
      "04 | Strings, Lists, Dictionaries, and Tuples"
    ]
  },
  {
    "objectID": "learning-modules/04-data-structures.html#strings",
    "href": "learning-modules/04-data-structures.html#strings",
    "title": "04 | Strings, Lists, Dictionaries, and Tuples",
    "section": "2\nStrings",
    "text": "2\nStrings\nStrings store text and are immutable sequences of\ncharacters. In Python, they form the foundation of almost all\nuser-facing output and file processing.\n\n2.1 A\nstring is a sequence\nA string is a sequence of characters in a specific\norder. A character can be a letter, digit, punctuation mark, or\nwhitespace. You can select any character in a string using the bracket\noperator:\n\nfruit = \"banana\"\nletter = fruit[1]\nletter\n\n'a'\n\n\nThe index in brackets starts at 0, so\nfruit[0] is the first character ('b'),\nfruit[1] is the second character ('a'), and so\non.\n\nfruit[0]\n\n'b'\n\n\nYou can use variables or expressions as indices:\n\ni = 1\nfruit[i+1]  # fruit[2]\n\n'n'\n\n\nIf you use a non-integer index, you get a TypeError. You\ncan use len() to determine a string’s length:\n\nn = len(fruit)  # 6 for \"banana\"\n\nBecause indices start at 0, the last character is at\nposition len(fruit) - 1, which is fruit[n-1].\nAlternatively, negative indices let you count backward:\n\nprint(fruit[-1])  # last character\nprint(fruit[-2])  # second to last\n\na\nn\n\n\nYou can quickly access any position in the string without manual\nloops.\n\n\n2.2\nString slices\nA slice selects a substring by indicating a range of\nindices with [start:end]. It includes the\nstart index but excludes the end.\n\nfruit = 'banana'\nprint(fruit[0:3])  # 'ban'\nprint(fruit[3:6])  # 'ana'\n\nban\nana\n\n\nOmitting start means “from the beginning”, and omitting\nend means “to the end”:\n\nprint(fruit[:3])   # 'ban'\nprint(fruit[3:])   # 'ana'\n\nban\nana\n\n\nIf the first index is greater than or equal to the second, you get an\nempty string. For example, fruit[3:3] returns\n''.\nUse slices to easily extract segments of text, such as prefixes,\nsuffixes, or partial filenames.\n\n\n2.3\nStrings are immutable\nStrings are immutable, so you cannot modify them in\nplace. An assignment like greeting[0] = 'J' causes a\nTypeError. Instead, create a new string:\n\ngreeting = 'Hello, world!'\nnew_greeting = 'J' + greeting[1:]\n\nThis prevents accidental data corruption, making string handling more\npredictable.\n\n\n2.4\nString comparison\nYou can compare strings using relational\noperators:\n\nword = 'banana'\n\nif word == 'banana':\n    print('All right, banana.')\n\nAll right, banana.\n\n\nOther operators let you determine alphabetical ordering:\n\ndef compare_word(word):\n    if word &lt; 'banana':\n        print(word, 'comes before banana.')\n    elif word &gt; 'banana':\n        print(word, 'comes after banana.')\n    else:\n        print('All right, banana.')\n\ncompare_word(\"apple\")\ncompare_word(\"Orange\")\n\napple comes before banana.\nOrange comes before banana.\n\n\nUppercase letters come before lowercase letters in Python’s default\nsort order, so be mindful of case differences. You can convert strings\nto lowercase or uppercase for case-insensitive comparisons.\n\n\n2.5\nString methods\nA method is like a function but follows the\nobject-dot-method syntax. For example:\n\ntext = \"Hello World\"\nprint(text.lower())\nprint(text.upper())\nprint(text.replace(\"Hello\", \"Hi\"))\nprint(text.split())\n\nhello world\nHELLO WORLD\nHi World\n['Hello', 'World']\n\n\nThese help easily perform text transformations for data cleaning or\nuser-facing output.\n\n\n2.6\nRegular expressions\nRegular expressions (regex) help you search for\ncomplex patterns in text. Python’s built-in re module\nprovides powerful tools for matching and manipulating text.\nFor example, you can verify formats (phone numbers, emails), capture\nspecific bits of text, or do advanced replacements.\n\n2.6.1\nA simple search example\n\nimport re\n\ntext = \"Hello, my name is Jane. It's nice to meet you.\"\npattern = 'Jane'\n\nresult = re.search(pattern, text)\nif result:\n    print(\"Found:\", result.group())\nelse:\n    print(\"Not found.\")\n\nFound: Jane\n\n\n\nIf the pattern is found, re.search returns a\nMatch object with .group(),\n.span(), etc.\nIf not found, it returns None.\n\nThis allows very fast pattern matching in large strings, flexible for\npartial matches (e.g., ’Jan[eE]*’ to allow slight variations).\n\n\n2.6.2\nUsing raw strings\nWhen writing regex, prefix patterns with r to create raw\nstrings, which interpret backslashes literally:\n\nnormal_str = \"Hello\\nWorld\"  # \\n is a newline\nraw_str = r\"Hello\\nWorld\"    # keeps the literal \\n\n\nprint(normal_str)\nprint(raw_str)\n\nHello\nWorld\nHello\\nWorld\n\n\nPrefix strings with r to avoid having to escape\nbackslashes, e.g. r\"\\d+\" instead of\n\"\\\\d+\".\n\n\n2.6.3\nSearching in a file\nFor the following examples, we will use this file:\n\nfor line in open('data/sample_text.txt'):\n    print(line)\n\nHello, world!\n\nAlice smiled as she greeted Bob with a cheerful hello.\n\nIn the quiet morning, Bob whispered hello to the sleeping world.\n\nAlice and Bob wandered through a world that seemed to echo with hello.\n\nA simple hello from Alice brightened Bobâ€™s day in an ordinary world.\n\nBob called out, \"Hello, Alice!\" as they explored the world together.\n\nIn a magical world, hello was the key that united Alice and Bob.\n\nAlice thought, \"Hello to a new day in this ever-changing world,\" as Bob nodded.\n\nWith a friendly hello, Bob opened the door to Aliceâ€™s mysterious world.\n\nThe world felt lighter when Alice and Bob exchanged a heartfelt hello.\n\nBob wrote in his journal: \"Today, Alice said hello to the whole world.\"\n\nAmid the busy city, a quiet hello from Alice and Bob brought calm to the world.\n\nIn the realm of dreams, Alice and Bob discovered that every hello sparked wonder in the world.\n\nA warm hello from Bob melted the chill of the early world, as Alice looked on.\n\nAlice and Bob laughed together, their hello echoing through the vibrant world.\n\nWhile strolling through the park, Bobâ€™s spontaneous hello made the world seem friendlier to Alice.\n\nIn a story of friendship, every hello by Alice and every nod from Bob transformed their little world.\n\nThe world listened as Bob said hello, while Alice beamed in response.\n\nUnder the starlight, Alice and Bob shared a soft hello that warmed their world.\n\nA final hello from Alice to Bob closed a day where the world felt wonderfully alive.\n\n\n\nYou might loop over each line in a file and call\nre.search:\n\ndef find_first(pattern, filename='data/sample_text.txt'):\n    import re\n    for line in open(filename):\n        result = re.search(pattern, line)\n        if result is not None:\n            return result\n\nfind_first(\"Hello\")\n\n&lt;re.Match object; span=(0, 5), match='Hello'&gt;\n\n\n\n\n2.6.4\nUsing the “OR” operator (|)\nUse the | symbol for logical OR within a regex. For example, to find\neither “Alice” or “Bob”:\n\npattern = 'Alice|Bob'\nresult = find_first(pattern)\nprint(result)\n\n&lt;re.Match object; span=(0, 5), match='Alice'&gt;\n\n\nYou can also loop through lines, counting matches. For instance:\n\ndef count_matches(pattern, filename='data/sample_text.txt'):\n    import re\n    count = 0\n    for line in open(filename):\n        if re.search(pattern, line) is not None:\n            count += 1\n    return count\n\nmentions = count_matches('Alice|Bob')\nprint(mentions)\n\n19\n\n\n\n\n2.6.5\nMatching start/end of lines\n\n^: start of a line\n$: end of a line\n\n\nfind_first('^Hello')\n\n&lt;re.Match object; span=(0, 5), match='Hello'&gt;\n\n\n\nfind_first('world!$')\n\n&lt;re.Match object; span=(7, 13), match='world!'&gt;\n\n\n\n\n2.6.6\nMore on regex syntax\nRegex includes special metacharacters and quantifiers:\n\n. matches any character (except newline).\n* matches 0 or more of the preceding element.\n+ matches 1 or more of the preceding element.\n? makes the preceding element optional (0 or 1).\n[...] matches any one character in the brackets.\n(...) captures the matched text as a group.\n\\ escapes special characters or denotes special\nsequences like , etc.\n\n\n\n2.6.7\nString substitution\nUse re.sub(pattern, replacement, text) to substitute\nmatches:\n\ntext_line = \"This is the centre of the city.\"\npattern = r'cent(er|re)'\nupdated_line = re.sub(pattern, 'center', text_line)\nprint(updated_line)\n\nThis is the center of the city.\n\n\nThis allows you to clean up strings in powerful ways, such as\nnormalizing different spellings or removing special characters.\nUse re.findall to get all matches, re.split\nto split a string by a regex, and various flags (e.g.,\nre.IGNORECASE) to alter matching behavior.\nRegex is extremely powerful for tasks like extracting email\naddresses, validating formats, or searching logs.",
    "crumbs": [
      "Learning Modules",
      "04 | Strings, Lists, Dictionaries, and Tuples"
    ]
  },
  {
    "objectID": "learning-modules/04-data-structures.html#lists",
    "href": "learning-modules/04-data-structures.html#lists",
    "title": "04 | Strings, Lists, Dictionaries, and Tuples",
    "section": "3\nLists",
    "text": "3\nLists\nLists are mutable sequences that can store elements\nof any type (including other lists). They form the workhorse for many\ndata-processing tasks due to their flexibility.\n\n3.1 A\nlist is a sequence\nA list is a sequence of values (of any type). Create\none with square brackets:\n\nnumbers = [42, 123]\ncheeses = ['Cheddar', 'Edam', 'Gouda']\nmixed = ['spam', 2.0, 5, [10, 20]]  # nested list\nempty = []\n\nlen(cheeses) returns the length of a list. The length of\nan empty list is 0.\n\n\n3.2\nLists are mutable\nUse the bracket operator to read or write an element:\n\nnumbers[1] = 17  # modifies the list\nprint(numbers)\n\n[42, 17]\n\n\nUnlike strings, lists allow you to assign directly to their indices.\nYou can still use negative indices to count backward.\nUse the in operator to check membership:\n\n'Edam' in cheeses\n\nTrue\n\n\n\n\n3.3\nList slices\nLists support slicing with the same [start:end] syntax\nas strings:\n\nletters = ['a', 'b', 'c', 'd']\n\n\nletters[1:3]\n\n['b', 'c']\n\n\n\nletters[:2]\n\n['a', 'b']\n\n\n\nletters[2:]\n\n['c', 'd']\n\n\n\nletters[:] # copy of the list\n\n['a', 'b', 'c', 'd']\n\n\n\n\n3.4\nList operations\n+ concatenates, * repeats:\n\n[1, 2] + [3, 4] \n\n[1, 2, 3, 4]\n\n\n\n['spam'] * 4\n\n['spam', 'spam', 'spam', 'spam']\n\n\n\nsum([1, 2, 3])\n\n6\n\n\n\nmin([3, 1, 4])\n\n1\n\n\n\nmax([3, 1, 4])\n\n4\n\n\n\n\n3.5\nList methods\n\nappend(x) adds an item at the end.\nextend([x, y]) adds multiple items.\npop(index) removes and returns the item at\nindex.\nremove(x) removes the first occurrence of\nx.\n\n\nletters = ['a', 'b', 'c']\n\n\nletters.append('d')      # modifies letters\nprint(letters)\n\n['a', 'b', 'c', 'd']\n\n\n\nletters.extend(['e', 'f'])\nprint(letters)\n\n['a', 'b', 'c', 'd', 'e', 'f']\n\n\n\nletters.pop(1)           # removes 'b'\nprint(letters)\n\n['a', 'c', 'd', 'e', 'f']\n\n\n\nletters.remove('e')      # removes 'e'\nprint(letters)\n\n['a', 'c', 'd', 'f']\n\n\nThese list methods help manage growing or shrinking lists without\nextra variables.\n\nList methods often modify a list in place and return\nNone. This can confuse people who expect them to behave\nlike string methods. For instance:\n\nt = [1, 2, 3]\nt = t.remove(3)  # WRONG!\n\nprint(t)\n# Expect: [1, 2]\n# Return: None\n\nNone\n\n\nremove(3) modifies t and returns\nNone, so assigning it back to t loses the\noriginal list. If you see an error like\nNoneType object has no attribute 'remove', check whether\nyou accidentally assigned a list method’s return value to the list.\nFor the example above, you would do this:\n\nt = [1, 2, 3]\nt.remove(3)  # CORRECT!\n\nprint(t)\n\n[1, 2]\n\n\n\n\n3.6\nLists and strings\na list of characters is not the same as a\nstring. To convert a string to a list of characters,\nuse list():\n\ns = 'coal'\nt = list(s)\nprint(t)\n\n['c', 'o', 'a', 'l']\n\n\nTo split a string by whitespace into a list of words:\n\ns = \"The children yearn for the mines\"\nwords = s.split()\nprint(words)\n\n['The', 'children', 'yearn', 'for', 'the', 'mines']\n\n\nYou can specify a delimiter for split, and you can use\n''.join(list_of_strings) to rebuild a single string from a\nlist. These are useful for text tokenization, splitting logs, or\nreconstructing messages.\n\n\n3.7\nLooping through a list\na for loop iterates over each element:\n\nfor cheese in cheeses:\n    print(cheese)\n\nCheddar\nEdam\nGouda\n\n\n\n\n3.8\nSorting lists\nUse sorted() to return a new sorted list without\nmodifying the original:\n\nscrambled_list = [\"c\", \"a\", \"b\"]\nsorted_list = sorted(scrambled_list)\n\nprint(sorted_list)\nprint(scrambled_list)\n\n['a', 'b', 'c']\n['c', 'a', 'b']\n\n\nsorted('letters') returns a list of characters. Combine\nwith \"\".join() to build a sorted string:\n\n\"\".join(sorted('letters'))\n\n'eelrstt'\n\n\n\n\n3.9\nObjects and values\nVariables can refer to the same object or different\nobjects that have the same value. For example:\n\na = 'banana'\nb = 'banana'\na is b  # often True (same object)\n\nTrue\n\n\nIn this example, Python only created one string object, and both\na and b refer to it. But when you create two\nlists, you get two objects.\n\nx = [1, 2, 3]\ny = [1, 2, 3]\nx is y  # False (different objects)\n\nFalse\n\n\nIn this case we would say that the two lists are\nequivalent, because they have the same elements, but\nnot identical, because they are not the same object. If\ntwo objects are identical, they are also equivalent, but if they are\nequivalent, they are not necessarily identical.\n\n\n3.10\nAliasing\nWhen you assign one variable to another, both variables\nreference the same object:\n\na = [1, 2, 3]\nb = a\nb is a\n\nTrue\n\n\nIf an object is mutable, changes made via one variable affect the\nother:\n\nprint(a)\nb[0] = 5\nprint(a)\n\n[1, 2, 3]\n[5, 2, 3]\n\n\nAvoid aliasing unless it’s intentional.\n\n\n3.11\nList arguments\nWhen you pass a list to a function, you pass a reference to that\nlist. The function can modify the original list:\n\ndef pop_first(lst):\n    return lst.pop(0)\n\nletters = ['a', 'b', 'c']\npop_first(letters)\nprint(letters)\n\n['b', 'c']\n\n\nIf you do not want a function to modify the original list, pass a\ncopy:\n\npop_first(list(letters))  # or pop_first(letters[:])\n\n'b'",
    "crumbs": [
      "Learning Modules",
      "04 | Strings, Lists, Dictionaries, and Tuples"
    ]
  },
  {
    "objectID": "learning-modules/04-data-structures.html#dictionaries",
    "href": "learning-modules/04-data-structures.html#dictionaries",
    "title": "04 | Strings, Lists, Dictionaries, and Tuples",
    "section": "4\nDictionaries",
    "text": "4\nDictionaries\nA dictionary maps keys to values and offers very\nfast lookups. Keys must be immutable, while values can be\nanything (including lists).\n\n4.1 A\ndictionary is a mapping\nInstead of using integer indices, a dictionary can use almost any\nhashable type as a key. You create a\ndictionary with curly braces:\n\nnumbers = {}\nnumbers['zero'] = 0\nnumbers['one'] = 1\nnumbers\n\n{'zero': 0, 'one': 1}\n\n\nAccess a value using its key:\n\nnumbers['one']\n\n1\n\n\nDictionary keys must be unique and immutable. Lists cannot serve as\nkeys because they are mutable. These are useful for fast lookup by label\n(e.g., “user_id” -&gt; user info) instead of by integer position.\n\n\n4.2\nCreating dictionaries\nYou can create a dictionary all at once:\n\nnumbers = {'zero': 0, 'one': 1, 'two': 2}\n\nor use dict():\n\nnumbers_copy = dict(numbers)\nprint(numbers_copy)\n\nempty = dict()\nprint(empty)\n\n{'zero': 0, 'one': 1, 'two': 2}\n{}\n\n\n\n\n4.3 The\nin operator\nin checks for keys in the dictionary for membership\nwithout searching through all entries:\n\n'one' in numbers\n\nTrue\n\n\n\n'three' in numbers\n\nFalse\n\n\nTo check if something appears as a value, use\nnumbers.values():\n\n1 in numbers.values()\n\nTrue\n\n\n\n\n4.4\nCounting with dictionaries\nUse a dictionary to count how often each character appears in a\nstring:\n\ndef value_counts(string):\n    counter = {}\n    for letter in string:\n        if letter not in counter:\n            counter[letter] = 1\n        else:\n            counter[letter] += 1\n    return counter\n\nvalue_counts('brontosaurus')\n\n{'b': 1, 'r': 2, 'o': 2, 'n': 1, 't': 1, 's': 2, 'a': 1, 'u': 2}\n\n\n\n\n4.5\nLooping with dictionaries\nWhen you loop over a dictionary, you traverse its keys:\n\ncounter = value_counts('banana')\n\n\nfor key in counter:\n    print(key)\n\nb\na\nn\n\n\nUse counter.values() to loop over values:\n\nfor value in counter.values():\n    print(value)\n\n1\n3\n2\n\n\nOr you can use the bracket operator to get the key and value:\n\nfor key in counter:\n    print(key, counter[key])\n\nb 1\na 3\nn 2\n\n\nThis method searches the counter dictionary in every\nloop, and we will see more efficient version of this loop in the tuples\nsection.\n\n\n4.6\nLists and dictionaries\nA dictionary’s values can be lists (or other\ndictionaries), but keys must be hashable:\n\nd = {\n    \"fruits\": [\"apple\", \"banana\", \"cherry\"],\n    \"numbers\": [10, 20, 30],\n    \"colors\": {\n        \"red\": [True, False, True],\n        \"yellow\": [True, True, False],\n        \"green\": [True, False, False]\n    }\n}\n\nprint(d)\n\n{'fruits': ['apple', 'banana', 'cherry'], 'numbers': [10, 20, 30], 'colors': {'red': [True, False, True], 'yellow': [True, True, False], 'green': [True, False, False]}}\n\n\nThis allows you to combine structures for more complex data\nrepresentations, such as JSON-like objects. You cannot use a\nlist as a key. Python uses a hash table for\nquick lookups, and hash values must not change.",
    "crumbs": [
      "Learning Modules",
      "04 | Strings, Lists, Dictionaries, and Tuples"
    ]
  },
  {
    "objectID": "learning-modules/04-data-structures.html#tuples",
    "href": "learning-modules/04-data-structures.html#tuples",
    "title": "04 | Strings, Lists, Dictionaries, and Tuples",
    "section": "5\nTuples",
    "text": "5\nTuples\nTuples are immutable sequences that can hold multiple items. They’re\noften used where immutability is helpful (e.g., as dictionary keys).\n\n5.1\nTuples are sequences\nTuples work like lists but cannot be modified once created. You\ncreate a tuple with comma-separated values, usually enclosed in\nparentheses:\n\nt = ('l', 'u', 'p', 'i', 'n')\nt_2 = 'l', 'u', 'p', 'i', 'n'\n\nprint(type(t))\nprint(type(t_2))\n\n&lt;class 'tuple'&gt;\n&lt;class 'tuple'&gt;\n\n\nYou can create a single element tuple:\n\nt_single = \"a\",\nprint(t_single)\n\n('a',)\n\n\nWrapping a single element with parenthesis does not make a\nsingle-element tuple:\n\nt_single_bad = (\"a\")\nprint(t_single_bad)\nprint(type(t_single_bad))\n\na\n&lt;class 'str'&gt;\n\n\n\n\n5.2\nTuples are immutable\nLike strings, tuples are immutable. Attempting to\nmodify a tuple directly causes an error. Tuples do not have list-like\nmethods such as append or remove.\n\nt[0] = \"L\"\n\n\n---------------------------------------------------------------------------\nTypeError                                 Traceback (most recent call last)\nCell In[68], line 1\n----&gt; 1 t[0] = \"L\"\n\nTypeError: 'tuple' object does not support item assignment\n\n\n\nBecause they are immutable, tuples are hashable and\ncan serve as keys in a dictionary:\n\ncoords = {}\ncoords[(1, 2)] = \"Location A\"\ncoords[(3, 4)] = \"Location B\"\nprint(coords)\n\n{(1, 2): 'Location A', (3, 4): 'Location B'}\n\n\nYou cannot alter tuple contents after creation.\n\n\n5.3\nTuple assignment\nYou can assign multiple variables at once with tuple unpacking:\n\na, b = 1, 2 # could also use: (a, b) = (1, 2) or any combo of parenthesis\nprint(a, b)\n\n1 2\n\n\nIf the right side has the wrong number of values, Python raises a\nValueError.\n\na, b = 1, 2, 3\n\n\n---------------------------------------------------------------------------\nValueError                                Traceback (most recent call last)\nCell In[71], line 1\n----&gt; 1 a, b = 1, 2, 3\n\nValueError: too many values to unpack (expected 2)\n\n\n\nYou can also swap variables in one line. This allows you to swap\nvariables without an extra temporary variable and return multiple values\nelegantly:\n\nprint(a, b)\na, b = b, a # swap\nprint(a, b)\n\n1 2\n2 1\n\n\nYou often use tuple assignment to iterate over\n(key, value) pairs from a dictionary:\n\nd = {'one': 1, 'two': 2, 'three': 3}\n\nfor item in d.items():\n    key, value = item\n    print(key, '-&gt;', value)\n\none -&gt; 1\ntwo -&gt; 2\nthree -&gt; 3\n\n\nEach time through the loop, item is assigned a tuple\nthat contains a key and the corresponding value.\nWe can write this loop more concisely, like this:\n\nfor key, value in d.items():\n    print(key, '-&gt;', value)\n\none -&gt; 1\ntwo -&gt; 2\nthree -&gt; 3\n\n\n\n\n5.4\nTuples as return values\nA function can return a single tuple, effectively returning multiple\nvalues:\n\ndef min_max(t):\n    return min(t), max(t) # could also write: (min(t), max(t))\n\nlow, high = min_max([2, 4, 1, 3])\nprint(low, high)\n\n1 4\n\n\nThis offers a clean way to return more than one piece of information\nfrom a function.\n\n\n5.5\nArgument packing and unpacking\nIf a function parameter starts with *, Python\npacks extra arguments into a tuple:\n\ndef mean(*args):\n    return sum(args) / len(args)\n\nmean(1, 2, 3)\n\n2.0\n\n\nHere is an example you are already familiar with,\nprint:\ndef print(*args, sep=' ', end='\\n', file=None, flush=False):\n    \"\"\"print code\"\"\"\n\nprint(1, 2, 3, sep=\", \")\n\n1, 2, 3\n\n\nYou can unpack a sequence by using *\nwhen calling a function:\n\ndivmod(*[7, 3])  # same as divmod(7, 3)\n\n(2, 1)\n\n\nConsider a function that calculates a “trimmed” mean by removing the\nlowest and highest values:\n\ndef trimmed_mean(*args):\n    low, high = min_max(args)\n    trimmed = list(args)\n    trimmed.remove(low)\n    trimmed.remove(high)\n    return mean(*trimmed)\n\ntrimmed_mean(1, 2, 3, 4, 5)\n\n3.0\n\n\nWhile this is a bit more advanced than we will need for this course,\nit allows flexible argument passing and returning, which helps build\nutility functions that accept varying numbers of inputs.\n\n\n5.6\nZip\nThe built-in zip function pairs up corresponding\nelements from multiple sequences:\n\nscores1 = [1, 2, 4, 5, 1, 5, 2]\nscores2 = [5, 5, 2, 5, 5, 2, 3]\n\nfor s1, s2 in zip(scores1, scores2):\n    if s1 &gt; s2:\n        print(\"Team1 wins this game!\")\n    elif s1 &lt; s2:\n        print(\"Team2 wins this game!\")\n    else:\n        print(\"It's a tie!\")\n\nTeam2 wins this game!\nTeam2 wins this game!\nTeam1 wins this game!\nIt's a tie!\nTeam2 wins this game!\nTeam1 wins this game!\nTeam2 wins this game!\n\n\nlist(zip(a, b)) returns a list of tuples. You can also\ncombine zip with dict to create dictionaries\nfrom two parallel lists:\n\nletters = 'abc'\nnumbers = [0, 1, 2]\ndict(zip(letters, numbers)) # try list(zip(letters, numbers)) on your own\n\n{'a': 0, 'b': 1, 'c': 2}\n\n\nUse enumerate to loop over the indices and elements of a\nsequence at the same time:\n\nfor index, element in enumerate('abcefghijk'):\n    print(index, element)\n\n0 a\n1 b\n2 c\n3 e\n4 f\n5 g\n6 h\n7 i\n8 j\n9 k\n\n\nTo see the values enumerate creates, you need to turn\nthe enumerate object into either a list, tuple, or\ndictionary:\n\nenumerate('abcefghijk')\n\n&lt;enumerate at 0x25ab4f3f740&gt;\n\n\n\nlist(enumerate('abcefghijk'))\n\n[(0, 'a'),\n (1, 'b'),\n (2, 'c'),\n (3, 'e'),\n (4, 'f'),\n (5, 'g'),\n (6, 'h'),\n (7, 'i'),\n (8, 'j'),\n (9, 'k')]\n\n\n\ntuple(enumerate('abcefghijk'))\n\n((0, 'a'),\n (1, 'b'),\n (2, 'c'),\n (3, 'e'),\n (4, 'f'),\n (5, 'g'),\n (6, 'h'),\n (7, 'i'),\n (8, 'j'),\n (9, 'k'))\n\n\n\ndict(enumerate('abcefghijk'))\n\n{0: 'a',\n 1: 'b',\n 2: 'c',\n 3: 'e',\n 4: 'f',\n 5: 'g',\n 6: 'h',\n 7: 'i',\n 8: 'j',\n 9: 'k'}\n\n\nThis is true for many Python functions that create objects, so\nremember to experiment with new code.\n\n\n5.7\nInverting a dictionary\nTo invert a dictionary that maps a key to a value, you might need to\nmap each value to a list of keys (because multiple keys can share the\nsame value). For example:\n\ndef invert_dict(d):\n    new_d = {}\n    for key, val in d.items():\n        if val not in new_d:\n            new_d[val] = [key]\n        else:\n            new_d[val].append(key)\n    return new_d\n\nThis is useful for reverse lookups when multiple keys share the same\nvalue:\n\ncounts = {\n    \"a\": 1,\n    \"b\": 23,\n    \"c\": 1,\n    \"d\": 4,\n    \"e\": 4\n}\n\ninvert_dict(counts)\n\n{1: ['a', 'c'], 23: ['b'], 4: ['d', 'e']}\n\n\n\n\n5.8\nDictionaries with tuple keys\nTuples are hashable, so we can use them as dictionary keys:\n\nlocations = {}\nlocations[(1, 2)] = \"Start\"\nlocations[(3, 4)] = \"Goal\"\nprint(locations[(3, 4)]) \n\nGoal\n\n\nThis could be useful for coordinate-based lookups (e.g., board games\nor grid-based apps).",
    "crumbs": [
      "Learning Modules",
      "04 | Strings, Lists, Dictionaries, and Tuples"
    ]
  },
  {
    "objectID": "learning-modules/04-data-structures.html#exercises",
    "href": "learning-modules/04-data-structures.html#exercises",
    "title": "04 | Strings, Lists, Dictionaries, and Tuples",
    "section": "6\nExercises",
    "text": "6\nExercises\n\n6.1\nChecking for a word in a sentence\nWrite a program that checks if the word \"apple\" appears\nin the sentence\n“I bought some apples and oranges at the market.\" Print\n\"Found\" or \"Not Found\" accordingly. Consider\nusing re.search() with a pattern allowing an optional\ns.\n\n\n6.2\nFinding phone numbers with different formats\nGiven:\n\ntext = \"\"\"\nCall me at 123-456-7890 or at (123) 456-7890.\nAlternatively, reach me at 123.456.7890.\n\"\"\"\n\nWrite a single regex that matches all three phone formats. Use\nre.findall() to capture them.\n\n\n6.3\nExtracting captured groups\nFor a product catalog:\n\ncatalog = \"\"\"Product ID: ABC-123 Price: $29.99\nProduct ID: XY-999 Price: $199.95\nProduct ID: TT-100 Price: $10.50\nProduct ID: ZZ-777 Price: $777.00\nProduct ID: FF-333 Price: $2.99\n\"\"\"\n\nWrite a regex that captures (ProductID, Price) as\ngroups. Use re.findall() to produce a list of tuples.\n\n\n6.4\nAnagrams\nTwo words are anagrams if one can be rearranged to form the other.\nWrite is_anagram that returns True if two\nstrings are anagrams. Then find all anagrams of \"takes\" in\na given word list.\n\n\n6.5\nPalindromes\nA palindrome reads the same forward and backward. Write\nis_palindrome that checks if a string is a palindrome. Use\nreversed or slice notation to reverse strings.\n\n\n6.6\nUsing get in a dictionary\nRewrite the value_counts function to eliminate the\nif statement by using\ndict.get(key, default).\n\n\n6.7\nLongest word with all unique letters\nWrite has_duplicates(sequence) that returns\nTrue if any element appears more than once. Test it to see\nif you can find a word longer than \"unpredictably\" with all\nunique letters.\n\n\n6.8\nFinding repeats\nWrite find_repeats(counter) that takes a dictionary\nmapping from keys to counts and returns a list of keys appearing more\nthan once.\n\n\n6.9\nMost frequent letters\nWrite most_frequent_letters(string) that prints letters\nin decreasing order of frequency. You can use\nreversed(sorted(...)) or\nsorted(..., reverse=True).",
    "crumbs": [
      "Learning Modules",
      "04 | Strings, Lists, Dictionaries, and Tuples"
    ]
  }
]